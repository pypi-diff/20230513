# Comparing `tmp/mlflow_skinny-2.3.1-py3-none-any.whl.zip` & `tmp/mlflow_skinny-2.3.2-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,354 +1,356 @@
-Zip file size: 4073960 bytes, number of entries: 352
--rw-r--r--  2.0 unx     6155 b- defN 23-Apr-28 08:25 mlflow/__init__.py
--rw-r--r--  2.0 unx       39 b- defN 23-Apr-28 08:25 mlflow/__main__.py
--rw-r--r--  2.0 unx     3668 b- defN 23-Apr-28 08:25 mlflow/_doctor.py
--rw-r--r--  2.0 unx     9428 b- defN 23-Apr-28 08:25 mlflow/_spark_autologging.py
--rw-r--r--  2.0 unx    15140 b- defN 23-Apr-28 08:25 mlflow/catboost.py
--rw-r--r--  2.0 unx    23356 b- defN 23-Apr-28 08:25 mlflow/cli.py
--rw-r--r--  2.0 unx      407 b- defN 23-Apr-28 08:25 mlflow/client.py
--rw-r--r--  2.0 unx      881 b- defN 23-Apr-28 08:25 mlflow/db.py
--rw-r--r--  2.0 unx    28178 b- defN 23-Apr-28 08:25 mlflow/diviner.py
--rw-r--r--  2.0 unx    10080 b- defN 23-Apr-28 08:25 mlflow/environment_variables.py
--rw-r--r--  2.0 unx     4881 b- defN 23-Apr-28 08:25 mlflow/exceptions.py
--rw-r--r--  2.0 unx     5080 b- defN 23-Apr-28 08:25 mlflow/experiments.py
--rw-r--r--  2.0 unx    14185 b- defN 23-Apr-28 08:25 mlflow/h2o.py
--rw-r--r--  2.0 unx      311 b- defN 23-Apr-28 08:25 mlflow/keras.py
--rw-r--r--  2.0 unx    35698 b- defN 23-Apr-28 08:25 mlflow/lightgbm.py
--rw-r--r--  2.0 unx      180 b- defN 23-Apr-28 08:25 mlflow/llm.py
--rw-r--r--  2.0 unx     5474 b- defN 23-Apr-28 08:25 mlflow/ml_package_versions.py
--rw-r--r--  2.0 unx    13885 b- defN 23-Apr-28 08:25 mlflow/mleap.py
--rw-r--r--  2.0 unx    21826 b- defN 23-Apr-28 08:25 mlflow/onnx.py
--rw-r--r--  2.0 unx    17616 b- defN 23-Apr-28 08:25 mlflow/pmdarima.py
--rw-r--r--  2.0 unx    14024 b- defN 23-Apr-28 08:25 mlflow/prophet.py
--rw-r--r--  2.0 unx  7197781 b- defN 23-Apr-28 08:25 mlflow/pypi_package_index.json
--rw-r--r--  2.0 unx     2519 b- defN 23-Apr-28 08:25 mlflow/runs.py
--rw-r--r--  2.0 unx    26647 b- defN 23-Apr-28 08:25 mlflow/shap.py
--rw-r--r--  2.0 unx    14259 b- defN 23-Apr-28 08:25 mlflow/spacy.py
--rw-r--r--  2.0 unx    44813 b- defN 23-Apr-28 08:25 mlflow/spark.py
--rw-r--r--  2.0 unx    24596 b- defN 23-Apr-28 08:25 mlflow/statsmodels.py
--rw-r--r--  2.0 unx    89127 b- defN 23-Apr-28 08:25 mlflow/transformers.py
--rw-r--r--  2.0 unx      147 b- defN 23-Apr-28 08:25 mlflow/version.py
--rw-r--r--  2.0 unx     6485 b- defN 23-Apr-28 08:25 mlflow/artifacts/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/azure/__init__.py
--rw-r--r--  2.0 unx    11647 b- defN 23-Apr-28 08:25 mlflow/azure/client.py
--rw-r--r--  2.0 unx     3797 b- defN 23-Apr-28 08:25 mlflow/deployments/__init__.py
--rw-r--r--  2.0 unx    15572 b- defN 23-Apr-28 08:25 mlflow/deployments/base.py
--rw-r--r--  2.0 unx    15078 b- defN 23-Apr-28 08:25 mlflow/deployments/cli.py
--rw-r--r--  2.0 unx     3825 b- defN 23-Apr-28 08:25 mlflow/deployments/interface.py
--rw-r--r--  2.0 unx     5512 b- defN 23-Apr-28 08:25 mlflow/deployments/plugin_manager.py
--rw-r--r--  2.0 unx      556 b- defN 23-Apr-28 08:25 mlflow/deployments/utils.py
--rw-r--r--  2.0 unx      948 b- defN 23-Apr-28 08:25 mlflow/entities/__init__.py
--rw-r--r--  2.0 unx     1414 b- defN 23-Apr-28 08:25 mlflow/entities/_mlflow_object.py
--rw-r--r--  2.0 unx     3510 b- defN 23-Apr-28 08:25 mlflow/entities/experiment.py
--rw-r--r--  2.0 unx      887 b- defN 23-Apr-28 08:25 mlflow/entities/experiment_tag.py
--rw-r--r--  2.0 unx     1215 b- defN 23-Apr-28 08:25 mlflow/entities/file_info.py
--rw-r--r--  2.0 unx     1242 b- defN 23-Apr-28 08:25 mlflow/entities/lifecycle_stage.py
--rw-r--r--  2.0 unx     1418 b- defN 23-Apr-28 08:25 mlflow/entities/metric.py
--rw-r--r--  2.0 unx     1133 b- defN 23-Apr-28 08:25 mlflow/entities/param.py
--rw-r--r--  2.0 unx     1438 b- defN 23-Apr-28 08:25 mlflow/entities/run.py
--rw-r--r--  2.0 unx     3032 b- defN 23-Apr-28 08:25 mlflow/entities/run_data.py
--rw-r--r--  2.0 unx     6182 b- defN 23-Apr-28 08:25 mlflow/entities/run_info.py
--rw-r--r--  2.0 unx     1550 b- defN 23-Apr-28 08:25 mlflow/entities/run_status.py
--rw-r--r--  2.0 unx      890 b- defN 23-Apr-28 08:25 mlflow/entities/run_tag.py
--rw-r--r--  2.0 unx     1212 b- defN 23-Apr-28 08:25 mlflow/entities/source_type.py
--rw-r--r--  2.0 unx     1826 b- defN 23-Apr-28 08:25 mlflow/entities/view_type.py
--rw-r--r--  2.0 unx      529 b- defN 23-Apr-28 08:25 mlflow/entities/model_registry/__init__.py
--rw-r--r--  2.0 unx      286 b- defN 23-Apr-28 08:25 mlflow/entities/model_registry/_model_registry_entity.py
--rw-r--r--  2.0 unx     6435 b- defN 23-Apr-28 08:25 mlflow/entities/model_registry/model_version.py
--rw-r--r--  2.0 unx      831 b- defN 23-Apr-28 08:25 mlflow/entities/model_registry/model_version_stages.py
--rw-r--r--  2.0 unx     1533 b- defN 23-Apr-28 08:25 mlflow/entities/model_registry/model_version_status.py
--rw-r--r--  2.0 unx      933 b- defN 23-Apr-28 08:25 mlflow/entities/model_registry/model_version_tag.py
--rw-r--r--  2.0 unx     4933 b- defN 23-Apr-28 08:25 mlflow/entities/model_registry/registered_model.py
--rw-r--r--  2.0 unx     1053 b- defN 23-Apr-28 08:25 mlflow/entities/model_registry/registered_model_alias.py
--rw-r--r--  2.0 unx      948 b- defN 23-Apr-28 08:25 mlflow/entities/model_registry/registered_model_tag.py
--rw-r--r--  2.0 unx    25354 b- defN 23-Apr-28 08:25 mlflow/fastai/__init__.py
--rw-r--r--  2.0 unx     5757 b- defN 23-Apr-28 08:25 mlflow/fastai/callback.py
--rw-r--r--  2.0 unx    19063 b- defN 23-Apr-28 08:25 mlflow/gluon/__init__.py
--rw-r--r--  2.0 unx     2020 b- defN 23-Apr-28 08:25 mlflow/gluon/_autolog.py
--rw-r--r--  2.0 unx    16643 b- defN 23-Apr-28 08:25 mlflow/langchain/__init__.py
--rw-r--r--  2.0 unx     4846 b- defN 23-Apr-28 08:25 mlflow/langchain/api_request_parallel_processor.py
--rw-r--r--  2.0 unx     3627 b- defN 23-Apr-28 08:25 mlflow/models/__init__.py
--rw-r--r--  2.0 unx     9803 b- defN 23-Apr-28 08:25 mlflow/models/cli.py
--rw-r--r--  2.0 unx     9853 b- defN 23-Apr-28 08:25 mlflow/models/docker_utils.py
--rw-r--r--  2.0 unx     3420 b- defN 23-Apr-28 08:25 mlflow/models/flavor_backend.py
--rw-r--r--  2.0 unx     2354 b- defN 23-Apr-28 08:25 mlflow/models/flavor_backend_registry.py
--rw-r--r--  2.0 unx    23802 b- defN 23-Apr-28 08:25 mlflow/models/model.py
--rw-r--r--  2.0 unx     8634 b- defN 23-Apr-28 08:25 mlflow/models/signature.py
--rw-r--r--  2.0 unx    38033 b- defN 23-Apr-28 08:25 mlflow/models/utils.py
--rw-r--r--  2.0 unx    11707 b- defN 23-Apr-28 08:25 mlflow/models/wheeled_model.py
--rw-r--r--  2.0 unx     9387 b- defN 23-Apr-28 08:25 mlflow/models/container/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/models/container/scoring_server/__init__.py
--rw-r--r--  2.0 unx      131 b- defN 23-Apr-28 08:25 mlflow/models/container/scoring_server/wsgi.py
--rw-r--r--  2.0 unx      491 b- defN 23-Apr-28 08:25 mlflow/models/evaluation/__init__.py
--rw-r--r--  2.0 unx     3105 b- defN 23-Apr-28 08:25 mlflow/models/evaluation/_shap_patch.py
--rw-r--r--  2.0 unx     6769 b- defN 23-Apr-28 08:25 mlflow/models/evaluation/artifacts.py
--rw-r--r--  2.0 unx    59205 b- defN 23-Apr-28 08:25 mlflow/models/evaluation/base.py
--rw-r--r--  2.0 unx    50976 b- defN 23-Apr-28 08:25 mlflow/models/evaluation/default_evaluator.py
--rw-r--r--  2.0 unx     2036 b- defN 23-Apr-28 08:25 mlflow/models/evaluation/evaluator_registry.py
--rw-r--r--  2.0 unx     6223 b- defN 23-Apr-28 08:25 mlflow/models/evaluation/lift_curve.py
--rw-r--r--  2.0 unx    10946 b- defN 23-Apr-28 08:25 mlflow/models/evaluation/validation.py
--rw-r--r--  2.0 unx    23159 b- defN 23-Apr-28 08:25 mlflow/openai/__init__.py
--rw-r--r--  2.0 unx    12309 b- defN 23-Apr-28 08:25 mlflow/openai/api_request_parallel_processor.py
--rw-r--r--  2.0 unx     2936 b- defN 23-Apr-28 08:25 mlflow/openai/retry.py
--rw-r--r--  2.0 unx     2040 b- defN 23-Apr-28 08:25 mlflow/openai/utils.py
--rw-r--r--  2.0 unx    23859 b- defN 23-Apr-28 08:25 mlflow/paddle/__init__.py
--rw-r--r--  2.0 unx     4792 b- defN 23-Apr-28 08:25 mlflow/paddle/_paddle_autolog.py
--rw-r--r--  2.0 unx    17396 b- defN 23-Apr-28 08:25 mlflow/projects/__init__.py
--rw-r--r--  2.0 unx    11532 b- defN 23-Apr-28 08:25 mlflow/projects/_project_spec.py
--rw-r--r--  2.0 unx    20270 b- defN 23-Apr-28 08:25 mlflow/projects/databricks.py
--rw-r--r--  2.0 unx     6394 b- defN 23-Apr-28 08:25 mlflow/projects/docker.py
--rw-r--r--  2.0 unx       94 b- defN 23-Apr-28 08:25 mlflow/projects/env_type.py
--rw-r--r--  2.0 unx     6379 b- defN 23-Apr-28 08:25 mlflow/projects/kubernetes.py
--rw-r--r--  2.0 unx     3574 b- defN 23-Apr-28 08:25 mlflow/projects/submitted_run.py
--rw-r--r--  2.0 unx    13432 b- defN 23-Apr-28 08:25 mlflow/projects/utils.py
--rw-r--r--  2.0 unx      271 b- defN 23-Apr-28 08:25 mlflow/projects/backend/__init__.py
--rw-r--r--  2.0 unx     2210 b- defN 23-Apr-28 08:25 mlflow/projects/backend/abstract_backend.py
--rw-r--r--  2.0 unx     1079 b- defN 23-Apr-28 08:25 mlflow/projects/backend/loader.py
--rw-r--r--  2.0 unx    17240 b- defN 23-Apr-28 08:25 mlflow/projects/backend/local.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/protos/__init__.py
--rw-r--r--  2.0 unx    17261 b- defN 23-Apr-28 08:25 mlflow/protos/databricks_artifacts_pb2.py
--rw-r--r--  2.0 unx    14095 b- defN 23-Apr-28 08:25 mlflow/protos/databricks_pb2.py
--rw-r--r--  2.0 unx    38674 b- defN 23-Apr-28 08:25 mlflow/protos/databricks_uc_registry_messages_pb2.py
--rw-r--r--  2.0 unx    12471 b- defN 23-Apr-28 08:25 mlflow/protos/databricks_uc_registry_service_pb2.py
--rw-r--r--  2.0 unx    16146 b- defN 23-Apr-28 08:25 mlflow/protos/facet_feature_statistics_pb2.py
--rw-r--r--  2.0 unx     8552 b- defN 23-Apr-28 08:25 mlflow/protos/mlflow_artifacts_pb2.py
--rw-r--r--  2.0 unx    54475 b- defN 23-Apr-28 08:25 mlflow/protos/model_registry_pb2.py
--rw-r--r--  2.0 unx    48593 b- defN 23-Apr-28 08:25 mlflow/protos/service_pb2.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/protos/scalapb/__init__.py
--rw-r--r--  2.0 unx     3307 b- defN 23-Apr-28 08:25 mlflow/protos/scalapb/scalapb_pb2.py
--rw-r--r--  2.0 unx    81392 b- defN 23-Apr-28 08:25 mlflow/pyfunc/__init__.py
--rw-r--r--  2.0 unx    16640 b- defN 23-Apr-28 08:25 mlflow/pyfunc/backend.py
--rw-r--r--  2.0 unx      901 b- defN 23-Apr-28 08:25 mlflow/pyfunc/mlserver.py
--rw-r--r--  2.0 unx    15392 b- defN 23-Apr-28 08:25 mlflow/pyfunc/model.py
--rw-r--r--  2.0 unx     2124 b- defN 23-Apr-28 08:25 mlflow/pyfunc/spark_model_cache.py
--rw-r--r--  2.0 unx     1001 b- defN 23-Apr-28 08:25 mlflow/pyfunc/stdin_server.py
--rw-r--r--  2.0 unx    13910 b- defN 23-Apr-28 08:25 mlflow/pyfunc/scoring_server/__init__.py
--rw-r--r--  2.0 unx     4222 b- defN 23-Apr-28 08:25 mlflow/pyfunc/scoring_server/client.py
--rw-r--r--  2.0 unx      175 b- defN 23-Apr-28 08:25 mlflow/pyfunc/scoring_server/wsgi.py
--rw-r--r--  2.0 unx       50 b- defN 23-Apr-28 08:25 mlflow/pyspark/__init__.py
--rw-r--r--  2.0 unx    53458 b- defN 23-Apr-28 08:25 mlflow/pyspark/ml/__init__.py
--rw-r--r--  2.0 unx     2908 b- defN 23-Apr-28 08:25 mlflow/pyspark/ml/_autolog.py
--rw-r--r--  2.0 unx     1886 b- defN 23-Apr-28 08:25 mlflow/pyspark/ml/log_model_allowlist.txt
--rw-r--r--  2.0 unx    45669 b- defN 23-Apr-28 08:25 mlflow/pytorch/__init__.py
--rw-r--r--  2.0 unx    17629 b- defN 23-Apr-28 08:25 mlflow/pytorch/_lightning_autolog.py
--rw-r--r--  2.0 unx     2654 b- defN 23-Apr-28 08:25 mlflow/pytorch/_pytorch_autolog.py
--rw-r--r--  2.0 unx     2090 b- defN 23-Apr-28 08:25 mlflow/pytorch/pickle_module.py
--rw-r--r--  2.0 unx     1330 b- defN 23-Apr-28 08:25 mlflow/recipes/__init__.py
--rw-r--r--  2.0 unx     6092 b- defN 23-Apr-28 08:25 mlflow/recipes/artifacts.py
--rw-r--r--  2.0 unx     2917 b- defN 23-Apr-28 08:25 mlflow/recipes/cli.py
--rw-r--r--  2.0 unx    18431 b- defN 23-Apr-28 08:25 mlflow/recipes/dag_help_strings.py
--rw-r--r--  2.0 unx    17933 b- defN 23-Apr-28 08:25 mlflow/recipes/recipe.py
--rw-r--r--  2.0 unx    14988 b- defN 23-Apr-28 08:25 mlflow/recipes/step.py
--rw-r--r--  2.0 unx    10229 b- defN 23-Apr-28 08:25 mlflow/recipes/cards/__init__.py
--rw-r--r--  2.0 unx     4780 b- defN 23-Apr-28 08:25 mlflow/recipes/cards/histogram_generator.py
--rw-r--r--  2.0 unx    12548 b- defN 23-Apr-28 08:25 mlflow/recipes/cards/pandas_renderer.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/recipes/cards/templates/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/recipes/classification/__init__.py
--rw-r--r--  2.0 unx      122 b- defN 23-Apr-28 08:25 mlflow/recipes/classification/v1/__init__.py
--rw-r--r--  2.0 unx    20462 b- defN 23-Apr-28 08:25 mlflow/recipes/classification/v1/recipe.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/recipes/regression/__init__.py
--rw-r--r--  2.0 unx      114 b- defN 23-Apr-28 08:25 mlflow/recipes/regression/v1/__init__.py
--rw-r--r--  2.0 unx    22495 b- defN 23-Apr-28 08:25 mlflow/recipes/regression/v1/recipe.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/recipes/steps/__init__.py
--rw-r--r--  2.0 unx    20717 b- defN 23-Apr-28 08:25 mlflow/recipes/steps/evaluate.py
--rw-r--r--  2.0 unx    12132 b- defN 23-Apr-28 08:25 mlflow/recipes/steps/predict.py
--rw-r--r--  2.0 unx     7680 b- defN 23-Apr-28 08:25 mlflow/recipes/steps/register.py
--rw-r--r--  2.0 unx    19541 b- defN 23-Apr-28 08:25 mlflow/recipes/steps/split.py
--rw-r--r--  2.0 unx    59789 b- defN 23-Apr-28 08:25 mlflow/recipes/steps/train.py
--rw-r--r--  2.0 unx    10602 b- defN 23-Apr-28 08:25 mlflow/recipes/steps/transform.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/recipes/steps/automl/__init__.py
--rw-r--r--  2.0 unx     6269 b- defN 23-Apr-28 08:25 mlflow/recipes/steps/automl/flaml.py
--rw-r--r--  2.0 unx    11137 b- defN 23-Apr-28 08:25 mlflow/recipes/steps/ingest/__init__.py
--rw-r--r--  2.0 unx    26446 b- defN 23-Apr-28 08:25 mlflow/recipes/steps/ingest/datasets.py
--rw-r--r--  2.0 unx     6355 b- defN 23-Apr-28 08:25 mlflow/recipes/utils/__init__.py
--rw-r--r--  2.0 unx    28468 b- defN 23-Apr-28 08:25 mlflow/recipes/utils/execution.py
--rw-r--r--  2.0 unx     8990 b- defN 23-Apr-28 08:25 mlflow/recipes/utils/metrics.py
--rw-r--r--  2.0 unx     7392 b- defN 23-Apr-28 08:25 mlflow/recipes/utils/step.py
--rw-r--r--  2.0 unx    12375 b- defN 23-Apr-28 08:25 mlflow/recipes/utils/tracking.py
--rw-r--r--  2.0 unx     1748 b- defN 23-Apr-28 08:25 mlflow/recipes/utils/wrapped_recipe_model.py
--rw-r--r--  2.0 unx     1115 b- defN 23-Apr-28 08:25 mlflow/rfunc/__init__.py
--rw-r--r--  2.0 unx     3643 b- defN 23-Apr-28 08:25 mlflow/rfunc/backend.py
--rw-r--r--  2.0 unx   135097 b- defN 23-Apr-28 08:25 mlflow/sagemaker/__init__.py
--rw-r--r--  2.0 unx    12986 b- defN 23-Apr-28 08:25 mlflow/sagemaker/cli.py
--rw-r--r--  2.0 unx     6460 b- defN 23-Apr-28 08:25 mlflow/server/__init__.py
--rw-r--r--  2.0 unx    68590 b- defN 23-Apr-28 08:25 mlflow/server/handlers.py
--rw-r--r--  2.0 unx      481 b- defN 23-Apr-28 08:25 mlflow/server/prometheus_exporter.py
--rw-r--r--  2.0 unx     4551 b- defN 23-Apr-28 08:25 mlflow/server/auth/__init__.py
--rw-r--r--  2.0 unx      409 b- defN 23-Apr-28 08:25 mlflow/server/auth/config.py
--rw-r--r--  2.0 unx     2384 b- defN 23-Apr-28 08:25 mlflow/server/auth/entities.py
--rw-r--r--  2.0 unx     5303 b- defN 23-Apr-28 08:25 mlflow/server/auth/sqlalchemy_store.py
--rw-r--r--  2.0 unx    82134 b- defN 23-Apr-28 08:25 mlflow/sklearn/__init__.py
--rw-r--r--  2.0 unx    37485 b- defN 23-Apr-28 08:25 mlflow/sklearn/utils.py
--rw-r--r--  2.0 unx      227 b- defN 23-Apr-28 08:25 mlflow/store/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/store/_unity_catalog/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/store/_unity_catalog/registry/__init__.py
--rw-r--r--  2.0 unx    25610 b- defN 23-Apr-28 08:25 mlflow/store/_unity_catalog/registry/rest_store.py
--rw-r--r--  2.0 unx     4276 b- defN 23-Apr-28 08:25 mlflow/store/_unity_catalog/registry/utils.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/store/artifact/__init__.py
--rw-r--r--  2.0 unx    15034 b- defN 23-Apr-28 08:25 mlflow/store/artifact/artifact_repo.py
--rw-r--r--  2.0 unx     5309 b- defN 23-Apr-28 08:25 mlflow/store/artifact/artifact_repository_registry.py
--rw-r--r--  2.0 unx     8136 b- defN 23-Apr-28 08:25 mlflow/store/artifact/azure_blob_artifact_repo.py
--rw-r--r--  2.0 unx     5829 b- defN 23-Apr-28 08:25 mlflow/store/artifact/azure_data_lake_artifact_repo.py
--rw-r--r--  2.0 unx     5378 b- defN 23-Apr-28 08:25 mlflow/store/artifact/cli.py
--rw-r--r--  2.0 unx    31773 b- defN 23-Apr-28 08:25 mlflow/store/artifact/databricks_artifact_repo.py
--rw-r--r--  2.0 unx     6654 b- defN 23-Apr-28 08:25 mlflow/store/artifact/databricks_models_artifact_repo.py
--rw-r--r--  2.0 unx    10247 b- defN 23-Apr-28 08:25 mlflow/store/artifact/dbfs_artifact_repo.py
--rw-r--r--  2.0 unx     5234 b- defN 23-Apr-28 08:25 mlflow/store/artifact/ftp_artifact_repo.py
--rw-r--r--  2.0 unx     5873 b- defN 23-Apr-28 08:25 mlflow/store/artifact/gcs_artifact_repo.py
--rw-r--r--  2.0 unx     9684 b- defN 23-Apr-28 08:25 mlflow/store/artifact/hdfs_artifact_repo.py
--rw-r--r--  2.0 unx     3377 b- defN 23-Apr-28 08:25 mlflow/store/artifact/http_artifact_repo.py
--rw-r--r--  2.0 unx     5085 b- defN 23-Apr-28 08:25 mlflow/store/artifact/local_artifact_repo.py
--rw-r--r--  2.0 unx     3001 b- defN 23-Apr-28 08:25 mlflow/store/artifact/mlflow_artifacts_repo.py
--rw-r--r--  2.0 unx     6757 b- defN 23-Apr-28 08:25 mlflow/store/artifact/models_artifact_repo.py
--rw-r--r--  2.0 unx     6016 b- defN 23-Apr-28 08:25 mlflow/store/artifact/runs_artifact_repo.py
--rw-r--r--  2.0 unx     9442 b- defN 23-Apr-28 08:25 mlflow/store/artifact/s3_artifact_repo.py
--rw-r--r--  2.0 unx     5455 b- defN 23-Apr-28 08:25 mlflow/store/artifact/sftp_artifact_repo.py
--rw-r--r--  2.0 unx     5326 b- defN 23-Apr-28 08:25 mlflow/store/artifact/unity_catalog_models_artifact_repo.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/store/artifact/utils/__init__.py
--rw-r--r--  2.0 unx     3934 b- defN 23-Apr-28 08:25 mlflow/store/artifact/utils/models.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/store/db/__init__.py
--rw-r--r--  2.0 unx       71 b- defN 23-Apr-28 08:25 mlflow/store/db/base_sql_model.py
--rw-r--r--  2.0 unx      221 b- defN 23-Apr-28 08:25 mlflow/store/db/db_types.py
--rw-r--r--  2.0 unx    10592 b- defN 23-Apr-28 08:25 mlflow/store/db/utils.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/__init__.py
--rw-r--r--  2.0 unx     1634 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/alembic.ini
--rw-r--r--  2.0 unx     2768 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/env.py
--rw-r--r--  2.0 unx     1990 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/0a8213491aaa_drop_duplicate_killed_constraint.py
--rw-r--r--  2.0 unx      462 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/0c779009ac13_add_deleted_time_field_to_runs_table.py
--rw-r--r--  2.0 unx      924 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/181f10493468_allow_nulls_for_metric_values.py
--rw-r--r--  2.0 unx     1059 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/27a6a02d2cf1_add_model_version_tags_table.py
--rw-r--r--  2.0 unx     2624 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/2b4d017a5e9b_add_model_registry_tables_to_db.py
--rw-r--r--  2.0 unx     1375 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/3500859a5d39_add_model_aliases_table.py
--rw-r--r--  2.0 unx     1433 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/39d1c3be5f05_add_is_nan_constraint_for_metrics_tables_if_necessary.py
--rw-r--r--  2.0 unx     1201 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/451aebb31d03_add_metric_step.py
--rw-r--r--  2.0 unx      940 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/728d730b5ebd_add_registered_model_tags_table.py
--rw-r--r--  2.0 unx     1014 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/7ac759974ad8_update_run_tags_with_larger_limit.py
--rw-r--r--  2.0 unx      476 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/84291f40a231_add_run_link_to_model_version.py
--rw-r--r--  2.0 unx     5716 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/89d4b8295536_create_latest_metrics_table.py
--rw-r--r--  2.0 unx     1666 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/90e64c465722_migrate_user_column_to_tags.py
--rw-r--r--  2.0 unx      577 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/97727af70f4d_creation_time_last_update_time_experiments.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/__init__.py
--rw-r--r--  2.0 unx      582 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/a8c4a736bde6_allow_nulls_for_run_id.py
--rw-r--r--  2.0 unx      637 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/bd07f7e963c5_create_index_on_run_uuid.py
--rw-r--r--  2.0 unx     1295 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/c48cb773bb87_reset_default_value_for_is_nan_in_metrics_table_for_mysql.py
--rw-r--r--  2.0 unx      684 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/cc1f77228345_change_param_value_length_to_500.py
--rw-r--r--  2.0 unx     2830 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/cfd24bdc0731_update_run_status_constraint_with_killed.py
--rw-r--r--  2.0 unx      904 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/df50e92ffc5e_add_experiment_tags_table.py
--rw-r--r--  2.0 unx       80 b- defN 23-Apr-28 08:25 mlflow/store/entities/__init__.py
--rw-r--r--  2.0 unx      479 b- defN 23-Apr-28 08:25 mlflow/store/entities/paged_list.py
--rw-r--r--  2.0 unx      605 b- defN 23-Apr-28 08:25 mlflow/store/model_registry/__init__.py
--rw-r--r--  2.0 unx    11022 b- defN 23-Apr-28 08:25 mlflow/store/model_registry/abstract_store.py
--rw-r--r--  2.0 unx     1330 b- defN 23-Apr-28 08:25 mlflow/store/model_registry/base_rest_store.py
--rw-r--r--  2.0 unx    38729 b- defN 23-Apr-28 08:25 mlflow/store/model_registry/file_store.py
--rw-r--r--  2.0 unx    16920 b- defN 23-Apr-28 08:25 mlflow/store/model_registry/rest_store.py
--rw-r--r--  2.0 unx    50457 b- defN 23-Apr-28 08:25 mlflow/store/model_registry/sqlalchemy_store.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/store/model_registry/dbmodels/__init__.py
--rw-r--r--  2.0 unx     6341 b- defN 23-Apr-28 08:25 mlflow/store/model_registry/dbmodels/models.py
--rw-r--r--  2.0 unx     1154 b- defN 23-Apr-28 08:25 mlflow/store/tracking/__init__.py
--rw-r--r--  2.0 unx    13042 b- defN 23-Apr-28 08:25 mlflow/store/tracking/abstract_store.py
--rw-r--r--  2.0 unx    46363 b- defN 23-Apr-28 08:25 mlflow/store/tracking/file_store.py
--rw-r--r--  2.0 unx    12172 b- defN 23-Apr-28 08:25 mlflow/store/tracking/rest_store.py
--rw-r--r--  2.0 unx    67230 b- defN 23-Apr-28 08:25 mlflow/store/tracking/sqlalchemy_store.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/store/tracking/dbmodels/__init__.py
--rw-r--r--  2.0 unx     8315 b- defN 23-Apr-28 08:25 mlflow/store/tracking/dbmodels/initial_models.py
--rw-r--r--  2.0 unx    15674 b- defN 23-Apr-28 08:25 mlflow/store/tracking/dbmodels/models.py
--rw-r--r--  2.0 unx    57261 b- defN 23-Apr-28 08:25 mlflow/tensorflow/__init__.py
--rw-r--r--  2.0 unx     8442 b- defN 23-Apr-28 08:25 mlflow/tensorflow/_autolog.py
--rw-r--r--  2.0 unx      995 b- defN 23-Apr-28 08:25 mlflow/tracking/__init__.py
--rw-r--r--  2.0 unx     7155 b- defN 23-Apr-28 08:25 mlflow/tracking/artifact_utils.py
--rw-r--r--  2.0 unx   126036 b- defN 23-Apr-28 08:25 mlflow/tracking/client.py
--rw-r--r--  2.0 unx    70974 b- defN 23-Apr-28 08:25 mlflow/tracking/fluent.py
--rw-r--r--  2.0 unx     3404 b- defN 23-Apr-28 08:25 mlflow/tracking/llm_utils.py
--rw-r--r--  2.0 unx     2248 b- defN 23-Apr-28 08:25 mlflow/tracking/metric_value_conversion_utils.py
--rw-r--r--  2.0 unx     3515 b- defN 23-Apr-28 08:25 mlflow/tracking/registry.py
--rw-r--r--  2.0 unx       41 b- defN 23-Apr-28 08:25 mlflow/tracking/_model_registry/__init__.py
--rw-r--r--  2.0 unx    15534 b- defN 23-Apr-28 08:25 mlflow/tracking/_model_registry/client.py
--rw-r--r--  2.0 unx     9364 b- defN 23-Apr-28 08:25 mlflow/tracking/_model_registry/fluent.py
--rw-r--r--  2.0 unx     3152 b- defN 23-Apr-28 08:25 mlflow/tracking/_model_registry/registry.py
--rw-r--r--  2.0 unx     7008 b- defN 23-Apr-28 08:25 mlflow/tracking/_model_registry/utils.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/tracking/_tracking_service/__init__.py
--rw-r--r--  2.0 unx    23690 b- defN 23-Apr-28 08:25 mlflow/tracking/_tracking_service/client.py
--rw-r--r--  2.0 unx     2335 b- defN 23-Apr-28 08:25 mlflow/tracking/_tracking_service/registry.py
--rw-r--r--  2.0 unx     9517 b- defN 23-Apr-28 08:25 mlflow/tracking/_tracking_service/utils.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/tracking/context/__init__.py
--rw-r--r--  2.0 unx     1076 b- defN 23-Apr-28 08:25 mlflow/tracking/context/abstract_context.py
--rw-r--r--  2.0 unx      520 b- defN 23-Apr-28 08:25 mlflow/tracking/context/databricks_cluster_context.py
--rw-r--r--  2.0 unx      561 b- defN 23-Apr-28 08:25 mlflow/tracking/context/databricks_command_context.py
--rw-r--r--  2.0 unx     1965 b- defN 23-Apr-28 08:25 mlflow/tracking/context/databricks_job_context.py
--rw-r--r--  2.0 unx     1713 b- defN 23-Apr-28 08:25 mlflow/tracking/context/databricks_notebook_context.py
--rw-r--r--  2.0 unx     1952 b- defN 23-Apr-28 08:25 mlflow/tracking/context/databricks_repo_context.py
--rw-r--r--  2.0 unx     1020 b- defN 23-Apr-28 08:25 mlflow/tracking/context/default_context.py
--rw-r--r--  2.0 unx      898 b- defN 23-Apr-28 08:25 mlflow/tracking/context/git_context.py
--rw-r--r--  2.0 unx     3738 b- defN 23-Apr-28 08:25 mlflow/tracking/context/registry.py
--rw-r--r--  2.0 unx      443 b- defN 23-Apr-28 08:25 mlflow/tracking/context/system_environment_context.py
--rw-r--r--  2.0 unx       28 b- defN 23-Apr-28 08:25 mlflow/tracking/default_experiment/__init__.py
--rw-r--r--  2.0 unx     1703 b- defN 23-Apr-28 08:25 mlflow/tracking/default_experiment/abstract_context.py
--rw-r--r--  2.0 unx     1718 b- defN 23-Apr-28 08:25 mlflow/tracking/default_experiment/databricks_job_experiment_provider.py
--rw-r--r--  2.0 unx     2300 b- defN 23-Apr-28 08:25 mlflow/tracking/default_experiment/databricks_notebook_experiment_provider.py
--rw-r--r--  2.0 unx     3173 b- defN 23-Apr-28 08:25 mlflow/tracking/default_experiment/registry.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/tracking/request_header/__init__.py
--rw-r--r--  2.0 unx     1077 b- defN 23-Apr-28 08:25 mlflow/tracking/request_header/abstract_request_header_provider.py
--rw-r--r--  2.0 unx     1336 b- defN 23-Apr-28 08:25 mlflow/tracking/request_header/databricks_request_header_provider.py
--rw-r--r--  2.0 unx      486 b- defN 23-Apr-28 08:25 mlflow/tracking/request_header/default_request_header_provider.py
--rw-r--r--  2.0 unx     2867 b- defN 23-Apr-28 08:25 mlflow/tracking/request_header/registry.py
--rw-r--r--  2.0 unx      299 b- defN 23-Apr-28 08:25 mlflow/types/__init__.py
--rw-r--r--  2.0 unx    13334 b- defN 23-Apr-28 08:25 mlflow/types/schema.py
--rw-r--r--  2.0 unx    17899 b- defN 23-Apr-28 08:25 mlflow/types/utils.py
--rw-r--r--  2.0 unx     9389 b- defN 23-Apr-28 08:25 mlflow/utils/__init__.py
--rw-r--r--  2.0 unx     6270 b- defN 23-Apr-28 08:25 mlflow/utils/_capture_modules.py
--rw-r--r--  2.0 unx     6395 b- defN 23-Apr-28 08:25 mlflow/utils/_spark_utils.py
--rw-r--r--  2.0 unx     4906 b- defN 23-Apr-28 08:25 mlflow/utils/annotations.py
--rw-r--r--  2.0 unx      400 b- defN 23-Apr-28 08:25 mlflow/utils/arguments_utils.py
--rw-r--r--  2.0 unx      215 b- defN 23-Apr-28 08:25 mlflow/utils/class_utils.py
--rw-r--r--  2.0 unx     6431 b- defN 23-Apr-28 08:25 mlflow/utils/cli_args.py
--rw-r--r--  2.0 unx    13002 b- defN 23-Apr-28 08:25 mlflow/utils/conda.py
--rw-r--r--  2.0 unx      432 b- defN 23-Apr-28 08:25 mlflow/utils/data_utils.py
--rw-r--r--  2.0 unx    21834 b- defN 23-Apr-28 08:25 mlflow/utils/databricks_utils.py
--rw-r--r--  2.0 unx     9138 b- defN 23-Apr-28 08:25 mlflow/utils/docstring_utils.py
--rw-r--r--  2.0 unx      192 b- defN 23-Apr-28 08:25 mlflow/utils/env.py
--rw-r--r--  2.0 unx      474 b- defN 23-Apr-28 08:25 mlflow/utils/env_manager.py
--rw-r--r--  2.0 unx    21930 b- defN 23-Apr-28 08:25 mlflow/utils/environment.py
--rw-r--r--  2.0 unx    25967 b- defN 23-Apr-28 08:25 mlflow/utils/file_utils.py
--rw-r--r--  2.0 unx     2306 b- defN 23-Apr-28 08:25 mlflow/utils/git_utils.py
--rw-r--r--  2.0 unx    24166 b- defN 23-Apr-28 08:25 mlflow/utils/gorilla.py
--rw-r--r--  2.0 unx     2597 b- defN 23-Apr-28 08:25 mlflow/utils/logging_utils.py
--rw-r--r--  2.0 unx     1298 b- defN 23-Apr-28 08:25 mlflow/utils/mime_type_utils.py
--rw-r--r--  2.0 unx     3839 b- defN 23-Apr-28 08:25 mlflow/utils/mlflow_tags.py
--rw-r--r--  2.0 unx     6208 b- defN 23-Apr-28 08:25 mlflow/utils/model_utils.py
--rw-r--r--  2.0 unx     5873 b- defN 23-Apr-28 08:25 mlflow/utils/name_utils.py
--rw-r--r--  2.0 unx     2412 b- defN 23-Apr-28 08:25 mlflow/utils/nfs_on_spark.py
--rw-r--r--  2.0 unx      139 b- defN 23-Apr-28 08:25 mlflow/utils/os.py
--rw-r--r--  2.0 unx     5799 b- defN 23-Apr-28 08:25 mlflow/utils/process.py
--rw-r--r--  2.0 unx    19923 b- defN 23-Apr-28 08:25 mlflow/utils/proto_json_utils.py
--rw-r--r--  2.0 unx    18470 b- defN 23-Apr-28 08:25 mlflow/utils/requirements_utils.py
--rw-r--r--  2.0 unx    16880 b- defN 23-Apr-28 08:25 mlflow/utils/rest_utils.py
--rw-r--r--  2.0 unx    56769 b- defN 23-Apr-28 08:25 mlflow/utils/search_utils.py
--rw-r--r--  2.0 unx     2368 b- defN 23-Apr-28 08:25 mlflow/utils/server_cli_utils.py
--rw-r--r--  2.0 unx     3805 b- defN 23-Apr-28 08:25 mlflow/utils/string_utils.py
--rw-r--r--  2.0 unx      512 b- defN 23-Apr-28 08:25 mlflow/utils/time_utils.py
--rw-r--r--  2.0 unx    13915 b- defN 23-Apr-28 08:25 mlflow/utils/uri.py
--rw-r--r--  2.0 unx    16024 b- defN 23-Apr-28 08:25 mlflow/utils/validation.py
--rw-r--r--  2.0 unx    16452 b- defN 23-Apr-28 08:25 mlflow/utils/virtualenv.py
--rw-r--r--  2.0 unx    25551 b- defN 23-Apr-28 08:25 mlflow/utils/autologging_utils/__init__.py
--rw-r--r--  2.0 unx    15731 b- defN 23-Apr-28 08:25 mlflow/utils/autologging_utils/client.py
--rw-r--r--  2.0 unx    10937 b- defN 23-Apr-28 08:25 mlflow/utils/autologging_utils/events.py
--rw-r--r--  2.0 unx    13381 b- defN 23-Apr-28 08:25 mlflow/utils/autologging_utils/logging_and_warnings.py
--rw-r--r--  2.0 unx    47266 b- defN 23-Apr-28 08:25 mlflow/utils/autologging_utils/safety.py
--rw-r--r--  2.0 unx     3489 b- defN 23-Apr-28 08:25 mlflow/utils/autologging_utils/versioning.py
--rw-r--r--  2.0 unx    13489 b- defN 23-Apr-28 08:25 mlflow/utils/import_hooks/__init__.py
--rw-r--r--  2.0 unx    34313 b- defN 23-Apr-28 08:25 mlflow/xgboost/__init__.py
--rw-r--r--  2.0 unx     2908 b- defN 23-Apr-28 08:25 mlflow/xgboost/_autolog.py
--rw-r--r--  2.0 unx      521 b- defN 23-Apr-28 08:25 pylint_plugins/__init__.py
--rw-r--r--  2.0 unx     2006 b- defN 23-Apr-28 08:25 pylint_plugins/errors.py
--rw-r--r--  2.0 unx      856 b- defN 23-Apr-28 08:25 pylint_plugins/print_function.py
--rw-r--r--  2.0 unx      571 b- defN 23-Apr-28 08:25 pylint_plugins/set_checker.py
--rw-r--r--  2.0 unx      878 b- defN 23-Apr-28 08:25 pylint_plugins/string_checker.py
--rw-r--r--  2.0 unx      692 b- defN 23-Apr-28 08:25 pylint_plugins/unittest_assert_raises.py
--rw-r--r--  2.0 unx     1546 b- defN 23-Apr-28 08:25 pylint_plugins/pytest_raises_checker/__init__.py
--rw-r--r--  2.0 unx    11382 b- defN 23-Apr-28 08:25 mlflow_skinny-2.3.1.dist-info/LICENSE.txt
--rw-r--r--  2.0 unx    12392 b- defN 23-Apr-28 08:25 mlflow_skinny-2.3.1.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Apr-28 08:25 mlflow_skinny-2.3.1.dist-info/WHEEL
--rw-r--r--  2.0 unx       92 b- defN 23-Apr-28 08:25 mlflow_skinny-2.3.1.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       22 b- defN 23-Apr-28 08:25 mlflow_skinny-2.3.1.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    32890 b- defN 23-Apr-28 08:25 mlflow_skinny-2.3.1.dist-info/RECORD
-352 files, 10959534 bytes uncompressed, 4021384 bytes compressed:  63.3%
+Zip file size: 4084510 bytes, number of entries: 354
+-rw-r--r--  2.0 unx     6155 b- defN 23-May-12 23:50 mlflow/__init__.py
+-rw-r--r--  2.0 unx       39 b- defN 23-May-12 23:50 mlflow/__main__.py
+-rw-r--r--  2.0 unx     3668 b- defN 23-May-12 23:50 mlflow/_doctor.py
+-rw-r--r--  2.0 unx     9428 b- defN 23-May-12 23:50 mlflow/_spark_autologging.py
+-rw-r--r--  2.0 unx    15140 b- defN 23-May-12 23:50 mlflow/catboost.py
+-rw-r--r--  2.0 unx    23356 b- defN 23-May-12 23:50 mlflow/cli.py
+-rw-r--r--  2.0 unx      407 b- defN 23-May-12 23:50 mlflow/client.py
+-rw-r--r--  2.0 unx      881 b- defN 23-May-12 23:50 mlflow/db.py
+-rw-r--r--  2.0 unx    28178 b- defN 23-May-12 23:50 mlflow/diviner.py
+-rw-r--r--  2.0 unx    10178 b- defN 23-May-12 23:50 mlflow/environment_variables.py
+-rw-r--r--  2.0 unx     4881 b- defN 23-May-12 23:50 mlflow/exceptions.py
+-rw-r--r--  2.0 unx     5080 b- defN 23-May-12 23:50 mlflow/experiments.py
+-rw-r--r--  2.0 unx    14185 b- defN 23-May-12 23:50 mlflow/h2o.py
+-rw-r--r--  2.0 unx      311 b- defN 23-May-12 23:50 mlflow/keras.py
+-rw-r--r--  2.0 unx    35902 b- defN 23-May-12 23:50 mlflow/lightgbm.py
+-rw-r--r--  2.0 unx      180 b- defN 23-May-12 23:50 mlflow/llm.py
+-rw-r--r--  2.0 unx     5575 b- defN 23-May-12 23:50 mlflow/ml_package_versions.py
+-rw-r--r--  2.0 unx    13885 b- defN 23-May-12 23:50 mlflow/mleap.py
+-rw-r--r--  2.0 unx    21826 b- defN 23-May-12 23:50 mlflow/onnx.py
+-rw-r--r--  2.0 unx    17616 b- defN 23-May-12 23:50 mlflow/pmdarima.py
+-rw-r--r--  2.0 unx    14024 b- defN 23-May-12 23:50 mlflow/prophet.py
+-rw-r--r--  2.0 unx  7197781 b- defN 23-May-12 23:50 mlflow/pypi_package_index.json
+-rw-r--r--  2.0 unx     2519 b- defN 23-May-12 23:50 mlflow/runs.py
+-rw-r--r--  2.0 unx    26647 b- defN 23-May-12 23:50 mlflow/shap.py
+-rw-r--r--  2.0 unx    14259 b- defN 23-May-12 23:50 mlflow/spacy.py
+-rw-r--r--  2.0 unx    44813 b- defN 23-May-12 23:50 mlflow/spark.py
+-rw-r--r--  2.0 unx    24596 b- defN 23-May-12 23:50 mlflow/statsmodels.py
+-rw-r--r--  2.0 unx    96409 b- defN 23-May-12 23:50 mlflow/transformers.py
+-rw-r--r--  2.0 unx      147 b- defN 23-May-12 23:50 mlflow/version.py
+-rw-r--r--  2.0 unx     6485 b- defN 23-May-12 23:50 mlflow/artifacts/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-12 23:50 mlflow/azure/__init__.py
+-rw-r--r--  2.0 unx    11647 b- defN 23-May-12 23:50 mlflow/azure/client.py
+-rw-r--r--  2.0 unx     3797 b- defN 23-May-12 23:50 mlflow/deployments/__init__.py
+-rw-r--r--  2.0 unx    15572 b- defN 23-May-12 23:50 mlflow/deployments/base.py
+-rw-r--r--  2.0 unx    15078 b- defN 23-May-12 23:50 mlflow/deployments/cli.py
+-rw-r--r--  2.0 unx     3825 b- defN 23-May-12 23:50 mlflow/deployments/interface.py
+-rw-r--r--  2.0 unx     5512 b- defN 23-May-12 23:50 mlflow/deployments/plugin_manager.py
+-rw-r--r--  2.0 unx      556 b- defN 23-May-12 23:50 mlflow/deployments/utils.py
+-rw-r--r--  2.0 unx      948 b- defN 23-May-12 23:50 mlflow/entities/__init__.py
+-rw-r--r--  2.0 unx     1414 b- defN 23-May-12 23:50 mlflow/entities/_mlflow_object.py
+-rw-r--r--  2.0 unx     3510 b- defN 23-May-12 23:50 mlflow/entities/experiment.py
+-rw-r--r--  2.0 unx      887 b- defN 23-May-12 23:50 mlflow/entities/experiment_tag.py
+-rw-r--r--  2.0 unx     1215 b- defN 23-May-12 23:50 mlflow/entities/file_info.py
+-rw-r--r--  2.0 unx     1242 b- defN 23-May-12 23:50 mlflow/entities/lifecycle_stage.py
+-rw-r--r--  2.0 unx     1418 b- defN 23-May-12 23:50 mlflow/entities/metric.py
+-rw-r--r--  2.0 unx     1133 b- defN 23-May-12 23:50 mlflow/entities/param.py
+-rw-r--r--  2.0 unx     1438 b- defN 23-May-12 23:50 mlflow/entities/run.py
+-rw-r--r--  2.0 unx     3032 b- defN 23-May-12 23:50 mlflow/entities/run_data.py
+-rw-r--r--  2.0 unx     6182 b- defN 23-May-12 23:50 mlflow/entities/run_info.py
+-rw-r--r--  2.0 unx     1550 b- defN 23-May-12 23:50 mlflow/entities/run_status.py
+-rw-r--r--  2.0 unx      890 b- defN 23-May-12 23:50 mlflow/entities/run_tag.py
+-rw-r--r--  2.0 unx     1212 b- defN 23-May-12 23:50 mlflow/entities/source_type.py
+-rw-r--r--  2.0 unx     1826 b- defN 23-May-12 23:50 mlflow/entities/view_type.py
+-rw-r--r--  2.0 unx      529 b- defN 23-May-12 23:50 mlflow/entities/model_registry/__init__.py
+-rw-r--r--  2.0 unx      286 b- defN 23-May-12 23:50 mlflow/entities/model_registry/_model_registry_entity.py
+-rw-r--r--  2.0 unx     6435 b- defN 23-May-12 23:50 mlflow/entities/model_registry/model_version.py
+-rw-r--r--  2.0 unx      831 b- defN 23-May-12 23:50 mlflow/entities/model_registry/model_version_stages.py
+-rw-r--r--  2.0 unx     1533 b- defN 23-May-12 23:50 mlflow/entities/model_registry/model_version_status.py
+-rw-r--r--  2.0 unx      933 b- defN 23-May-12 23:50 mlflow/entities/model_registry/model_version_tag.py
+-rw-r--r--  2.0 unx     4933 b- defN 23-May-12 23:50 mlflow/entities/model_registry/registered_model.py
+-rw-r--r--  2.0 unx     1053 b- defN 23-May-12 23:50 mlflow/entities/model_registry/registered_model_alias.py
+-rw-r--r--  2.0 unx      948 b- defN 23-May-12 23:50 mlflow/entities/model_registry/registered_model_tag.py
+-rw-r--r--  2.0 unx    25354 b- defN 23-May-12 23:50 mlflow/fastai/__init__.py
+-rw-r--r--  2.0 unx     5757 b- defN 23-May-12 23:50 mlflow/fastai/callback.py
+-rw-r--r--  2.0 unx    19063 b- defN 23-May-12 23:50 mlflow/gluon/__init__.py
+-rw-r--r--  2.0 unx     2020 b- defN 23-May-12 23:50 mlflow/gluon/_autolog.py
+-rw-r--r--  2.0 unx    16643 b- defN 23-May-12 23:50 mlflow/langchain/__init__.py
+-rw-r--r--  2.0 unx     4846 b- defN 23-May-12 23:50 mlflow/langchain/api_request_parallel_processor.py
+-rw-r--r--  2.0 unx     3627 b- defN 23-May-12 23:50 mlflow/models/__init__.py
+-rw-r--r--  2.0 unx     9803 b- defN 23-May-12 23:50 mlflow/models/cli.py
+-rw-r--r--  2.0 unx     9853 b- defN 23-May-12 23:50 mlflow/models/docker_utils.py
+-rw-r--r--  2.0 unx     3420 b- defN 23-May-12 23:50 mlflow/models/flavor_backend.py
+-rw-r--r--  2.0 unx     2354 b- defN 23-May-12 23:50 mlflow/models/flavor_backend_registry.py
+-rw-r--r--  2.0 unx    24148 b- defN 23-May-12 23:50 mlflow/models/model.py
+-rw-r--r--  2.0 unx     8634 b- defN 23-May-12 23:50 mlflow/models/signature.py
+-rw-r--r--  2.0 unx    38161 b- defN 23-May-12 23:50 mlflow/models/utils.py
+-rw-r--r--  2.0 unx    11707 b- defN 23-May-12 23:50 mlflow/models/wheeled_model.py
+-rw-r--r--  2.0 unx     9387 b- defN 23-May-12 23:50 mlflow/models/container/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-12 23:50 mlflow/models/container/scoring_server/__init__.py
+-rw-r--r--  2.0 unx      131 b- defN 23-May-12 23:50 mlflow/models/container/scoring_server/wsgi.py
+-rw-r--r--  2.0 unx      491 b- defN 23-May-12 23:50 mlflow/models/evaluation/__init__.py
+-rw-r--r--  2.0 unx     3105 b- defN 23-May-12 23:50 mlflow/models/evaluation/_shap_patch.py
+-rw-r--r--  2.0 unx     6769 b- defN 23-May-12 23:50 mlflow/models/evaluation/artifacts.py
+-rw-r--r--  2.0 unx    59488 b- defN 23-May-12 23:50 mlflow/models/evaluation/base.py
+-rw-r--r--  2.0 unx    50976 b- defN 23-May-12 23:50 mlflow/models/evaluation/default_evaluator.py
+-rw-r--r--  2.0 unx     2036 b- defN 23-May-12 23:50 mlflow/models/evaluation/evaluator_registry.py
+-rw-r--r--  2.0 unx     6223 b- defN 23-May-12 23:50 mlflow/models/evaluation/lift_curve.py
+-rw-r--r--  2.0 unx    10946 b- defN 23-May-12 23:50 mlflow/models/evaluation/validation.py
+-rw-r--r--  2.0 unx    23265 b- defN 23-May-12 23:50 mlflow/openai/__init__.py
+-rw-r--r--  2.0 unx    12309 b- defN 23-May-12 23:50 mlflow/openai/api_request_parallel_processor.py
+-rw-r--r--  2.0 unx     2936 b- defN 23-May-12 23:50 mlflow/openai/retry.py
+-rw-r--r--  2.0 unx     2040 b- defN 23-May-12 23:50 mlflow/openai/utils.py
+-rw-r--r--  2.0 unx    23859 b- defN 23-May-12 23:50 mlflow/paddle/__init__.py
+-rw-r--r--  2.0 unx     4792 b- defN 23-May-12 23:50 mlflow/paddle/_paddle_autolog.py
+-rw-r--r--  2.0 unx    17396 b- defN 23-May-12 23:50 mlflow/projects/__init__.py
+-rw-r--r--  2.0 unx    11532 b- defN 23-May-12 23:50 mlflow/projects/_project_spec.py
+-rw-r--r--  2.0 unx    20270 b- defN 23-May-12 23:50 mlflow/projects/databricks.py
+-rw-r--r--  2.0 unx     6394 b- defN 23-May-12 23:50 mlflow/projects/docker.py
+-rw-r--r--  2.0 unx       94 b- defN 23-May-12 23:50 mlflow/projects/env_type.py
+-rw-r--r--  2.0 unx     6379 b- defN 23-May-12 23:50 mlflow/projects/kubernetes.py
+-rw-r--r--  2.0 unx     3574 b- defN 23-May-12 23:50 mlflow/projects/submitted_run.py
+-rw-r--r--  2.0 unx    13432 b- defN 23-May-12 23:50 mlflow/projects/utils.py
+-rw-r--r--  2.0 unx      271 b- defN 23-May-12 23:50 mlflow/projects/backend/__init__.py
+-rw-r--r--  2.0 unx     2210 b- defN 23-May-12 23:50 mlflow/projects/backend/abstract_backend.py
+-rw-r--r--  2.0 unx     1079 b- defN 23-May-12 23:50 mlflow/projects/backend/loader.py
+-rw-r--r--  2.0 unx    17240 b- defN 23-May-12 23:50 mlflow/projects/backend/local.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-12 23:50 mlflow/protos/__init__.py
+-rw-r--r--  2.0 unx    17261 b- defN 23-May-12 23:50 mlflow/protos/databricks_artifacts_pb2.py
+-rw-r--r--  2.0 unx    14095 b- defN 23-May-12 23:50 mlflow/protos/databricks_pb2.py
+-rw-r--r--  2.0 unx    39471 b- defN 23-May-12 23:50 mlflow/protos/databricks_uc_registry_messages_pb2.py
+-rw-r--r--  2.0 unx    12471 b- defN 23-May-12 23:50 mlflow/protos/databricks_uc_registry_service_pb2.py
+-rw-r--r--  2.0 unx    16146 b- defN 23-May-12 23:50 mlflow/protos/facet_feature_statistics_pb2.py
+-rw-r--r--  2.0 unx     8552 b- defN 23-May-12 23:50 mlflow/protos/mlflow_artifacts_pb2.py
+-rw-r--r--  2.0 unx    54475 b- defN 23-May-12 23:50 mlflow/protos/model_registry_pb2.py
+-rw-r--r--  2.0 unx    48593 b- defN 23-May-12 23:50 mlflow/protos/service_pb2.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-12 23:50 mlflow/protos/scalapb/__init__.py
+-rw-r--r--  2.0 unx     3307 b- defN 23-May-12 23:50 mlflow/protos/scalapb/scalapb_pb2.py
+-rw-r--r--  2.0 unx    81392 b- defN 23-May-12 23:50 mlflow/pyfunc/__init__.py
+-rw-r--r--  2.0 unx    16640 b- defN 23-May-12 23:50 mlflow/pyfunc/backend.py
+-rw-r--r--  2.0 unx      901 b- defN 23-May-12 23:50 mlflow/pyfunc/mlserver.py
+-rw-r--r--  2.0 unx    15392 b- defN 23-May-12 23:50 mlflow/pyfunc/model.py
+-rw-r--r--  2.0 unx     2124 b- defN 23-May-12 23:50 mlflow/pyfunc/spark_model_cache.py
+-rw-r--r--  2.0 unx     1001 b- defN 23-May-12 23:50 mlflow/pyfunc/stdin_server.py
+-rw-r--r--  2.0 unx    13910 b- defN 23-May-12 23:50 mlflow/pyfunc/scoring_server/__init__.py
+-rw-r--r--  2.0 unx     4222 b- defN 23-May-12 23:50 mlflow/pyfunc/scoring_server/client.py
+-rw-r--r--  2.0 unx      175 b- defN 23-May-12 23:50 mlflow/pyfunc/scoring_server/wsgi.py
+-rw-r--r--  2.0 unx       50 b- defN 23-May-12 23:50 mlflow/pyspark/__init__.py
+-rw-r--r--  2.0 unx    53458 b- defN 23-May-12 23:50 mlflow/pyspark/ml/__init__.py
+-rw-r--r--  2.0 unx     2908 b- defN 23-May-12 23:50 mlflow/pyspark/ml/_autolog.py
+-rw-r--r--  2.0 unx     1886 b- defN 23-May-12 23:50 mlflow/pyspark/ml/log_model_allowlist.txt
+-rw-r--r--  2.0 unx    45379 b- defN 23-May-12 23:50 mlflow/pytorch/__init__.py
+-rw-r--r--  2.0 unx    17629 b- defN 23-May-12 23:50 mlflow/pytorch/_lightning_autolog.py
+-rw-r--r--  2.0 unx     2654 b- defN 23-May-12 23:50 mlflow/pytorch/_pytorch_autolog.py
+-rw-r--r--  2.0 unx     2090 b- defN 23-May-12 23:50 mlflow/pytorch/pickle_module.py
+-rw-r--r--  2.0 unx     1330 b- defN 23-May-12 23:50 mlflow/recipes/__init__.py
+-rw-r--r--  2.0 unx     6092 b- defN 23-May-12 23:50 mlflow/recipes/artifacts.py
+-rw-r--r--  2.0 unx     2917 b- defN 23-May-12 23:50 mlflow/recipes/cli.py
+-rw-r--r--  2.0 unx    18431 b- defN 23-May-12 23:50 mlflow/recipes/dag_help_strings.py
+-rw-r--r--  2.0 unx    17933 b- defN 23-May-12 23:50 mlflow/recipes/recipe.py
+-rw-r--r--  2.0 unx    14988 b- defN 23-May-12 23:50 mlflow/recipes/step.py
+-rw-r--r--  2.0 unx    10229 b- defN 23-May-12 23:50 mlflow/recipes/cards/__init__.py
+-rw-r--r--  2.0 unx     4780 b- defN 23-May-12 23:50 mlflow/recipes/cards/histogram_generator.py
+-rw-r--r--  2.0 unx    12548 b- defN 23-May-12 23:50 mlflow/recipes/cards/pandas_renderer.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-12 23:50 mlflow/recipes/cards/templates/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-12 23:50 mlflow/recipes/classification/__init__.py
+-rw-r--r--  2.0 unx      122 b- defN 23-May-12 23:50 mlflow/recipes/classification/v1/__init__.py
+-rw-r--r--  2.0 unx    20462 b- defN 23-May-12 23:50 mlflow/recipes/classification/v1/recipe.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-12 23:50 mlflow/recipes/regression/__init__.py
+-rw-r--r--  2.0 unx      114 b- defN 23-May-12 23:50 mlflow/recipes/regression/v1/__init__.py
+-rw-r--r--  2.0 unx    22495 b- defN 23-May-12 23:50 mlflow/recipes/regression/v1/recipe.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-12 23:50 mlflow/recipes/steps/__init__.py
+-rw-r--r--  2.0 unx    20717 b- defN 23-May-12 23:50 mlflow/recipes/steps/evaluate.py
+-rw-r--r--  2.0 unx    12132 b- defN 23-May-12 23:50 mlflow/recipes/steps/predict.py
+-rw-r--r--  2.0 unx     7680 b- defN 23-May-12 23:50 mlflow/recipes/steps/register.py
+-rw-r--r--  2.0 unx    19541 b- defN 23-May-12 23:50 mlflow/recipes/steps/split.py
+-rw-r--r--  2.0 unx    59789 b- defN 23-May-12 23:50 mlflow/recipes/steps/train.py
+-rw-r--r--  2.0 unx    10602 b- defN 23-May-12 23:50 mlflow/recipes/steps/transform.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-12 23:50 mlflow/recipes/steps/automl/__init__.py
+-rw-r--r--  2.0 unx     6269 b- defN 23-May-12 23:50 mlflow/recipes/steps/automl/flaml.py
+-rw-r--r--  2.0 unx    11137 b- defN 23-May-12 23:50 mlflow/recipes/steps/ingest/__init__.py
+-rw-r--r--  2.0 unx    26446 b- defN 23-May-12 23:50 mlflow/recipes/steps/ingest/datasets.py
+-rw-r--r--  2.0 unx     6355 b- defN 23-May-12 23:50 mlflow/recipes/utils/__init__.py
+-rw-r--r--  2.0 unx    28468 b- defN 23-May-12 23:50 mlflow/recipes/utils/execution.py
+-rw-r--r--  2.0 unx     8990 b- defN 23-May-12 23:50 mlflow/recipes/utils/metrics.py
+-rw-r--r--  2.0 unx     7392 b- defN 23-May-12 23:50 mlflow/recipes/utils/step.py
+-rw-r--r--  2.0 unx    12375 b- defN 23-May-12 23:50 mlflow/recipes/utils/tracking.py
+-rw-r--r--  2.0 unx     1748 b- defN 23-May-12 23:50 mlflow/recipes/utils/wrapped_recipe_model.py
+-rw-r--r--  2.0 unx     1115 b- defN 23-May-12 23:50 mlflow/rfunc/__init__.py
+-rw-r--r--  2.0 unx     3643 b- defN 23-May-12 23:50 mlflow/rfunc/backend.py
+-rw-r--r--  2.0 unx   135097 b- defN 23-May-12 23:50 mlflow/sagemaker/__init__.py
+-rw-r--r--  2.0 unx    12986 b- defN 23-May-12 23:50 mlflow/sagemaker/cli.py
+-rw-r--r--  2.0 unx     6460 b- defN 23-May-12 23:50 mlflow/server/__init__.py
+-rw-r--r--  2.0 unx    68605 b- defN 23-May-12 23:50 mlflow/server/handlers.py
+-rw-r--r--  2.0 unx      481 b- defN 23-May-12 23:50 mlflow/server/prometheus_exporter.py
+-rw-r--r--  2.0 unx    24354 b- defN 23-May-12 23:50 mlflow/server/auth/__init__.py
+-rw-r--r--  2.0 unx      575 b- defN 23-May-12 23:50 mlflow/server/auth/config.py
+-rw-r--r--  2.0 unx     3171 b- defN 23-May-12 23:50 mlflow/server/auth/entities.py
+-rw-r--r--  2.0 unx     2673 b- defN 23-May-12 23:50 mlflow/server/auth/logo.py
+-rw-r--r--  2.0 unx     1267 b- defN 23-May-12 23:50 mlflow/server/auth/permissions.py
+-rw-r--r--  2.0 unx    12648 b- defN 23-May-12 23:50 mlflow/server/auth/sqlalchemy_store.py
+-rw-r--r--  2.0 unx    82319 b- defN 23-May-12 23:50 mlflow/sklearn/__init__.py
+-rw-r--r--  2.0 unx    37485 b- defN 23-May-12 23:50 mlflow/sklearn/utils.py
+-rw-r--r--  2.0 unx      227 b- defN 23-May-12 23:50 mlflow/store/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-12 23:50 mlflow/store/_unity_catalog/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-12 23:50 mlflow/store/_unity_catalog/registry/__init__.py
+-rw-r--r--  2.0 unx    27183 b- defN 23-May-12 23:50 mlflow/store/_unity_catalog/registry/rest_store.py
+-rw-r--r--  2.0 unx     5419 b- defN 23-May-12 23:50 mlflow/store/_unity_catalog/registry/utils.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-12 23:50 mlflow/store/artifact/__init__.py
+-rw-r--r--  2.0 unx    15034 b- defN 23-May-12 23:50 mlflow/store/artifact/artifact_repo.py
+-rw-r--r--  2.0 unx     5309 b- defN 23-May-12 23:50 mlflow/store/artifact/artifact_repository_registry.py
+-rw-r--r--  2.0 unx     8136 b- defN 23-May-12 23:50 mlflow/store/artifact/azure_blob_artifact_repo.py
+-rw-r--r--  2.0 unx     5829 b- defN 23-May-12 23:50 mlflow/store/artifact/azure_data_lake_artifact_repo.py
+-rw-r--r--  2.0 unx     5378 b- defN 23-May-12 23:50 mlflow/store/artifact/cli.py
+-rw-r--r--  2.0 unx    31773 b- defN 23-May-12 23:50 mlflow/store/artifact/databricks_artifact_repo.py
+-rw-r--r--  2.0 unx     6654 b- defN 23-May-12 23:50 mlflow/store/artifact/databricks_models_artifact_repo.py
+-rw-r--r--  2.0 unx    10247 b- defN 23-May-12 23:50 mlflow/store/artifact/dbfs_artifact_repo.py
+-rw-r--r--  2.0 unx     5234 b- defN 23-May-12 23:50 mlflow/store/artifact/ftp_artifact_repo.py
+-rw-r--r--  2.0 unx     5873 b- defN 23-May-12 23:50 mlflow/store/artifact/gcs_artifact_repo.py
+-rw-r--r--  2.0 unx     9684 b- defN 23-May-12 23:50 mlflow/store/artifact/hdfs_artifact_repo.py
+-rw-r--r--  2.0 unx     3377 b- defN 23-May-12 23:50 mlflow/store/artifact/http_artifact_repo.py
+-rw-r--r--  2.0 unx     5085 b- defN 23-May-12 23:50 mlflow/store/artifact/local_artifact_repo.py
+-rw-r--r--  2.0 unx     3001 b- defN 23-May-12 23:50 mlflow/store/artifact/mlflow_artifacts_repo.py
+-rw-r--r--  2.0 unx     6757 b- defN 23-May-12 23:50 mlflow/store/artifact/models_artifact_repo.py
+-rw-r--r--  2.0 unx     6016 b- defN 23-May-12 23:50 mlflow/store/artifact/runs_artifact_repo.py
+-rw-r--r--  2.0 unx     9442 b- defN 23-May-12 23:50 mlflow/store/artifact/s3_artifact_repo.py
+-rw-r--r--  2.0 unx     5455 b- defN 23-May-12 23:50 mlflow/store/artifact/sftp_artifact_repo.py
+-rw-r--r--  2.0 unx     5592 b- defN 23-May-12 23:50 mlflow/store/artifact/unity_catalog_models_artifact_repo.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-12 23:50 mlflow/store/artifact/utils/__init__.py
+-rw-r--r--  2.0 unx     3934 b- defN 23-May-12 23:50 mlflow/store/artifact/utils/models.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-12 23:50 mlflow/store/db/__init__.py
+-rw-r--r--  2.0 unx       71 b- defN 23-May-12 23:50 mlflow/store/db/base_sql_model.py
+-rw-r--r--  2.0 unx      221 b- defN 23-May-12 23:50 mlflow/store/db/db_types.py
+-rw-r--r--  2.0 unx    10592 b- defN 23-May-12 23:50 mlflow/store/db/utils.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-12 23:50 mlflow/store/db_migrations/__init__.py
+-rw-r--r--  2.0 unx     1634 b- defN 23-May-12 23:50 mlflow/store/db_migrations/alembic.ini
+-rw-r--r--  2.0 unx     2768 b- defN 23-May-12 23:50 mlflow/store/db_migrations/env.py
+-rw-r--r--  2.0 unx     1990 b- defN 23-May-12 23:50 mlflow/store/db_migrations/versions/0a8213491aaa_drop_duplicate_killed_constraint.py
+-rw-r--r--  2.0 unx      462 b- defN 23-May-12 23:50 mlflow/store/db_migrations/versions/0c779009ac13_add_deleted_time_field_to_runs_table.py
+-rw-r--r--  2.0 unx      924 b- defN 23-May-12 23:50 mlflow/store/db_migrations/versions/181f10493468_allow_nulls_for_metric_values.py
+-rw-r--r--  2.0 unx     1059 b- defN 23-May-12 23:50 mlflow/store/db_migrations/versions/27a6a02d2cf1_add_model_version_tags_table.py
+-rw-r--r--  2.0 unx     2624 b- defN 23-May-12 23:50 mlflow/store/db_migrations/versions/2b4d017a5e9b_add_model_registry_tables_to_db.py
+-rw-r--r--  2.0 unx     1375 b- defN 23-May-12 23:50 mlflow/store/db_migrations/versions/3500859a5d39_add_model_aliases_table.py
+-rw-r--r--  2.0 unx     1433 b- defN 23-May-12 23:50 mlflow/store/db_migrations/versions/39d1c3be5f05_add_is_nan_constraint_for_metrics_tables_if_necessary.py
+-rw-r--r--  2.0 unx     1201 b- defN 23-May-12 23:50 mlflow/store/db_migrations/versions/451aebb31d03_add_metric_step.py
+-rw-r--r--  2.0 unx      940 b- defN 23-May-12 23:50 mlflow/store/db_migrations/versions/728d730b5ebd_add_registered_model_tags_table.py
+-rw-r--r--  2.0 unx     1014 b- defN 23-May-12 23:50 mlflow/store/db_migrations/versions/7ac759974ad8_update_run_tags_with_larger_limit.py
+-rw-r--r--  2.0 unx      476 b- defN 23-May-12 23:50 mlflow/store/db_migrations/versions/84291f40a231_add_run_link_to_model_version.py
+-rw-r--r--  2.0 unx     5716 b- defN 23-May-12 23:50 mlflow/store/db_migrations/versions/89d4b8295536_create_latest_metrics_table.py
+-rw-r--r--  2.0 unx     1666 b- defN 23-May-12 23:50 mlflow/store/db_migrations/versions/90e64c465722_migrate_user_column_to_tags.py
+-rw-r--r--  2.0 unx      577 b- defN 23-May-12 23:50 mlflow/store/db_migrations/versions/97727af70f4d_creation_time_last_update_time_experiments.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-12 23:50 mlflow/store/db_migrations/versions/__init__.py
+-rw-r--r--  2.0 unx      582 b- defN 23-May-12 23:50 mlflow/store/db_migrations/versions/a8c4a736bde6_allow_nulls_for_run_id.py
+-rw-r--r--  2.0 unx      637 b- defN 23-May-12 23:50 mlflow/store/db_migrations/versions/bd07f7e963c5_create_index_on_run_uuid.py
+-rw-r--r--  2.0 unx     1295 b- defN 23-May-12 23:50 mlflow/store/db_migrations/versions/c48cb773bb87_reset_default_value_for_is_nan_in_metrics_table_for_mysql.py
+-rw-r--r--  2.0 unx      684 b- defN 23-May-12 23:50 mlflow/store/db_migrations/versions/cc1f77228345_change_param_value_length_to_500.py
+-rw-r--r--  2.0 unx     2830 b- defN 23-May-12 23:50 mlflow/store/db_migrations/versions/cfd24bdc0731_update_run_status_constraint_with_killed.py
+-rw-r--r--  2.0 unx      904 b- defN 23-May-12 23:50 mlflow/store/db_migrations/versions/df50e92ffc5e_add_experiment_tags_table.py
+-rw-r--r--  2.0 unx       80 b- defN 23-May-12 23:50 mlflow/store/entities/__init__.py
+-rw-r--r--  2.0 unx      479 b- defN 23-May-12 23:50 mlflow/store/entities/paged_list.py
+-rw-r--r--  2.0 unx      605 b- defN 23-May-12 23:50 mlflow/store/model_registry/__init__.py
+-rw-r--r--  2.0 unx    11022 b- defN 23-May-12 23:50 mlflow/store/model_registry/abstract_store.py
+-rw-r--r--  2.0 unx     1330 b- defN 23-May-12 23:50 mlflow/store/model_registry/base_rest_store.py
+-rw-r--r--  2.0 unx    38729 b- defN 23-May-12 23:50 mlflow/store/model_registry/file_store.py
+-rw-r--r--  2.0 unx    16920 b- defN 23-May-12 23:50 mlflow/store/model_registry/rest_store.py
+-rw-r--r--  2.0 unx    50457 b- defN 23-May-12 23:50 mlflow/store/model_registry/sqlalchemy_store.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-12 23:50 mlflow/store/model_registry/dbmodels/__init__.py
+-rw-r--r--  2.0 unx     6341 b- defN 23-May-12 23:50 mlflow/store/model_registry/dbmodels/models.py
+-rw-r--r--  2.0 unx     1154 b- defN 23-May-12 23:50 mlflow/store/tracking/__init__.py
+-rw-r--r--  2.0 unx    13042 b- defN 23-May-12 23:50 mlflow/store/tracking/abstract_store.py
+-rw-r--r--  2.0 unx    46363 b- defN 23-May-12 23:50 mlflow/store/tracking/file_store.py
+-rw-r--r--  2.0 unx    12172 b- defN 23-May-12 23:50 mlflow/store/tracking/rest_store.py
+-rw-r--r--  2.0 unx    67230 b- defN 23-May-12 23:50 mlflow/store/tracking/sqlalchemy_store.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-12 23:50 mlflow/store/tracking/dbmodels/__init__.py
+-rw-r--r--  2.0 unx     8315 b- defN 23-May-12 23:50 mlflow/store/tracking/dbmodels/initial_models.py
+-rw-r--r--  2.0 unx    15674 b- defN 23-May-12 23:50 mlflow/store/tracking/dbmodels/models.py
+-rw-r--r--  2.0 unx    57261 b- defN 23-May-12 23:50 mlflow/tensorflow/__init__.py
+-rw-r--r--  2.0 unx     8442 b- defN 23-May-12 23:50 mlflow/tensorflow/_autolog.py
+-rw-r--r--  2.0 unx      995 b- defN 23-May-12 23:50 mlflow/tracking/__init__.py
+-rw-r--r--  2.0 unx     7155 b- defN 23-May-12 23:50 mlflow/tracking/artifact_utils.py
+-rw-r--r--  2.0 unx   130061 b- defN 23-May-12 23:50 mlflow/tracking/client.py
+-rw-r--r--  2.0 unx    71082 b- defN 23-May-12 23:50 mlflow/tracking/fluent.py
+-rw-r--r--  2.0 unx     3404 b- defN 23-May-12 23:50 mlflow/tracking/llm_utils.py
+-rw-r--r--  2.0 unx     2248 b- defN 23-May-12 23:50 mlflow/tracking/metric_value_conversion_utils.py
+-rw-r--r--  2.0 unx     3515 b- defN 23-May-12 23:50 mlflow/tracking/registry.py
+-rw-r--r--  2.0 unx       41 b- defN 23-May-12 23:50 mlflow/tracking/_model_registry/__init__.py
+-rw-r--r--  2.0 unx    15534 b- defN 23-May-12 23:50 mlflow/tracking/_model_registry/client.py
+-rw-r--r--  2.0 unx     9641 b- defN 23-May-12 23:50 mlflow/tracking/_model_registry/fluent.py
+-rw-r--r--  2.0 unx     3152 b- defN 23-May-12 23:50 mlflow/tracking/_model_registry/registry.py
+-rw-r--r--  2.0 unx     7008 b- defN 23-May-12 23:50 mlflow/tracking/_model_registry/utils.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-12 23:50 mlflow/tracking/_tracking_service/__init__.py
+-rw-r--r--  2.0 unx    23690 b- defN 23-May-12 23:50 mlflow/tracking/_tracking_service/client.py
+-rw-r--r--  2.0 unx     2335 b- defN 23-May-12 23:50 mlflow/tracking/_tracking_service/registry.py
+-rw-r--r--  2.0 unx     9517 b- defN 23-May-12 23:50 mlflow/tracking/_tracking_service/utils.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-12 23:50 mlflow/tracking/context/__init__.py
+-rw-r--r--  2.0 unx     1076 b- defN 23-May-12 23:50 mlflow/tracking/context/abstract_context.py
+-rw-r--r--  2.0 unx      520 b- defN 23-May-12 23:50 mlflow/tracking/context/databricks_cluster_context.py
+-rw-r--r--  2.0 unx      561 b- defN 23-May-12 23:50 mlflow/tracking/context/databricks_command_context.py
+-rw-r--r--  2.0 unx     1965 b- defN 23-May-12 23:50 mlflow/tracking/context/databricks_job_context.py
+-rw-r--r--  2.0 unx     1713 b- defN 23-May-12 23:50 mlflow/tracking/context/databricks_notebook_context.py
+-rw-r--r--  2.0 unx     1952 b- defN 23-May-12 23:50 mlflow/tracking/context/databricks_repo_context.py
+-rw-r--r--  2.0 unx     1020 b- defN 23-May-12 23:50 mlflow/tracking/context/default_context.py
+-rw-r--r--  2.0 unx      898 b- defN 23-May-12 23:50 mlflow/tracking/context/git_context.py
+-rw-r--r--  2.0 unx     3738 b- defN 23-May-12 23:50 mlflow/tracking/context/registry.py
+-rw-r--r--  2.0 unx      443 b- defN 23-May-12 23:50 mlflow/tracking/context/system_environment_context.py
+-rw-r--r--  2.0 unx       28 b- defN 23-May-12 23:50 mlflow/tracking/default_experiment/__init__.py
+-rw-r--r--  2.0 unx     1703 b- defN 23-May-12 23:50 mlflow/tracking/default_experiment/abstract_context.py
+-rw-r--r--  2.0 unx     1718 b- defN 23-May-12 23:50 mlflow/tracking/default_experiment/databricks_job_experiment_provider.py
+-rw-r--r--  2.0 unx     2300 b- defN 23-May-12 23:50 mlflow/tracking/default_experiment/databricks_notebook_experiment_provider.py
+-rw-r--r--  2.0 unx     3173 b- defN 23-May-12 23:50 mlflow/tracking/default_experiment/registry.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-12 23:50 mlflow/tracking/request_header/__init__.py
+-rw-r--r--  2.0 unx     1077 b- defN 23-May-12 23:50 mlflow/tracking/request_header/abstract_request_header_provider.py
+-rw-r--r--  2.0 unx     1336 b- defN 23-May-12 23:50 mlflow/tracking/request_header/databricks_request_header_provider.py
+-rw-r--r--  2.0 unx      486 b- defN 23-May-12 23:50 mlflow/tracking/request_header/default_request_header_provider.py
+-rw-r--r--  2.0 unx     2867 b- defN 23-May-12 23:50 mlflow/tracking/request_header/registry.py
+-rw-r--r--  2.0 unx      299 b- defN 23-May-12 23:50 mlflow/types/__init__.py
+-rw-r--r--  2.0 unx    13334 b- defN 23-May-12 23:50 mlflow/types/schema.py
+-rw-r--r--  2.0 unx    17899 b- defN 23-May-12 23:50 mlflow/types/utils.py
+-rw-r--r--  2.0 unx     9389 b- defN 23-May-12 23:50 mlflow/utils/__init__.py
+-rw-r--r--  2.0 unx     6270 b- defN 23-May-12 23:50 mlflow/utils/_capture_modules.py
+-rw-r--r--  2.0 unx     6395 b- defN 23-May-12 23:50 mlflow/utils/_spark_utils.py
+-rw-r--r--  2.0 unx     4906 b- defN 23-May-12 23:50 mlflow/utils/annotations.py
+-rw-r--r--  2.0 unx      400 b- defN 23-May-12 23:50 mlflow/utils/arguments_utils.py
+-rw-r--r--  2.0 unx      215 b- defN 23-May-12 23:50 mlflow/utils/class_utils.py
+-rw-r--r--  2.0 unx     6431 b- defN 23-May-12 23:50 mlflow/utils/cli_args.py
+-rw-r--r--  2.0 unx    13002 b- defN 23-May-12 23:50 mlflow/utils/conda.py
+-rw-r--r--  2.0 unx      432 b- defN 23-May-12 23:50 mlflow/utils/data_utils.py
+-rw-r--r--  2.0 unx    22596 b- defN 23-May-12 23:50 mlflow/utils/databricks_utils.py
+-rw-r--r--  2.0 unx     9138 b- defN 23-May-12 23:50 mlflow/utils/docstring_utils.py
+-rw-r--r--  2.0 unx      192 b- defN 23-May-12 23:50 mlflow/utils/env.py
+-rw-r--r--  2.0 unx      474 b- defN 23-May-12 23:50 mlflow/utils/env_manager.py
+-rw-r--r--  2.0 unx    21851 b- defN 23-May-12 23:50 mlflow/utils/environment.py
+-rw-r--r--  2.0 unx    25967 b- defN 23-May-12 23:50 mlflow/utils/file_utils.py
+-rw-r--r--  2.0 unx     2306 b- defN 23-May-12 23:50 mlflow/utils/git_utils.py
+-rw-r--r--  2.0 unx    24166 b- defN 23-May-12 23:50 mlflow/utils/gorilla.py
+-rw-r--r--  2.0 unx     2597 b- defN 23-May-12 23:50 mlflow/utils/logging_utils.py
+-rw-r--r--  2.0 unx     1298 b- defN 23-May-12 23:50 mlflow/utils/mime_type_utils.py
+-rw-r--r--  2.0 unx     3839 b- defN 23-May-12 23:50 mlflow/utils/mlflow_tags.py
+-rw-r--r--  2.0 unx     6208 b- defN 23-May-12 23:50 mlflow/utils/model_utils.py
+-rw-r--r--  2.0 unx     5873 b- defN 23-May-12 23:50 mlflow/utils/name_utils.py
+-rw-r--r--  2.0 unx     2412 b- defN 23-May-12 23:50 mlflow/utils/nfs_on_spark.py
+-rw-r--r--  2.0 unx      139 b- defN 23-May-12 23:50 mlflow/utils/os.py
+-rw-r--r--  2.0 unx     5799 b- defN 23-May-12 23:50 mlflow/utils/process.py
+-rw-r--r--  2.0 unx    19923 b- defN 23-May-12 23:50 mlflow/utils/proto_json_utils.py
+-rw-r--r--  2.0 unx    18470 b- defN 23-May-12 23:50 mlflow/utils/requirements_utils.py
+-rw-r--r--  2.0 unx    16880 b- defN 23-May-12 23:50 mlflow/utils/rest_utils.py
+-rw-r--r--  2.0 unx    56769 b- defN 23-May-12 23:50 mlflow/utils/search_utils.py
+-rw-r--r--  2.0 unx     2368 b- defN 23-May-12 23:50 mlflow/utils/server_cli_utils.py
+-rw-r--r--  2.0 unx     3805 b- defN 23-May-12 23:50 mlflow/utils/string_utils.py
+-rw-r--r--  2.0 unx      512 b- defN 23-May-12 23:50 mlflow/utils/time_utils.py
+-rw-r--r--  2.0 unx    13915 b- defN 23-May-12 23:50 mlflow/utils/uri.py
+-rw-r--r--  2.0 unx    16024 b- defN 23-May-12 23:50 mlflow/utils/validation.py
+-rw-r--r--  2.0 unx    16452 b- defN 23-May-12 23:50 mlflow/utils/virtualenv.py
+-rw-r--r--  2.0 unx    27070 b- defN 23-May-12 23:50 mlflow/utils/autologging_utils/__init__.py
+-rw-r--r--  2.0 unx    15731 b- defN 23-May-12 23:50 mlflow/utils/autologging_utils/client.py
+-rw-r--r--  2.0 unx    10937 b- defN 23-May-12 23:50 mlflow/utils/autologging_utils/events.py
+-rw-r--r--  2.0 unx    13381 b- defN 23-May-12 23:50 mlflow/utils/autologging_utils/logging_and_warnings.py
+-rw-r--r--  2.0 unx    47266 b- defN 23-May-12 23:50 mlflow/utils/autologging_utils/safety.py
+-rw-r--r--  2.0 unx     3489 b- defN 23-May-12 23:50 mlflow/utils/autologging_utils/versioning.py
+-rw-r--r--  2.0 unx    13489 b- defN 23-May-12 23:50 mlflow/utils/import_hooks/__init__.py
+-rw-r--r--  2.0 unx    34313 b- defN 23-May-12 23:50 mlflow/xgboost/__init__.py
+-rw-r--r--  2.0 unx     2908 b- defN 23-May-12 23:50 mlflow/xgboost/_autolog.py
+-rw-r--r--  2.0 unx      521 b- defN 23-May-12 23:50 pylint_plugins/__init__.py
+-rw-r--r--  2.0 unx     2006 b- defN 23-May-12 23:50 pylint_plugins/errors.py
+-rw-r--r--  2.0 unx      856 b- defN 23-May-12 23:50 pylint_plugins/print_function.py
+-rw-r--r--  2.0 unx      571 b- defN 23-May-12 23:50 pylint_plugins/set_checker.py
+-rw-r--r--  2.0 unx      878 b- defN 23-May-12 23:50 pylint_plugins/string_checker.py
+-rw-r--r--  2.0 unx      692 b- defN 23-May-12 23:50 pylint_plugins/unittest_assert_raises.py
+-rw-r--r--  2.0 unx     1546 b- defN 23-May-12 23:50 pylint_plugins/pytest_raises_checker/__init__.py
+-rw-r--r--  2.0 unx    11382 b- defN 23-May-12 23:50 mlflow_skinny-2.3.2.dist-info/LICENSE.txt
+-rw-r--r--  2.0 unx    12761 b- defN 23-May-12 23:50 mlflow_skinny-2.3.2.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-May-12 23:50 mlflow_skinny-2.3.2.dist-info/WHEEL
+-rw-r--r--  2.0 unx       92 b- defN 23-May-12 23:50 mlflow_skinny-2.3.2.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       22 b- defN 23-May-12 23:50 mlflow_skinny-2.3.2.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    33065 b- defN 23-May-12 23:50 mlflow_skinny-2.3.2.dist-info/RECORD
+354 files, 11010968 bytes uncompressed, 4031664 bytes compressed:  63.4%
```

## zipnote {}

```diff
@@ -525,14 +525,20 @@
 
 Filename: mlflow/server/auth/config.py
 Comment: 
 
 Filename: mlflow/server/auth/entities.py
 Comment: 
 
+Filename: mlflow/server/auth/logo.py
+Comment: 
+
+Filename: mlflow/server/auth/permissions.py
+Comment: 
+
 Filename: mlflow/server/auth/sqlalchemy_store.py
 Comment: 
 
 Filename: mlflow/sklearn/__init__.py
 Comment: 
 
 Filename: mlflow/sklearn/utils.py
@@ -1032,26 +1038,26 @@
 
 Filename: pylint_plugins/unittest_assert_raises.py
 Comment: 
 
 Filename: pylint_plugins/pytest_raises_checker/__init__.py
 Comment: 
 
-Filename: mlflow_skinny-2.3.1.dist-info/LICENSE.txt
+Filename: mlflow_skinny-2.3.2.dist-info/LICENSE.txt
 Comment: 
 
-Filename: mlflow_skinny-2.3.1.dist-info/METADATA
+Filename: mlflow_skinny-2.3.2.dist-info/METADATA
 Comment: 
 
-Filename: mlflow_skinny-2.3.1.dist-info/WHEEL
+Filename: mlflow_skinny-2.3.2.dist-info/WHEEL
 Comment: 
 
-Filename: mlflow_skinny-2.3.1.dist-info/entry_points.txt
+Filename: mlflow_skinny-2.3.2.dist-info/entry_points.txt
 Comment: 
 
-Filename: mlflow_skinny-2.3.1.dist-info/top_level.txt
+Filename: mlflow_skinny-2.3.2.dist-info/top_level.txt
 Comment: 
 
-Filename: mlflow_skinny-2.3.1.dist-info/RECORD
+Filename: mlflow_skinny-2.3.2.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## mlflow/environment_variables.py

```diff
@@ -194,15 +194,16 @@
 MLFLOW_ARTIFACT_UPLOAD_DOWNLOAD_TIMEOUT = _EnvironmentVariable(
     "MLFLOW_ARTIFACT_UPLOAD_DOWNLOAD_TIMEOUT", int, None
 )
 
 #: Specifies the device intended for use in the predict function - can be used
 #: to override behavior where the GPU is used by default when available by
 #: setting this environment variable to be ``cpu``. Currently, this
-#: variable is only supported for the MLflow PyTorch flavor.
+#: variable is only supported for the MLflow PyTorch and HuggingFace flavors.
+#: For the HuggingFace flavor, note that device must be parseable as an integer.
 MLFLOW_DEFAULT_PREDICTION_DEVICE = _EnvironmentVariable(
     "MLFLOW_DEFAULT_PREDICTION_DEVICE", str, None
 )
 
 #: Specifies whether or not to allow using a file URI as a model version source.
 #: Please be aware that setting this environment variable to True is potentially risky
 #: because it can allow access to arbitrary files on the specified filesystem
```

## mlflow/lightgbm.py

```diff
@@ -332,28 +332,33 @@
 
     .. code-block:: python
         :caption: Example
 
         from lightgbm import LGBMClassifier
         from sklearn import datasets
         import mlflow
+        from mlflow.models.signature import infer_signature
 
         # Load iris dataset
         X, y = datasets.load_iris(return_X_y=True, as_frame=True)
 
         # Initialize our model
         model = LGBMClassifier(objective="multiclass", random_state=42)
 
         # Train the model
         model.fit(X, y)
 
+        # Create model signature
+        predictions = model.predict(X)
+        signature = infer_signature(X, predictions)
+
         # Log the model
         artifact_path = "model"
         with mlflow.start_run():
-            model_info = mlflow.lightgbm.log_model(model, artifact_path)
+            model_info = mlflow.lightgbm.log_model(model, artifact_path, signature=signature)
 
         # Fetch the logged model artifacts
         print(f"run_id: {run.info.run_id}")
         client = mlflow.MlflowClient()
         artifacts = [f.path for f in client.list_artifacts(run.info.run_id, artifact_path)]
         print(f"artifacts: {artifacts}")
 
@@ -444,29 +449,29 @@
     .. code-block:: python
         :caption: Example
 
         from lightgbm import LGBMClassifier
         from sklearn import datasets
         import mlflow
 
+        # Auto log all MLflow entities
+        mlflow.lightgbm.autolog()
+
         # Load iris dataset
         X, y = datasets.load_iris(return_X_y=True, as_frame=True)
 
         # Initialize our model
         model = LGBMClassifier(objective="multiclass", random_state=42)
 
         # Train the model
         model.fit(X, y)
 
-        # Log the model
-        with mlflow.start_run():
-            model_info = mlflow.lightgbm.log_model(model, artifact_path="model")
-
         # Load model for inference
-        loaded_model = mlflow.lightgbm.load_model(model_info.model_uri)
+        model_uri = f"runs:/{mlflow.last_active_run().info.run_id}/model"
+        loaded_model = mlflow.lightgbm.load_model(model_uri)
         print(loaded_model.predict(X[:5]))
 
     .. code-block:: text
         :caption: Output
 
         [0 0 0 0 0]
     """
```

## mlflow/ml_package_versions.py

```diff
@@ -221,14 +221,18 @@
     "transformers": {
         "package_info": {
             "pip_release": "transformers"
         },
         "models": {
             "minimum": "4.25.1",
             "maximum": "4.28.1"
+        },
+        "autologging": {
+            "minimum": "4.25.1",
+            "maximum": "4.28.1"
         }
     },
     "openai": {
         "package_info": {
             "pip_release": "openai"
         },
         "models": {
```

## mlflow/transformers.py

```diff
@@ -1,8 +1,10 @@
 import ast
+import contextlib
+from functools import lru_cache
 import json
 import logging
 import pathlib
 import pandas as pd
 import numpy as np
 import re
 from typing import Union, List, Optional, Dict, Any, NamedTuple
@@ -14,22 +16,24 @@
 from mlflow.exceptions import MlflowException
 from mlflow.models import ModelInputExample, Model, infer_pip_requirements
 from mlflow.models.model import MLMODEL_FILE_NAME
 from mlflow.models.signature import ModelSignature, infer_signature
 from mlflow.models.utils import _save_example
 from mlflow.protos.databricks_pb2 import INVALID_PARAMETER_VALUE, BAD_REQUEST
 from mlflow.tracking._model_registry import DEFAULT_AWAIT_MAX_SLEEP_SECONDS
-from mlflow.types.schema import Schema, ColSpec
+from mlflow.types.schema import Schema, ColSpec, TensorSpec
 from mlflow.types.utils import _validate_input_dictionary_contains_only_strings_and_lists_of_strings
 from mlflow.utils.annotations import experimental
+from mlflow.utils.autologging_utils import autologging_integration, safe_patch
 from mlflow.utils.docstring_utils import (
     format_docstring,
     LOG_MODEL_PARAM_DOCS,
     docstring_version_compatibility_warning,
 )
+from mlflow.environment_variables import MLFLOW_DEFAULT_PREDICTION_DEVICE
 from mlflow.utils.environment import (
     _mlflow_conda_env,
     _validate_env_arguments,
     _CONDA_ENV_FILE_NAME,
     _PYTHON_ENV_FILE_NAME,
     _process_conda_env,
     _process_pip_requirements,
@@ -45,35 +49,44 @@
     _get_flavor_configuration,
     _get_flavor_configuration_from_uri,
     _add_code_from_conf_to_system_path,
 )
 from mlflow.utils.requirements_utils import _get_pinned_requirement
 
 FLAVOR_NAME = "transformers"
-_PIPELINE_BINARY_KEY = "pipeline"
-_PIPELINE_BINARY_FILE_NAME = "pipeline"
+
+_CARD_TEXT_FILE_NAME = "model_card.md"
+_CARD_DATA_FILE_NAME = "model_card_data.yaml"
 _COMPONENTS_BINARY_KEY = "components"
-_INFERENCE_CONFIG_BINARY_KEY = "inference_config.txt"
-_MODEL_KEY = "model"
-_TOKENIZER_KEY = "tokenizer"
 _FEATURE_EXTRACTOR_KEY = "feature_extractor"
-_IMAGE_PROCESSOR_KEY = "image_processor"
-_PROCESSOR_KEY = "processor"
-_TOKENIZER_TYPE_KEY = "tokenizer_type"
 _FEATURE_EXTRACTOR_TYPE_KEY = "feature_extractor_type"
+_FRAMEWORK_KEY = "framework"
+_IMAGE_PROCESSOR_KEY = "image_processor"
 _IMAGE_PROCESSOR_TYPE_KEY = "image_processor_type"
-_PROCESSOR_TYPE_KEY = "processor_type"
-_CARD_TEXT_FILE_NAME = "model_card.md"
-_CARD_DATA_FILE_NAME = "model_card_data.yaml"
-_TASK_KEY = "task"
+_INFERENCE_CONFIG_BINARY_KEY = "inference_config.txt"
 _INSTANCE_TYPE_KEY = "instance_type"
-_PIPELINE_MODEL_TYPE_KEY = "pipeline_model_type"
+_MODEL_KEY = "model"
 _MODEL_PATH_OR_NAME_KEY = "source_model_name"
-_SUPPORTED_SAVE_KEYS = {_MODEL_KEY, _TOKENIZER_KEY, _FEATURE_EXTRACTOR_KEY, _IMAGE_PROCESSOR_KEY}
+_PIPELINE_BINARY_KEY = "pipeline"
+_PIPELINE_BINARY_FILE_NAME = "pipeline"
+_PIPELINE_MODEL_TYPE_KEY = "pipeline_model_type"
+_PROCESSOR_KEY = "processor"
+_PROCESSOR_TYPE_KEY = "processor_type"
 _SUPPORTED_RETURN_TYPES = {"pipeline", "components"}
+# The default device id for CPU is -1 and GPU IDs are ordinal starting at 0, as documented here:
+# https://huggingface.co/transformers/v4.7.0/main_classes/pipelines.html
+_TRANSFORMERS_DEFAULT_CPU_DEVICE_ID = -1
+_TRANSFORMERS_DEFAULT_GPU_DEVICE_ID = 0
+_TASK_KEY = "task"
+_TOKENIZER_KEY = "tokenizer"
+_TOKENIZER_TYPE_KEY = "tokenizer_type"
+_TORCH_DTYPE_KEY = "torch_dtype"
+_METADATA_PIPELINE_SCALAR_CONFIG_KEYS = {_FRAMEWORK_KEY}
+_SUPPORTED_SAVE_KEYS = {_MODEL_KEY, _TOKENIZER_KEY, _FEATURE_EXTRACTOR_KEY, _IMAGE_PROCESSOR_KEY}
+
 _logger = logging.getLogger(__name__)
 
 
 def _model_packages(model) -> List[str]:
     """
     Determines which pip libraries should be included based on the base model engine
     type.
@@ -710,15 +723,15 @@
         extra_pip_requirements=extra_pip_requirements,
         **kwargs,
     )
 
 
 @experimental
 @docstring_version_compatibility_warning(integration_name=FLAVOR_NAME)
-def load_model(model_uri: str, dst_path: str = None, return_type="pipeline", **kwargs):
+def load_model(model_uri: str, dst_path: str = None, return_type="pipeline", device=None, **kwargs):
     """
     Load a ``transformers`` object from a local file or a run.
 
     :param model_uri: The location, in URI format, of the MLflow model. For example:
 
                       - ``/Users/me/path/to/local/model``
                       - ``relative/path/to/local/model``
@@ -749,14 +762,16 @@
                         have the desired pipeline return types for certain use cases.
                         If set as "pipeline", the model, along with any and all required
                         ``Tokenizer``, ``FeatureExtractor``, ``Processor``, or ``ImageProcessor``
                         objects will be returned within a ``Pipeline`` object of the appropriate
                         type defined by the ``task`` set by the model instance type. To override
                         this behavior, supply a valid ``task`` argument during model logging or
                         saving. Default is "pipeline".
+    :param device: The device on which to load the model. Default is None. Use 0 to
+                   load to the default GPU.
     :param kwargs: Optional configuration options for loading of a ``transformers`` object.
                    For information on parameters and their usage, see
                    `transformers documentation <https://huggingface.co/docs/transformers/index>`_.
     :return: A ``transformers`` model instance or a dictionary of components
     """
 
     if return_type not in _SUPPORTED_RETURN_TYPES:
@@ -778,51 +793,122 @@
             "not compatible with Pipelines. Please load this model by specifying "
             "the 'return_type'='components'.",
             error_code=BAD_REQUEST,
         )
 
     _add_code_from_conf_to_system_path(local_model_path, flavor_config)
 
-    return _load_model(local_model_path, flavor_config, return_type, **kwargs)
+    return _load_model(local_model_path, flavor_config, return_type, device, **kwargs)
+
+
+# This function attempts to determine if a GPU is available for the PyTorch and TensorFlow libraries
+def is_gpu_available():
+    # try pytorch and if it fails, try tf
+    is_gpu = None
+    try:
+        import torch
+
+        is_gpu = torch.cuda.is_available()
+    except ImportError:
+        pass
+    if is_gpu is None:
+        try:
+            import tensorflow as tf
 
+            is_gpu = tf.test.is_gpu_available()
+        except ImportError:
+            pass
+    if is_gpu is None:
+        is_gpu = False
+    return is_gpu
 
-def _load_model(path: str, flavor_config, return_type: str, **kwargs):
+
+def _load_model(path: str, flavor_config, return_type: str, device=None, **kwargs):
     """
     Loads components from a locally serialized ``Pipeline`` object.
     """
     import transformers
 
+    if device is None:
+        if MLFLOW_DEFAULT_PREDICTION_DEVICE.get():
+            try:
+                device = int(MLFLOW_DEFAULT_PREDICTION_DEVICE.get())
+            except ValueError:
+                device = _TRANSFORMERS_DEFAULT_CPU_DEVICE_ID
+        elif is_gpu_available():
+            device = _TRANSFORMERS_DEFAULT_GPU_DEVICE_ID
+
     local_path = pathlib.Path(path)
     pipeline_path = local_path.joinpath(
         flavor_config.get(_PIPELINE_BINARY_KEY, _PIPELINE_BINARY_FILE_NAME)
     )
 
     model_instance = getattr(transformers, flavor_config[_PIPELINE_MODEL_TYPE_KEY])
     conf = {
         "task": flavor_config[_TASK_KEY],
         "model": model_instance.from_pretrained(pipeline_path),
     }
+    if device is not None:
+        conf["device"] = device
 
     if _PROCESSOR_TYPE_KEY in flavor_config:
         conf[_PROCESSOR_KEY] = _load_component(
             local_path, _PROCESSOR_KEY, flavor_config[_PROCESSOR_TYPE_KEY]
         )
 
     for component_key in flavor_config[_COMPONENTS_BINARY_KEY]:
         component_type_key = f"{component_key}_type"
         component_type = flavor_config[component_type_key]
         conf[component_key] = _load_component(local_path, component_key, component_type)
 
+    if _TORCH_DTYPE_KEY in flavor_config:
+        conf[_TORCH_DTYPE_KEY] = _deserialize_torch_dtype_if_exists(flavor_config)
+
+    for key in _METADATA_PIPELINE_SCALAR_CONFIG_KEYS:
+        if key in flavor_config:
+            conf[key] = flavor_config[key]
+
     if return_type == "pipeline":
         conf.update(**kwargs)
         return transformers.pipeline(**conf)
     elif return_type == "components":
         return conf
 
 
+@lru_cache
+def _torch_dype_mapping():
+    """
+    Memoized torch data type mapping from the torch primary datatypes for use in deserializing the
+    saved pipeline parameter `torch_dtype`
+    """
+    try:
+        import torch
+
+        return {
+            str(dtype): dtype
+            for name, dtype in torch.__dict__.items()
+            if isinstance(dtype, torch.dtype)
+        }
+    except ImportError as e:
+        raise MlflowException(
+            "Unable to determine if the value supplied by the argument "
+            "torch_dtype is valid since torch is not installed.",
+            error_code=INVALID_PARAMETER_VALUE,
+        ) from e
+
+
+def _deserialize_torch_dtype_if_exists(flavor_config):
+    """
+    Convert the string-encoded `torch_dtype` pipeline argument back to the correct `torch.dtype`
+    instance value for applying to a loaded pipeline instance.
+    """
+
+    return _torch_dype_mapping()[flavor_config["torch_dtype"]]
+
+
 def _fetch_model_card(model_or_pipeline):
     """
     Attempts to retrieve the model card for the specified model architecture iff the
     `huggingface_hub` library is installed. If a card cannot be found in the registry or
     the library is not installed, returns None.
     """
     try:
@@ -921,15 +1007,15 @@
     components_dir = root_path.joinpath(_COMPONENTS_BINARY_KEY)
     component_path = components_dir.joinpath(component_key)
     component_instance = getattr(transformers, component_type)
     return component_instance.from_pretrained(component_path)
 
 
 def _generate_base_flavor_configuration(
-    model,
+    pipeline,
     task: str,
 ) -> Dict[str, str]:
     """
     Generates the base flavor metadata needed for reconstructing a pipeline from saved
     components. This is important because the ``Pipeline`` class does not have a loader
     functionality. The serialization of a Pipeline saves the model, configurations, and
     metadata for ``FeatureExtractor``s, ``Processor``s, and ``Tokenizer``s exclusively.
@@ -937,22 +1023,48 @@
     instance types can be loaded correctly.
     """
 
     _validate_transformers_task_type(task)
 
     flavor_configuration = {
         _TASK_KEY: task,
-        _INSTANCE_TYPE_KEY: _get_instance_type(model),
-        _MODEL_PATH_OR_NAME_KEY: _get_base_model_architecture(model),
-        _PIPELINE_MODEL_TYPE_KEY: _get_instance_type(model.model),
+        _INSTANCE_TYPE_KEY: _get_instance_type(pipeline),
+        _MODEL_PATH_OR_NAME_KEY: _get_base_model_architecture(pipeline),
+        _PIPELINE_MODEL_TYPE_KEY: _get_instance_type(pipeline.model),
     }
 
+    # Extract and add to the configuration the scalar serializable arguments for pipeline args
+    for arg_key in _METADATA_PIPELINE_SCALAR_CONFIG_KEYS:
+        if entry := _get_scalar_argument_from_pipeline(pipeline, arg_key):
+            flavor_configuration[arg_key] = entry
+
+    # Extract a serialized representation of torch_dtype if provided
+    if torch_dtype := _extract_torch_dtype_if_set(pipeline):
+        flavor_configuration[_TORCH_DTYPE_KEY] = torch_dtype
+
     return flavor_configuration
 
 
+def _get_scalar_argument_from_pipeline(pipeline, arg_key):
+    """
+    Retrieve provided pipeline arguments for the purposes of instantiating a pipeline object upon
+    loading.
+    """
+
+    return getattr(pipeline, arg_key, None)
+
+
+def _extract_torch_dtype_if_set(pipeline):
+    """
+    Extract the torch datatype argument if set and return as a string encoded value.
+    """
+    if torch_dtype := getattr(pipeline, _TORCH_DTYPE_KEY, None):
+        return str(torch_dtype)
+
+
 def _get_or_infer_task_type(model, task: Optional[str] = None) -> str:
     """
     Validates that a supplied task type is supported by the ``transformers`` library if supplied,
     else, if not supplied, infers the appropriate task type based on the model type.
     """
     if task:
         _validate_transformers_task_type(task)
@@ -1122,14 +1234,15 @@
             (
                 transformers.TokenClassificationPipeline,
                 transformers.ConversationalPipeline,
                 transformers.TranslationPipeline,
                 transformers.TextClassificationPipeline,
                 transformers.FillMaskPipeline,
                 transformers.TextGenerationPipeline,
+                transformers.Text2TextGenerationPipeline,
             ),
         ):
             return ModelSignature(
                 inputs=Schema([ColSpec("string")]), outputs=Schema([ColSpec("string")])
             )
         elif isinstance(pipeline, transformers.ZeroShotClassificationPipeline):
             return ModelSignature(
@@ -1142,39 +1255,39 @@
                 ),
                 outputs=Schema([ColSpec("string")]),
             )
         elif isinstance(
             pipeline,
             (
                 transformers.TableQuestionAnsweringPipeline,
-                transformers.Text2TextGenerationPipeline,
                 transformers.QuestionAnsweringPipeline,
             ),
         ):
             column_1 = None
             column_2 = None
             if isinstance(pipeline, transformers.TableQuestionAnsweringPipeline):
                 column_1 = "query"
                 column_2 = "table"
-            elif isinstance(pipeline, transformers.Text2TextGenerationPipeline):
-                column_1 = "answer"
-                column_2 = "context"
             elif isinstance(pipeline, transformers.QuestionAnsweringPipeline):
                 column_1 = "question"
                 column_2 = "context"
             return ModelSignature(
                 inputs=Schema(
                     [
                         ColSpec("string", name=column_1),
                         ColSpec("string", name=column_2),
                     ]
                 ),
                 outputs=Schema([ColSpec("string")]),
             )
-
+        elif isinstance(pipeline, transformers.FeatureExtractionPipeline):
+            return ModelSignature(
+                inputs=Schema([ColSpec("string")]),
+                outputs=Schema([TensorSpec(np.dtype("float64"), [-1], "double")]),
+            )
         else:
             _logger.warning(
                 "An unsupported Pipeline type was supplied for signature inference. "
                 "Either provide an `input_example` or generate a signature manually "
                 "via `infer_signature` if you would like to have a signature recorded "
                 "in the MLmodel file."
             )
@@ -1358,15 +1471,15 @@
                     parsed[key] = (
                         contents
                         if all(isinstance(item, str) for item in contents) and len(contents) > 1
                         else contents[0]
                     )
             return parsed
 
-    def predict(self, data):
+    def predict(self, data, device=None):
         if isinstance(data, pd.DataFrame):
             input_data = self._convert_pandas_to_dict(data)
         elif isinstance(data, dict):
             input_data = data
         elif isinstance(data, list):
             if not all(isinstance(entry, (str, dict)) for entry in data):
                 raise MlflowException(
@@ -1392,19 +1505,19 @@
         elif isinstance(input_data, list) and all(isinstance(entry, dict) for entry in input_data):
             # Validate each dict inside an input List[Dict]
             all(
                 _validate_input_dictionary_contains_only_strings_and_lists_of_strings(x)
                 for x in input_data
             )
 
-        predictions = self._predict(input_data)
+        predictions = self._predict(input_data, device)
 
         return predictions
 
-    def _predict(self, data):
+    def _predict(self, data, device):
         import transformers
 
         # NB: the ordering of these conditional statements matters. TranslationPipeline and
         # SummarizationPipeline both inherit from TextGenerationPipeline (they are subclasses)
         # in which the return data structure from their __call__ implementation is modified.
         if isinstance(self.pipeline, transformers.TranslationPipeline):
             self._validate_str_or_list_str(data)
@@ -1430,14 +1543,17 @@
             output_key = "labels"
             data = self._parse_json_encoded_list(data, "candidate_labels")
         elif isinstance(self.pipeline, transformers.TableQuestionAnsweringPipeline):
             output_key = "answer"
             data = self._parse_json_encoded_dict_payload_to_dict(data, "table")
         elif isinstance(self.pipeline, transformers.TokenClassificationPipeline):
             output_key = {"entity_group", "entity"}
+        elif isinstance(self.pipeline, transformers.FeatureExtractionPipeline):
+            output_key = None
+            data = self._parse_feature_extraction_input(data)
         elif isinstance(self.pipeline, transformers.ConversationalPipeline):
             output_key = None
             if not self._conversation:
                 self._conversation = transformers.Conversation()
             self._conversation.add_user_input(data)
         elif type(self.pipeline).__name__ in self._supported_custom_generator_types:
             self._validate_str_or_list_str(data)
@@ -1452,14 +1568,16 @@
         # Optional input preservation for specific pipeline types. This is True (include raw
         # formatting output), but if `include_prompt` is set to False in the `inference_config`
         # option during model saving, excess newline characters and the fed-in prompt will be
         # trimmed out from the start of the response.
         include_prompt = self.inference_config.pop("include_prompt", True)
         # Optional stripping out of `\n` for specific generator pipelines.
         collapse_whitespace = self.inference_config.pop("collapse_whitespace", False)
+        if device is not None:
+            self.inference_config["device"] = device
 
         data = self._convert_cast_lists_from_np_back_to_list(data)
 
         # Generate inference data with the pipeline object
         if isinstance(self.pipeline, transformers.ConversationalPipeline):
             conversation_output = self.pipeline(self._conversation)
             return conversation_output.generated_responses[-1]
@@ -1476,14 +1594,16 @@
                 data,
                 raw_output,
                 output_key,
                 self.flavor_config,
                 include_prompt,
                 collapse_whitespace,
             )
+        elif isinstance(self.pipeline, transformers.FeatureExtractionPipeline):
+            return self._parse_feature_extraction_output(raw_output)
         elif isinstance(self.pipeline, transformers.FillMaskPipeline):
             output = self._parse_list_of_multiple_dicts(raw_output, output_key)
         elif isinstance(self.pipeline, transformers.ZeroShotClassificationPipeline):
             interim_output = self._parse_lists_of_dict_to_list_of_str(raw_output, output_key)
             output = self._parse_list_output_for_multiple_candidate_pipelines(interim_output)
         elif isinstance(self.pipeline, transformers.TokenClassificationPipeline):
             output = self._parse_tokenizer_output(raw_output, output_key)
@@ -1750,14 +1870,44 @@
                     output_coll.append(
                         self._parse_lists_of_dict_to_list_of_str(output, target_dict_key)[0]
                     )
             return output_coll
         else:
             return output_data[target_dict_key]
 
+    @staticmethod
+    def _parse_feature_extraction_input(input_data):
+        if isinstance(input_data, list) and isinstance(input_data[0], dict):
+            return [list(data.values())[0] for data in input_data]
+        else:
+            return input_data
+
+    @staticmethod
+    def _parse_feature_extraction_output(output_data):
+        """
+        Parse the return type from a FeatureExtractionPipeline output. The mixed types for
+        input are present depending on how the pyfunc is instantiated. For model serving usage,
+        the returned type from MLServer will be a numpy.ndarray type, otherwise, the return
+        within a manually executed pyfunc (i.e., for udf usage), the return will be a collection
+        of nested lists.
+
+        Examples:
+
+        Input: [[[0.11, 0.98, 0.76]]] or np.array([0.11, 0.98, 0.76])
+        Output: np.array([0.11, 0.98, 0.76])
+
+        Input: [[[[0.1, 0.2], [0.3, 0.4]]]] or
+            np.array([np.array([0.1, 0.2]), np.array([0.3, 0.4])])
+        Output: np.array([np.array([0.1, 0.2]), np.array([0.3, 0.4])])
+        """
+        if isinstance(output_data, np.ndarray):
+            return output_data
+        else:
+            return np.array(output_data[0][0])
+
     def _parse_tokenizer_output(self, output_data, target_set):
         """
         Parses the tokenizer pipeline output.
 
         Examples:
 
         Input: [{"entity": "PRON", "score": 0.95}, {"entity": "NOUN", "score": 0.998}]
@@ -1994,7 +2144,53 @@
             parsed_data = []
             for entry in data:
                 if all(isinstance(value, np.ndarray) for value in entry.values()):
                     parsed_data.append({key: value.tolist() for key, value in entry.items()})
                 else:
                     parsed_data.append(entry)
             return parsed_data
+
+
+@experimental
+@autologging_integration(FLAVOR_NAME)
+def autolog(
+    log_input_examples=False,
+    log_model_signatures=False,
+    log_models=False,
+    disable=False,
+    exclusive=False,
+    disable_for_unsupported_versions=False,
+    silent=False,
+):  # pylint: disable=W0102,unused-argument
+    """
+    This autologging integration is solely used for disabling spurious autologging of irrelevant
+    sub-models that are created during the training and evaluation of transformers-based models.
+    Autologging functionality is not implemented fully for the transformers flavor.
+    """
+    import functools
+
+    # A list of other flavors whose base autologging config would be automatically logged due to
+    # training a model that would otherwise create a run and be logged internally within the
+    # transformers-supported trainer calls.
+    DISABLED_ANCILLARY_FLAVOR_AUTOLOGGING = ["sklearn", "tensorflow", "pytorch"]
+
+    def train(original, *args, **kwargs):
+        with mlflow.utils.autologging_utils.disable_discrete_autologging(
+            DISABLED_ANCILLARY_FLAVOR_AUTOLOGGING
+        ):
+            return original(*args, **kwargs)
+
+    with contextlib.suppress(ImportError):
+        import setfit
+
+        safe_patch(
+            FLAVOR_NAME, setfit.SetFitTrainer, "train", functools.partial(train), manage_run=False
+        )
+
+    with contextlib.suppress(ImportError):
+        import transformers
+
+        classes = [transformers.Trainer, transformers.Seq2SeqTrainer]
+        methods = ["train"]
+        for clazz in classes:
+            for method in methods:
+                safe_patch(FLAVOR_NAME, clazz, method, functools.partial(train), manage_run=False)
```

## mlflow/version.py

```diff
@@ -1,9 +1,9 @@
 # Copyright 2018 Databricks, Inc.
 import re
 
 
-VERSION = "2.3.1"
+VERSION = "2.3.2"
 
 
 def is_release_version():
     return bool(re.match(r"^\d+\.\d+\.\d+$", VERSION))
```

## mlflow/models/model.py

```diff
@@ -205,22 +205,25 @@
             :caption: Example usage of Model Metadata
 
             # Create and log a model with metadata to the Model Registry
 
             from sklearn import datasets
             from sklearn.ensemble import RandomForestClassifier
             import mlflow
+            from mlflow.models.signature import infer_signature
 
             with mlflow.start_run():
                 iris = datasets.load_iris()
                 clf = RandomForestClassifier()
                 clf.fit(iris.data, iris.target)
+                signature = infer_signature(iris.data, iris.target)
                 mlflow.sklearn.log_model(
                     clf,
                     "iris_rf",
+                    signature=signature,
                     registered_model_name="model-with-metadata",
                     metadata={"metadata_key": "metadata_value"},
                 )
 
             # model uri for the above model
             model_uri = "models:/model-with-metadata/1"
 
@@ -324,22 +327,25 @@
             :caption: Example
 
             # Create and log a model with metadata to the Model Registry
 
             from sklearn import datasets
             from sklearn.ensemble import RandomForestClassifier
             import mlflow
+            from mlflow.models.signature import infer_signature
 
             with mlflow.start_run():
                 iris = datasets.load_iris()
                 clf = RandomForestClassifier()
                 clf.fit(iris.data, iris.target)
+                signature = infer_signature(iris.data, iris.target)
                 mlflow.sklearn.log_model(
                     clf,
                     "iris_rf",
+                    signature=signature,
                     registered_model_name="model-with-metadata",
                     metadata={"metadata_key": "metadata_value"},
                 )
 
             # model uri for the above model
             model_uri = "models:/model-with-metadata/1"
```

## mlflow/models/utils.py

```diff
@@ -775,15 +775,18 @@
         from mlflow.models.signature import infer_signature
 
         with mlflow.start_run():
             iris = datasets.load_iris()
             iris_train = pd.DataFrame(iris.data, columns=iris.feature_names)
             clf = RandomForestClassifier(max_depth=7, random_state=0)
             clf.fit(iris_train, iris.target)
-            mlflow.sklearn.log_model(clf, "iris_rf", registered_model_name="model-with-libs")
+            signature = infer_signature(iris_train, clf.predict(iris_train))
+            mlflow.sklearn.log_model(
+                clf, "iris_rf", signature=signature, registered_model_name="model-with-libs"
+            )
 
         # model uri for the above model
         model_uri = "models:/model-with-libs/1"
 
         # Import utility
         from mlflow.models.utils import add_libraries_to_model
```

## mlflow/models/evaluation/base.py

```diff
@@ -416,23 +416,33 @@
         if isinstance(data, (np.ndarray, list)):
             if not isinstance(targets, (np.ndarray, list)):
                 raise MlflowException(
                     message="If data is a numpy array or list of evaluation features, "
                     "`targets` argument must be a numpy array or list of evaluation labels.",
                     error_code=INVALID_PARAMETER_VALUE,
                 )
+
+            shape_message = (
+                "If the `data` argument is a numpy array, it must be a 2 dimension "
+                "array and second dimension represent the number of features. If the `data` "
+                "argument is a list, each of its element must be a feature array of "
+                "numpy array or list and all element must has the same length."
+            )
+
             if isinstance(data, list):
-                data = np.array(data)
+                try:
+                    data = np.array(data)
+                except ValueError as e:
+                    raise MlflowException(
+                        message=shape_message, error_code=INVALID_PARAMETER_VALUE
+                    ) from e
 
             if len(data.shape) != 2:
                 raise MlflowException(
-                    message="If the `data` argument is a numpy array, it must be a 2 dimension"
-                    " array and second dimension represent the number of features. If the `data` "
-                    "argument is a list, each of its element must be a feature array of "
-                    "numpy array or list and all element must has the same length.",
+                    message=shape_message,
                     error_code=INVALID_PARAMETER_VALUE,
                 )
 
             self._features_data = data
             self._labels_data = targets if isinstance(targets, np.ndarray) else np.array(targets)
 
             if len(self._features_data) != len(self._labels_data):
```

## mlflow/openai/__init__.py

```diff
@@ -60,15 +60,18 @@
 )
 from mlflow.protos.databricks_pb2 import INVALID_PARAMETER_VALUE
 from mlflow.utils.docstring_utils import format_docstring, LOG_MODEL_PARAM_DOCS
 from mlflow.tracking._model_registry import DEFAULT_AWAIT_MAX_SLEEP_SECONDS
 from mlflow.types import Schema, ColSpec
 from mlflow.environment_variables import _MLFLOW_OPENAI_TESTING, MLFLOW_OPENAI_SECRET_SCOPE
 from mlflow.utils.annotations import experimental
-from mlflow.utils.databricks_utils import is_in_databricks_runtime
+from mlflow.utils.databricks_utils import (
+    check_databricks_secret_scope_access,
+    is_in_databricks_runtime,
+)
 
 FLAVOR_NAME = "openai"
 MODEL_FILENAME = "model.yaml"
 
 _logger = logging.getLogger(__name__)
 
 
@@ -341,19 +344,20 @@
         data=MODEL_FILENAME,
         code=code_dir_subpath,
     )
     mlflow_model.save(os.path.join(path, MLMODEL_FILE_NAME))
 
     if is_in_databricks_runtime():
         if scope := MLFLOW_OPENAI_SECRET_SCOPE.get():
+            check_databricks_secret_scope_access(scope)
             _log_secrets_yaml(path, scope)
         else:
             _logger.info(
                 "No secret scope specified, skipping logging of secrets for OpenAI credentials. "
-                "See https://mlflow.org/docs/latest/python_api/mlflow.openai.html#credential-management-for-openai-on-databricks "
+                "See https://mlflow.org/docs/latest/python_api/openai/index.html#credential-management-for-openai-on-databricks "
                 "for more information."
             )
 
     if conda_env is None:
         if pip_requirements is None:
             default_reqs = get_default_pip_requirements()
             inferred_reqs = mlflow.models.infer_pip_requirements(
```

## mlflow/protos/databricks_uc_registry_messages_pb2.py

```diff
@@ -13,15 +13,15 @@
 _sym_db = _symbol_database.Default()
 
 
 from .scalapb import scalapb_pb2 as scalapb_dot_scalapb__pb2
 from . import databricks_pb2 as databricks__pb2
 
 
-DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n%databricks_uc_registry_messages.proto\x12\x16mlflow.ucmodelregistry\x1a\x15scalapb/scalapb.proto\x1a\x10\x64\x61tabricks.proto\"\x81\x01\n\x0fRegisteredModel\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x1a\n\x12\x63reation_timestamp\x18\x02 \x01(\x03\x12\x1e\n\x16last_updated_timestamp\x18\x03 \x01(\x03\x12\x0f\n\x07user_id\x18\x04 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x05 \x01(\t\"\xd8\x02\n\x0cModelVersion\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0f\n\x07version\x18\x02 \x01(\t\x12\x1a\n\x12\x63reation_timestamp\x18\x03 \x01(\x03\x12\x1e\n\x16last_updated_timestamp\x18\x04 \x01(\x03\x12\x0f\n\x07user_id\x18\x05 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x06 \x01(\t\x12\x0e\n\x06source\x18\x07 \x01(\t\x12\x0e\n\x06run_id\x18\x08 \x01(\t\x12\x19\n\x11run_experiment_id\x18\t \x01(\t\x12\x1e\n\x16run_tracking_server_id\x18\n \x01(\t\x12:\n\x06status\x18\x0b \x01(\x0e\x32*.mlflow.ucmodelregistry.ModelVersionStatus\x12\x16\n\x0estatus_message\x18\x0c \x01(\t\x12\x18\n\x10storage_location\x18\r \x01(\t\"\x9d\x02\n\x14TemporaryCredentials\x12\x46\n\x14\x61ws_temp_credentials\x18\x02 \x01(\x0b\x32&.mlflow.ucmodelregistry.AwsCredentialsH\x00\x12S\n\x19\x61zure_user_delegation_sas\x18\x03 \x01(\x0b\x32..mlflow.ucmodelregistry.AzureUserDelegationSASH\x00\x12@\n\x0fgcp_oauth_token\x18\x04 \x01(\x0b\x32%.mlflow.ucmodelregistry.GcpOauthTokenH\x00\x12\x17\n\x0f\x65xpiration_time\x18\x01 \x01(\x03\x42\r\n\x0b\x63redentials\"Y\n\x0e\x41wsCredentials\x12\x15\n\raccess_key_id\x18\x01 \x01(\t\x12\x19\n\x11secret_access_key\x18\x02 \x01(\t\x12\x15\n\rsession_token\x18\x03 \x01(\t\"+\n\x16\x41zureUserDelegationSAS\x12\x11\n\tsas_token\x18\x01 \x01(\t\"$\n\rGcpOauthToken\x12\x13\n\x0boauth_token\x18\x01 \x01(\t\"\x83\x01\n\x1c\x43reateRegisteredModelRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x13\n\x0b\x64\x65scription\x18\x03 \x01(\t::\xe2?7\n5com.databricks.rpc.RPC[CreateRegisteredModelResponse]\"b\n\x1d\x43reateRegisteredModelResponse\x12\x41\n\x10registered_model\x18\x01 \x01(\x0b\x32\'.mlflow.ucmodelregistry.RegisteredModel\"\x83\x01\n\x1cUpdateRegisteredModelRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x13\n\x0b\x64\x65scription\x18\x02 \x01(\t::\xe2?7\n5com.databricks.rpc.RPC[UpdateRegisteredModelResponse]\"b\n\x1dUpdateRegisteredModelResponse\x12\x41\n\x10registered_model\x18\x01 \x01(\x0b\x32\'.mlflow.ucmodelregistry.RegisteredModel\"n\n\x1c\x44\x65leteRegisteredModelRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01::\xe2?7\n5com.databricks.rpc.RPC[DeleteRegisteredModelResponse]\"\x1f\n\x1d\x44\x65leteRegisteredModelResponse\"h\n\x19GetRegisteredModelRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01:7\xe2?4\n2com.databricks.rpc.RPC[GetRegisteredModelResponse]\"_\n\x1aGetRegisteredModelResponse\x12\x41\n\x10registered_model\x18\x01 \x01(\x0b\x32\'.mlflow.ucmodelregistry.RegisteredModel\"\x8a\x01\n\x1dSearchRegisteredModelsRequest\x12\x18\n\x0bmax_results\x18\x01 \x01(\x03:\x03\x31\x30\x30\x12\x12\n\npage_token\x18\x02 \x01(\t:;\xe2?8\n6com.databricks.rpc.RPC[SearchRegisteredModelsResponse]\"}\n\x1eSearchRegisteredModelsResponse\x12\x42\n\x11registered_models\x18\x01 \x03(\x0b\x32\'.mlflow.ucmodelregistry.RegisteredModel\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\t\"\xc3\x01\n\x19\x43reateModelVersionRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x14\n\x06source\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x12\x0e\n\x06run_id\x18\x03 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x04 \x01(\t\x12\x1e\n\x16run_tracking_server_id\x18\x05 \x01(\t:7\xe2?4\n2com.databricks.rpc.RPC[CreateModelVersionResponse]\"Y\n\x1a\x43reateModelVersionResponse\x12;\n\rmodel_version\x18\x01 \x01(\x0b\x32$.mlflow.ucmodelregistry.ModelVersion\"\x94\x01\n\x19UpdateModelVersionRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x12\x13\n\x0b\x64\x65scription\x18\x03 \x01(\t:7\xe2?4\n2com.databricks.rpc.RPC[UpdateModelVersionResponse]\"Y\n\x1aUpdateModelVersionResponse\x12;\n\rmodel_version\x18\x01 \x01(\x0b\x32$.mlflow.ucmodelregistry.ModelVersion\"\x7f\n\x19\x44\x65leteModelVersionRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01:7\xe2?4\n2com.databricks.rpc.RPC[DeleteModelVersionResponse]\"\x1c\n\x1a\x44\x65leteModelVersionResponse\"y\n\x16GetModelVersionRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01:4\xe2?1\n/com.databricks.rpc.RPC[GetModelVersionResponse]\"V\n\x17GetModelVersionResponse\x12;\n\rmodel_version\x18\x01 \x01(\x0b\x32$.mlflow.ucmodelregistry.ModelVersion\"\x96\x01\n\x1aSearchModelVersionsRequest\x12\x0e\n\x06\x66ilter\x18\x01 \x01(\t\x12\x1a\n\x0bmax_results\x18\x02 \x01(\x03:\x05\x31\x30\x30\x30\x30\x12\x12\n\npage_token\x18\x03 \x01(\t:8\xe2?5\n3com.databricks.rpc.RPC[SearchModelVersionsResponse]\"t\n\x1bSearchModelVersionsResponse\x12<\n\x0emodel_versions\x18\x01 \x03(\x0b\x32$.mlflow.ucmodelregistry.ModelVersion\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\t\"\xf3\x01\n/GenerateTemporaryModelVersionCredentialsRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x12\x46\n\toperation\x18\x03 \x01(\x0e\x32-.mlflow.ucmodelregistry.ModelVersionOperationB\x04\xf8\x86\x19\x01:M\xe2?J\nHcom.databricks.rpc.RPC[GenerateTemporaryModelVersionCredentialsResponse]\"u\n0GenerateTemporaryModelVersionCredentialsResponse\x12\x41\n\x0b\x63redentials\x18\x01 \x01(\x0b\x32,.mlflow.ucmodelregistry.TemporaryCredentials\"\x8f\x01\n!GetModelVersionDownloadUriRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01:?\xe2?<\n:com.databricks.rpc.RPC[GetModelVersionDownloadUriResponse]\":\n\"GetModelVersionDownloadUriResponse\x12\x14\n\x0c\x61rtifact_uri\x18\x01 \x01(\t\"\x83\x01\n\x1b\x46inalizeModelVersionRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01:9\xe2?6\n4com.databricks.rpc.RPC[FinalizeModelVersionResponse]\"[\n\x1c\x46inalizeModelVersionResponse\x12;\n\rmodel_version\x18\x01 \x01(\x0b\x32$.mlflow.ucmodelregistry.ModelVersion\"\x9e\x01\n\x1eSetRegisteredModelAliasRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x13\n\x05\x61lias\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x03 \x01(\tB\x04\xf8\x86\x19\x01:<\xe2?9\n7com.databricks.rpc.RPC[SetRegisteredModelAliasResponse]\"!\n\x1fSetRegisteredModelAliasResponse\"\x8d\x01\n!DeleteRegisteredModelAliasRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x13\n\x05\x61lias\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01:?\xe2?<\n:com.databricks.rpc.RPC[DeleteRegisteredModelAliasResponse]\"$\n\"DeleteRegisteredModelAliasResponse\"\x85\x01\n\x1dGetModelVersionByAliasRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x13\n\x05\x61lias\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01:;\xe2?8\n6com.databricks.rpc.RPC[GetModelVersionByAliasResponse]\"]\n\x1eGetModelVersionByAliasResponse\x12;\n\rmodel_version\x18\x01 \x01(\x0b\x32$.mlflow.ucmodelregistry.ModelVersion*c\n\x12ModelVersionStatus\x12\x0f\n\x0bUNSPECIFIED\x10\x00\x12\x18\n\x14PENDING_REGISTRATION\x10\x01\x12\x17\n\x13\x46\x41ILED_REGISTRATION\x10\x02\x12\t\n\x05READY\x10\x03*\x8a\x01\n\x15ModelVersionOperation\x12\'\n#MODEL_VERSION_OPERATION_UNSPECIFIED\x10\x00\x12 \n\x1cMODEL_VERSION_OPERATION_READ\x10\x01\x12&\n\"MODEL_VERSION_OPERATION_READ_WRITE\x10\x02\x42\x32\n(com.databricks.api.proto.ucmodelregistry\xa0\x01\x01\xe2?\x02\x10\x01')
+DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n%databricks_uc_registry_messages.proto\x12\x16mlflow.ucmodelregistry\x1a\x15scalapb/scalapb.proto\x1a\x10\x64\x61tabricks.proto\"\xc0\x01\n\x0fRegisteredModel\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x1a\n\x12\x63reation_timestamp\x18\x02 \x01(\x03\x12\x1e\n\x16last_updated_timestamp\x18\x03 \x01(\x03\x12\x0f\n\x07user_id\x18\x04 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x05 \x01(\t\x12=\n\x07\x61liases\x18\x06 \x03(\x0b\x32,.mlflow.ucmodelregistry.RegisteredModelAlias\"6\n\x14RegisteredModelAlias\x12\r\n\x05\x61lias\x18\x01 \x01(\t\x12\x0f\n\x07version\x18\x02 \x01(\t\"\x97\x03\n\x0cModelVersion\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0f\n\x07version\x18\x02 \x01(\t\x12\x1a\n\x12\x63reation_timestamp\x18\x03 \x01(\x03\x12\x1e\n\x16last_updated_timestamp\x18\x04 \x01(\x03\x12\x0f\n\x07user_id\x18\x05 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x06 \x01(\t\x12\x0e\n\x06source\x18\x07 \x01(\t\x12\x0e\n\x06run_id\x18\x08 \x01(\t\x12\x19\n\x11run_experiment_id\x18\t \x01(\t\x12\x1e\n\x16run_tracking_server_id\x18\n \x01(\t\x12:\n\x06status\x18\x0b \x01(\x0e\x32*.mlflow.ucmodelregistry.ModelVersionStatus\x12\x16\n\x0estatus_message\x18\x0c \x01(\t\x12\x18\n\x10storage_location\x18\r \x01(\t\x12=\n\x07\x61liases\x18\x0e \x03(\x0b\x32,.mlflow.ucmodelregistry.RegisteredModelAlias\"\x9d\x02\n\x14TemporaryCredentials\x12\x46\n\x14\x61ws_temp_credentials\x18\x02 \x01(\x0b\x32&.mlflow.ucmodelregistry.AwsCredentialsH\x00\x12S\n\x19\x61zure_user_delegation_sas\x18\x03 \x01(\x0b\x32..mlflow.ucmodelregistry.AzureUserDelegationSASH\x00\x12@\n\x0fgcp_oauth_token\x18\x04 \x01(\x0b\x32%.mlflow.ucmodelregistry.GcpOauthTokenH\x00\x12\x17\n\x0f\x65xpiration_time\x18\x01 \x01(\x03\x42\r\n\x0b\x63redentials\"Y\n\x0e\x41wsCredentials\x12\x15\n\raccess_key_id\x18\x01 \x01(\t\x12\x19\n\x11secret_access_key\x18\x02 \x01(\t\x12\x15\n\rsession_token\x18\x03 \x01(\t\"+\n\x16\x41zureUserDelegationSAS\x12\x11\n\tsas_token\x18\x01 \x01(\t\"$\n\rGcpOauthToken\x12\x13\n\x0boauth_token\x18\x01 \x01(\t\"\x83\x01\n\x1c\x43reateRegisteredModelRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x13\n\x0b\x64\x65scription\x18\x03 \x01(\t::\xe2?7\n5com.databricks.rpc.RPC[CreateRegisteredModelResponse]\"b\n\x1d\x43reateRegisteredModelResponse\x12\x41\n\x10registered_model\x18\x01 \x01(\x0b\x32\'.mlflow.ucmodelregistry.RegisteredModel\"\x83\x01\n\x1cUpdateRegisteredModelRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x13\n\x0b\x64\x65scription\x18\x02 \x01(\t::\xe2?7\n5com.databricks.rpc.RPC[UpdateRegisteredModelResponse]\"b\n\x1dUpdateRegisteredModelResponse\x12\x41\n\x10registered_model\x18\x01 \x01(\x0b\x32\'.mlflow.ucmodelregistry.RegisteredModel\"n\n\x1c\x44\x65leteRegisteredModelRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01::\xe2?7\n5com.databricks.rpc.RPC[DeleteRegisteredModelResponse]\"\x1f\n\x1d\x44\x65leteRegisteredModelResponse\"h\n\x19GetRegisteredModelRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01:7\xe2?4\n2com.databricks.rpc.RPC[GetRegisteredModelResponse]\"_\n\x1aGetRegisteredModelResponse\x12\x41\n\x10registered_model\x18\x01 \x01(\x0b\x32\'.mlflow.ucmodelregistry.RegisteredModel\"\x8a\x01\n\x1dSearchRegisteredModelsRequest\x12\x18\n\x0bmax_results\x18\x01 \x01(\x03:\x03\x31\x30\x30\x12\x12\n\npage_token\x18\x02 \x01(\t:;\xe2?8\n6com.databricks.rpc.RPC[SearchRegisteredModelsResponse]\"}\n\x1eSearchRegisteredModelsResponse\x12\x42\n\x11registered_models\x18\x01 \x03(\x0b\x32\'.mlflow.ucmodelregistry.RegisteredModel\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\t\"\xc3\x01\n\x19\x43reateModelVersionRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x14\n\x06source\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x12\x0e\n\x06run_id\x18\x03 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x04 \x01(\t\x12\x1e\n\x16run_tracking_server_id\x18\x05 \x01(\t:7\xe2?4\n2com.databricks.rpc.RPC[CreateModelVersionResponse]\"Y\n\x1a\x43reateModelVersionResponse\x12;\n\rmodel_version\x18\x01 \x01(\x0b\x32$.mlflow.ucmodelregistry.ModelVersion\"\x94\x01\n\x19UpdateModelVersionRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x12\x13\n\x0b\x64\x65scription\x18\x03 \x01(\t:7\xe2?4\n2com.databricks.rpc.RPC[UpdateModelVersionResponse]\"Y\n\x1aUpdateModelVersionResponse\x12;\n\rmodel_version\x18\x01 \x01(\x0b\x32$.mlflow.ucmodelregistry.ModelVersion\"\x7f\n\x19\x44\x65leteModelVersionRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01:7\xe2?4\n2com.databricks.rpc.RPC[DeleteModelVersionResponse]\"\x1c\n\x1a\x44\x65leteModelVersionResponse\"y\n\x16GetModelVersionRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01:4\xe2?1\n/com.databricks.rpc.RPC[GetModelVersionResponse]\"V\n\x17GetModelVersionResponse\x12;\n\rmodel_version\x18\x01 \x01(\x0b\x32$.mlflow.ucmodelregistry.ModelVersion\"\x96\x01\n\x1aSearchModelVersionsRequest\x12\x0e\n\x06\x66ilter\x18\x01 \x01(\t\x12\x1a\n\x0bmax_results\x18\x02 \x01(\x03:\x05\x31\x30\x30\x30\x30\x12\x12\n\npage_token\x18\x03 \x01(\t:8\xe2?5\n3com.databricks.rpc.RPC[SearchModelVersionsResponse]\"t\n\x1bSearchModelVersionsResponse\x12<\n\x0emodel_versions\x18\x01 \x03(\x0b\x32$.mlflow.ucmodelregistry.ModelVersion\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\t\"\xf3\x01\n/GenerateTemporaryModelVersionCredentialsRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x12\x46\n\toperation\x18\x03 \x01(\x0e\x32-.mlflow.ucmodelregistry.ModelVersionOperationB\x04\xf8\x86\x19\x01:M\xe2?J\nHcom.databricks.rpc.RPC[GenerateTemporaryModelVersionCredentialsResponse]\"u\n0GenerateTemporaryModelVersionCredentialsResponse\x12\x41\n\x0b\x63redentials\x18\x01 \x01(\x0b\x32,.mlflow.ucmodelregistry.TemporaryCredentials\"\x8f\x01\n!GetModelVersionDownloadUriRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01:?\xe2?<\n:com.databricks.rpc.RPC[GetModelVersionDownloadUriResponse]\":\n\"GetModelVersionDownloadUriResponse\x12\x14\n\x0c\x61rtifact_uri\x18\x01 \x01(\t\"\x83\x01\n\x1b\x46inalizeModelVersionRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01:9\xe2?6\n4com.databricks.rpc.RPC[FinalizeModelVersionResponse]\"[\n\x1c\x46inalizeModelVersionResponse\x12;\n\rmodel_version\x18\x01 \x01(\x0b\x32$.mlflow.ucmodelregistry.ModelVersion\"\x9e\x01\n\x1eSetRegisteredModelAliasRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x13\n\x05\x61lias\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x03 \x01(\tB\x04\xf8\x86\x19\x01:<\xe2?9\n7com.databricks.rpc.RPC[SetRegisteredModelAliasResponse]\"!\n\x1fSetRegisteredModelAliasResponse\"\x8d\x01\n!DeleteRegisteredModelAliasRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x13\n\x05\x61lias\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01:?\xe2?<\n:com.databricks.rpc.RPC[DeleteRegisteredModelAliasResponse]\"$\n\"DeleteRegisteredModelAliasResponse\"\x85\x01\n\x1dGetModelVersionByAliasRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x13\n\x05\x61lias\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01:;\xe2?8\n6com.databricks.rpc.RPC[GetModelVersionByAliasResponse]\"]\n\x1eGetModelVersionByAliasResponse\x12;\n\rmodel_version\x18\x01 \x01(\x0b\x32$.mlflow.ucmodelregistry.ModelVersion*c\n\x12ModelVersionStatus\x12\x0f\n\x0bUNSPECIFIED\x10\x00\x12\x18\n\x14PENDING_REGISTRATION\x10\x01\x12\x17\n\x13\x46\x41ILED_REGISTRATION\x10\x02\x12\t\n\x05READY\x10\x03*\x8a\x01\n\x15ModelVersionOperation\x12\'\n#MODEL_VERSION_OPERATION_UNSPECIFIED\x10\x00\x12 \n\x1cMODEL_VERSION_OPERATION_READ\x10\x01\x12&\n\"MODEL_VERSION_OPERATION_READ_WRITE\x10\x02\x42\x32\n(com.databricks.api.proto.ucmodelregistry\xa0\x01\x01\xe2?\x02\x10\x01')
 
 _MODELVERSIONSTATUS = DESCRIPTOR.enum_types_by_name['ModelVersionStatus']
 ModelVersionStatus = enum_type_wrapper.EnumTypeWrapper(_MODELVERSIONSTATUS)
 _MODELVERSIONOPERATION = DESCRIPTOR.enum_types_by_name['ModelVersionOperation']
 ModelVersionOperation = enum_type_wrapper.EnumTypeWrapper(_MODELVERSIONOPERATION)
 UNSPECIFIED = 0
 PENDING_REGISTRATION = 1
@@ -29,14 +29,15 @@
 READY = 3
 MODEL_VERSION_OPERATION_UNSPECIFIED = 0
 MODEL_VERSION_OPERATION_READ = 1
 MODEL_VERSION_OPERATION_READ_WRITE = 2
 
 
 _REGISTEREDMODEL = DESCRIPTOR.message_types_by_name['RegisteredModel']
+_REGISTEREDMODELALIAS = DESCRIPTOR.message_types_by_name['RegisteredModelAlias']
 _MODELVERSION = DESCRIPTOR.message_types_by_name['ModelVersion']
 _TEMPORARYCREDENTIALS = DESCRIPTOR.message_types_by_name['TemporaryCredentials']
 _AWSCREDENTIALS = DESCRIPTOR.message_types_by_name['AwsCredentials']
 _AZUREUSERDELEGATIONSAS = DESCRIPTOR.message_types_by_name['AzureUserDelegationSAS']
 _GCPOAUTHTOKEN = DESCRIPTOR.message_types_by_name['GcpOauthToken']
 _CREATEREGISTEREDMODELREQUEST = DESCRIPTOR.message_types_by_name['CreateRegisteredModelRequest']
 _CREATEREGISTEREDMODELRESPONSE = DESCRIPTOR.message_types_by_name['CreateRegisteredModelResponse']
@@ -73,14 +74,21 @@
 RegisteredModel = _reflection.GeneratedProtocolMessageType('RegisteredModel', (_message.Message,), {
   'DESCRIPTOR' : _REGISTEREDMODEL,
   '__module__' : 'databricks_uc_registry_messages_pb2'
   # @@protoc_insertion_point(class_scope:mlflow.ucmodelregistry.RegisteredModel)
   })
 _sym_db.RegisterMessage(RegisteredModel)
 
+RegisteredModelAlias = _reflection.GeneratedProtocolMessageType('RegisteredModelAlias', (_message.Message,), {
+  'DESCRIPTOR' : _REGISTEREDMODELALIAS,
+  '__module__' : 'databricks_uc_registry_messages_pb2'
+  # @@protoc_insertion_point(class_scope:mlflow.ucmodelregistry.RegisteredModelAlias)
+  })
+_sym_db.RegisterMessage(RegisteredModelAlias)
+
 ModelVersion = _reflection.GeneratedProtocolMessageType('ModelVersion', (_message.Message,), {
   'DESCRIPTOR' : _MODELVERSION,
   '__module__' : 'databricks_uc_registry_messages_pb2'
   # @@protoc_insertion_point(class_scope:mlflow.ucmodelregistry.ModelVersion)
   })
 _sym_db.RegisterMessage(ModelVersion)
 
@@ -420,88 +428,90 @@
   _DELETEREGISTEREDMODELALIASREQUEST._serialized_options = b'\342?<\n:com.databricks.rpc.RPC[DeleteRegisteredModelAliasResponse]'
   _GETMODELVERSIONBYALIASREQUEST.fields_by_name['name']._options = None
   _GETMODELVERSIONBYALIASREQUEST.fields_by_name['name']._serialized_options = b'\370\206\031\001'
   _GETMODELVERSIONBYALIASREQUEST.fields_by_name['alias']._options = None
   _GETMODELVERSIONBYALIASREQUEST.fields_by_name['alias']._serialized_options = b'\370\206\031\001'
   _GETMODELVERSIONBYALIASREQUEST._options = None
   _GETMODELVERSIONBYALIASREQUEST._serialized_options = b'\342?8\n6com.databricks.rpc.RPC[GetModelVersionByAliasResponse]'
-  _MODELVERSIONSTATUS._serialized_start=4710
-  _MODELVERSIONSTATUS._serialized_end=4809
-  _MODELVERSIONOPERATION._serialized_start=4812
-  _MODELVERSIONOPERATION._serialized_end=4950
+  _MODELVERSIONSTATUS._serialized_start=4892
+  _MODELVERSIONSTATUS._serialized_end=4991
+  _MODELVERSIONOPERATION._serialized_start=4994
+  _MODELVERSIONOPERATION._serialized_end=5132
   _REGISTEREDMODEL._serialized_start=107
-  _REGISTEREDMODEL._serialized_end=236
-  _MODELVERSION._serialized_start=239
-  _MODELVERSION._serialized_end=583
-  _TEMPORARYCREDENTIALS._serialized_start=586
-  _TEMPORARYCREDENTIALS._serialized_end=871
-  _AWSCREDENTIALS._serialized_start=873
-  _AWSCREDENTIALS._serialized_end=962
-  _AZUREUSERDELEGATIONSAS._serialized_start=964
-  _AZUREUSERDELEGATIONSAS._serialized_end=1007
-  _GCPOAUTHTOKEN._serialized_start=1009
-  _GCPOAUTHTOKEN._serialized_end=1045
-  _CREATEREGISTEREDMODELREQUEST._serialized_start=1048
-  _CREATEREGISTEREDMODELREQUEST._serialized_end=1179
-  _CREATEREGISTEREDMODELRESPONSE._serialized_start=1181
-  _CREATEREGISTEREDMODELRESPONSE._serialized_end=1279
-  _UPDATEREGISTEREDMODELREQUEST._serialized_start=1282
-  _UPDATEREGISTEREDMODELREQUEST._serialized_end=1413
-  _UPDATEREGISTEREDMODELRESPONSE._serialized_start=1415
-  _UPDATEREGISTEREDMODELRESPONSE._serialized_end=1513
-  _DELETEREGISTEREDMODELREQUEST._serialized_start=1515
-  _DELETEREGISTEREDMODELREQUEST._serialized_end=1625
-  _DELETEREGISTEREDMODELRESPONSE._serialized_start=1627
-  _DELETEREGISTEREDMODELRESPONSE._serialized_end=1658
-  _GETREGISTEREDMODELREQUEST._serialized_start=1660
-  _GETREGISTEREDMODELREQUEST._serialized_end=1764
-  _GETREGISTEREDMODELRESPONSE._serialized_start=1766
-  _GETREGISTEREDMODELRESPONSE._serialized_end=1861
-  _SEARCHREGISTEREDMODELSREQUEST._serialized_start=1864
-  _SEARCHREGISTEREDMODELSREQUEST._serialized_end=2002
-  _SEARCHREGISTEREDMODELSRESPONSE._serialized_start=2004
-  _SEARCHREGISTEREDMODELSRESPONSE._serialized_end=2129
-  _CREATEMODELVERSIONREQUEST._serialized_start=2132
-  _CREATEMODELVERSIONREQUEST._serialized_end=2327
-  _CREATEMODELVERSIONRESPONSE._serialized_start=2329
-  _CREATEMODELVERSIONRESPONSE._serialized_end=2418
-  _UPDATEMODELVERSIONREQUEST._serialized_start=2421
-  _UPDATEMODELVERSIONREQUEST._serialized_end=2569
-  _UPDATEMODELVERSIONRESPONSE._serialized_start=2571
-  _UPDATEMODELVERSIONRESPONSE._serialized_end=2660
-  _DELETEMODELVERSIONREQUEST._serialized_start=2662
-  _DELETEMODELVERSIONREQUEST._serialized_end=2789
-  _DELETEMODELVERSIONRESPONSE._serialized_start=2791
-  _DELETEMODELVERSIONRESPONSE._serialized_end=2819
-  _GETMODELVERSIONREQUEST._serialized_start=2821
-  _GETMODELVERSIONREQUEST._serialized_end=2942
-  _GETMODELVERSIONRESPONSE._serialized_start=2944
-  _GETMODELVERSIONRESPONSE._serialized_end=3030
-  _SEARCHMODELVERSIONSREQUEST._serialized_start=3033
-  _SEARCHMODELVERSIONSREQUEST._serialized_end=3183
-  _SEARCHMODELVERSIONSRESPONSE._serialized_start=3185
-  _SEARCHMODELVERSIONSRESPONSE._serialized_end=3301
-  _GENERATETEMPORARYMODELVERSIONCREDENTIALSREQUEST._serialized_start=3304
-  _GENERATETEMPORARYMODELVERSIONCREDENTIALSREQUEST._serialized_end=3547
-  _GENERATETEMPORARYMODELVERSIONCREDENTIALSRESPONSE._serialized_start=3549
-  _GENERATETEMPORARYMODELVERSIONCREDENTIALSRESPONSE._serialized_end=3666
-  _GETMODELVERSIONDOWNLOADURIREQUEST._serialized_start=3669
-  _GETMODELVERSIONDOWNLOADURIREQUEST._serialized_end=3812
-  _GETMODELVERSIONDOWNLOADURIRESPONSE._serialized_start=3814
-  _GETMODELVERSIONDOWNLOADURIRESPONSE._serialized_end=3872
-  _FINALIZEMODELVERSIONREQUEST._serialized_start=3875
-  _FINALIZEMODELVERSIONREQUEST._serialized_end=4006
-  _FINALIZEMODELVERSIONRESPONSE._serialized_start=4008
-  _FINALIZEMODELVERSIONRESPONSE._serialized_end=4099
-  _SETREGISTEREDMODELALIASREQUEST._serialized_start=4102
-  _SETREGISTEREDMODELALIASREQUEST._serialized_end=4260
-  _SETREGISTEREDMODELALIASRESPONSE._serialized_start=4262
-  _SETREGISTEREDMODELALIASRESPONSE._serialized_end=4295
-  _DELETEREGISTEREDMODELALIASREQUEST._serialized_start=4298
-  _DELETEREGISTEREDMODELALIASREQUEST._serialized_end=4439
-  _DELETEREGISTEREDMODELALIASRESPONSE._serialized_start=4441
-  _DELETEREGISTEREDMODELALIASRESPONSE._serialized_end=4477
-  _GETMODELVERSIONBYALIASREQUEST._serialized_start=4480
-  _GETMODELVERSIONBYALIASREQUEST._serialized_end=4613
-  _GETMODELVERSIONBYALIASRESPONSE._serialized_start=4615
-  _GETMODELVERSIONBYALIASRESPONSE._serialized_end=4708
+  _REGISTEREDMODEL._serialized_end=299
+  _REGISTEREDMODELALIAS._serialized_start=301
+  _REGISTEREDMODELALIAS._serialized_end=355
+  _MODELVERSION._serialized_start=358
+  _MODELVERSION._serialized_end=765
+  _TEMPORARYCREDENTIALS._serialized_start=768
+  _TEMPORARYCREDENTIALS._serialized_end=1053
+  _AWSCREDENTIALS._serialized_start=1055
+  _AWSCREDENTIALS._serialized_end=1144
+  _AZUREUSERDELEGATIONSAS._serialized_start=1146
+  _AZUREUSERDELEGATIONSAS._serialized_end=1189
+  _GCPOAUTHTOKEN._serialized_start=1191
+  _GCPOAUTHTOKEN._serialized_end=1227
+  _CREATEREGISTEREDMODELREQUEST._serialized_start=1230
+  _CREATEREGISTEREDMODELREQUEST._serialized_end=1361
+  _CREATEREGISTEREDMODELRESPONSE._serialized_start=1363
+  _CREATEREGISTEREDMODELRESPONSE._serialized_end=1461
+  _UPDATEREGISTEREDMODELREQUEST._serialized_start=1464
+  _UPDATEREGISTEREDMODELREQUEST._serialized_end=1595
+  _UPDATEREGISTEREDMODELRESPONSE._serialized_start=1597
+  _UPDATEREGISTEREDMODELRESPONSE._serialized_end=1695
+  _DELETEREGISTEREDMODELREQUEST._serialized_start=1697
+  _DELETEREGISTEREDMODELREQUEST._serialized_end=1807
+  _DELETEREGISTEREDMODELRESPONSE._serialized_start=1809
+  _DELETEREGISTEREDMODELRESPONSE._serialized_end=1840
+  _GETREGISTEREDMODELREQUEST._serialized_start=1842
+  _GETREGISTEREDMODELREQUEST._serialized_end=1946
+  _GETREGISTEREDMODELRESPONSE._serialized_start=1948
+  _GETREGISTEREDMODELRESPONSE._serialized_end=2043
+  _SEARCHREGISTEREDMODELSREQUEST._serialized_start=2046
+  _SEARCHREGISTEREDMODELSREQUEST._serialized_end=2184
+  _SEARCHREGISTEREDMODELSRESPONSE._serialized_start=2186
+  _SEARCHREGISTEREDMODELSRESPONSE._serialized_end=2311
+  _CREATEMODELVERSIONREQUEST._serialized_start=2314
+  _CREATEMODELVERSIONREQUEST._serialized_end=2509
+  _CREATEMODELVERSIONRESPONSE._serialized_start=2511
+  _CREATEMODELVERSIONRESPONSE._serialized_end=2600
+  _UPDATEMODELVERSIONREQUEST._serialized_start=2603
+  _UPDATEMODELVERSIONREQUEST._serialized_end=2751
+  _UPDATEMODELVERSIONRESPONSE._serialized_start=2753
+  _UPDATEMODELVERSIONRESPONSE._serialized_end=2842
+  _DELETEMODELVERSIONREQUEST._serialized_start=2844
+  _DELETEMODELVERSIONREQUEST._serialized_end=2971
+  _DELETEMODELVERSIONRESPONSE._serialized_start=2973
+  _DELETEMODELVERSIONRESPONSE._serialized_end=3001
+  _GETMODELVERSIONREQUEST._serialized_start=3003
+  _GETMODELVERSIONREQUEST._serialized_end=3124
+  _GETMODELVERSIONRESPONSE._serialized_start=3126
+  _GETMODELVERSIONRESPONSE._serialized_end=3212
+  _SEARCHMODELVERSIONSREQUEST._serialized_start=3215
+  _SEARCHMODELVERSIONSREQUEST._serialized_end=3365
+  _SEARCHMODELVERSIONSRESPONSE._serialized_start=3367
+  _SEARCHMODELVERSIONSRESPONSE._serialized_end=3483
+  _GENERATETEMPORARYMODELVERSIONCREDENTIALSREQUEST._serialized_start=3486
+  _GENERATETEMPORARYMODELVERSIONCREDENTIALSREQUEST._serialized_end=3729
+  _GENERATETEMPORARYMODELVERSIONCREDENTIALSRESPONSE._serialized_start=3731
+  _GENERATETEMPORARYMODELVERSIONCREDENTIALSRESPONSE._serialized_end=3848
+  _GETMODELVERSIONDOWNLOADURIREQUEST._serialized_start=3851
+  _GETMODELVERSIONDOWNLOADURIREQUEST._serialized_end=3994
+  _GETMODELVERSIONDOWNLOADURIRESPONSE._serialized_start=3996
+  _GETMODELVERSIONDOWNLOADURIRESPONSE._serialized_end=4054
+  _FINALIZEMODELVERSIONREQUEST._serialized_start=4057
+  _FINALIZEMODELVERSIONREQUEST._serialized_end=4188
+  _FINALIZEMODELVERSIONRESPONSE._serialized_start=4190
+  _FINALIZEMODELVERSIONRESPONSE._serialized_end=4281
+  _SETREGISTEREDMODELALIASREQUEST._serialized_start=4284
+  _SETREGISTEREDMODELALIASREQUEST._serialized_end=4442
+  _SETREGISTEREDMODELALIASRESPONSE._serialized_start=4444
+  _SETREGISTEREDMODELALIASRESPONSE._serialized_end=4477
+  _DELETEREGISTEREDMODELALIASREQUEST._serialized_start=4480
+  _DELETEREGISTEREDMODELALIASREQUEST._serialized_end=4621
+  _DELETEREGISTEREDMODELALIASRESPONSE._serialized_start=4623
+  _DELETEREGISTEREDMODELALIASRESPONSE._serialized_end=4659
+  _GETMODELVERSIONBYALIASREQUEST._serialized_start=4662
+  _GETMODELVERSIONBYALIASREQUEST._serialized_end=4795
+  _GETMODELVERSIONBYALIASRESPONSE._serialized_start=4797
+  _GETMODELVERSIONBYALIASRESPONSE._serialized_end=4890
 # @@protoc_insertion_point(module_scope)
```

## mlflow/pytorch/__init__.py

```diff
@@ -101,15 +101,15 @@
     .. code-block:: python
         :caption: Example
 
         import mlflow.pytorch
 
         # Log PyTorch model
         with mlflow.start_run() as run:
-            mlflow.pytorch.log_model(model, "model")
+            mlflow.pytorch.log_model(model, "model", signature=signature)
 
         # Fetch the associated conda environment
         env = mlflow.pytorch.get_default_conda_env()
         print("conda env: {}".format(env))
 
     .. code-block:: text
         :caption: Output
@@ -244,56 +244,44 @@
              metadata of the logged model.
 
     .. code-block:: python
         :caption: Example
 
         import numpy as np
         import torch
-        import mlflow.pytorch
-
-
-        class LinearNNModel(torch.nn.Module):
-            def __init__(self):
-                super().__init__()
-                self.linear = torch.nn.Linear(1, 1)  # One in and one out
-
-            def forward(self, x):
-                y_pred = self.linear(x)
-                return y_pred
-
-
-        def gen_data():
-            # Example linear model modified to use y = 2x
-            # from https://github.com/hunkim/PyTorchZeroToAll
-            # X training data, y labels
-            X = torch.arange(1.0, 25.0).view(-1, 1)
-            y = torch.from_numpy(np.array([x * 2 for x in X])).view(-1, 1)
-            return X, y
-
+        import mlflow
+        from mlflow import MlflowClient
+        from mlflow.models.signature import infer_signature
 
         # Define model, loss, and optimizer
-        model = LinearNNModel()
+        model = nn.Linear(1, 1)
         criterion = torch.nn.MSELoss()
         optimizer = torch.optim.SGD(model.parameters(), lr=0.001)
 
+        # Create training data with relationship y = 2X
+        X = torch.arange(1.0, 26.0).reshape(-1, 1)
+        y = X * 2
+
         # Training loop
         epochs = 250
-        X, y = gen_data()
         for epoch in range(epochs):
             # Forward pass: Compute predicted y by passing X to the model
             y_pred = model(X)
 
             # Compute the loss
             loss = criterion(y_pred, y)
 
             # Zero gradients, perform a backward pass, and update the weights.
             optimizer.zero_grad()
             loss.backward()
             optimizer.step()
 
+        # Create model signature
+        signature = infer_signature(X.numpy(), model(X).detach().numpy())
+
         # Log the model
         with mlflow.start_run() as run:
             mlflow.pytorch.log_model(model, "model")
 
             # convert to scripted model and log the model
             scripted_pytorch_model = torch.jit.script(model)
             mlflow.pytorch.log_model(scripted_pytorch_model, "scripted_model")
@@ -717,15 +705,15 @@
         ...
 
         # Training loop
         ...
 
         # Log the model
         with mlflow.start_run() as run:
-            mlflow.pytorch.log_model(model, "model")
+            mlflow.pytorch.log_model(model, "model", signature=signature)
 
         # Inference after loading the logged model
         model_uri = "runs:/{}/model".format(run.info.run_id)
         loaded_model = mlflow.pytorch.load_model(model_uri)
         for x in [4.0, 6.0, 30.0]:
             X = torch.Tensor([[x]])
             y_pred = loaded_model(X)
```

## mlflow/server/handlers.py

```diff
@@ -1091,22 +1091,21 @@
 
 
 @catch_mlflow_exception
 @_disable_if_artifacts_only
 def _log_batch():
     def _assert_metrics_fields_present(metrics):
         for m in metrics:
-            _assert_required(m["key"])
-            _assert_required(m["value"])
-            _assert_required(m["timestamp"])
-            _assert_required(m["step"])
+            _assert_required(m.get("key"))
+            _assert_required(m.get("value"))
+            _assert_required(m.get("timestamp"))
 
     def _assert_params_tags_fields_present(params_or_tags):
         for param_or_tag in params_or_tags:
-            _assert_required(param_or_tag["key"])
+            _assert_required(param_or_tag.get("key"))
 
     _validate_batch_log_api_req(_get_request_json())
     request_message = _get_request_message(
         LogBatch(),
         schema={
             "run_id": [_assert_string, _assert_required],
             "metrics": [_assert_array, _assert_metrics_fields_present],
@@ -1766,33 +1765,33 @@
     """
     :param request_class: The type of protobuf message
     :return:
     """
     return HANDLERS.get(request_class, _not_implemented)
 
 
-def get_endpoints():
+def get_service_endpoints(service, get_handler):
+    ret = []
+    for service_method in service.DESCRIPTOR.methods:
+        endpoints = service_method.GetOptions().Extensions[databricks_pb2.rpc].endpoints
+        for endpoint in endpoints:
+            for http_path in _get_paths(endpoint.path):
+                handler = get_handler(service().GetRequestClass(service_method))
+                ret.append((http_path, handler, [endpoint.method]))
+    return ret
+
+
+def get_endpoints(get_handler=get_handler):
     """
     :return: List of tuples (path, handler, methods)
     """
-
-    def get_service_endpoints(service):
-        ret = []
-        for service_method in service.DESCRIPTOR.methods:
-            endpoints = service_method.GetOptions().Extensions[databricks_pb2.rpc].endpoints
-            for endpoint in endpoints:
-                for http_path in _get_paths(endpoint.path):
-                    handler = get_handler(service().GetRequestClass(service_method))
-                    ret.append((http_path, handler, [endpoint.method]))
-        return ret
-
     return (
-        get_service_endpoints(MlflowService)
-        + get_service_endpoints(ModelRegistryService)
-        + get_service_endpoints(MlflowArtifactsService)
+        get_service_endpoints(MlflowService, get_handler)
+        + get_service_endpoints(ModelRegistryService, get_handler)
+        + get_service_endpoints(MlflowArtifactsService, get_handler)
     )
 
 
 HANDLERS = {
     # Tracking Server APIs
     CreateExperiment: _create_experiment,
     GetExperiment: _get_experiment,
```

## mlflow/server/auth/__init__.py

```diff
@@ -7,39 +7,126 @@
     mlflow server --app-name basic-auth
 """
 
 import logging
 import uuid
 import os
 from pathlib import Path
-from flask import Flask, request, make_response, Response, redirect, flash, render_template_string
+from typing import Callable, Optional
 
+from flask import Flask, request, make_response, Response, flash, render_template_string
+
+from mlflow import get_run, MlflowException
 from mlflow.server import app
 from mlflow.server.auth.config import read_auth_config
+from mlflow.server.auth.logo import MLFLOW_LOGO
+from mlflow.server.auth.permissions import get_permission, Permission, MANAGE
 from mlflow.server.auth.sqlalchemy_store import SqlAlchemyStore
-from mlflow.server.handlers import _get_rest_path, catch_mlflow_exception
+from mlflow.server.handlers import (
+    _get_rest_path,
+    _get_tracking_store,
+    catch_mlflow_exception,
+    get_endpoints,
+)
 from mlflow.tracking._tracking_service.utils import (
     _TRACKING_USERNAME_ENV_VAR,
     _TRACKING_PASSWORD_ENV_VAR,
 )
+from mlflow.protos.databricks_pb2 import (
+    ErrorCode,
+    BAD_REQUEST,
+    INVALID_PARAMETER_VALUE,
+    RESOURCE_DOES_NOT_EXIST,
+)
+from mlflow.protos.service_pb2 import (
+    GetExperiment,
+    GetRun,
+    ListArtifacts,
+    GetMetricHistory,
+    CreateRun,
+    UpdateRun,
+    LogMetric,
+    LogParam,
+    SetTag,
+    DeleteExperiment,
+    RestoreExperiment,
+    RestoreRun,
+    DeleteRun,
+    UpdateExperiment,
+    LogBatch,
+    DeleteTag,
+    SetExperimentTag,
+    GetExperimentByName,
+    LogModel,
+    CreateExperiment,
+)
+from mlflow.protos.model_registry_pb2 import (
+    GetRegisteredModel,
+    DeleteRegisteredModel,
+    UpdateRegisteredModel,
+    RenameRegisteredModel,
+    GetLatestVersions,
+    CreateModelVersion,
+    GetModelVersion,
+    DeleteModelVersion,
+    UpdateModelVersion,
+    TransitionModelVersionStage,
+    GetModelVersionDownloadUri,
+    SetRegisteredModelTag,
+    DeleteRegisteredModelTag,
+    SetModelVersionTag,
+    DeleteModelVersionTag,
+    SetRegisteredModelAlias,
+    DeleteRegisteredModelAlias,
+    GetModelVersionByAlias,
+    CreateRegisteredModel,
+)
+from mlflow.utils.proto_json_utils import parse_dict
 
 _AUTH_CONFIG_PATH_ENV_VAR = "MLFLOW_AUTH_CONFIG_PATH"
 
 _logger = logging.getLogger(__name__)
 
+
+def _get_auth_config_path():
+    return os.environ.get(
+        _AUTH_CONFIG_PATH_ENV_VAR, (Path(__file__).parent / "basic_auth.ini").resolve()
+    )
+
+
+auth_config_path = _get_auth_config_path()
+auth_config = read_auth_config(auth_config_path)
 store = SqlAlchemyStore()
 
 
 class ROUTES:
     HOME = "/"
-    USERS = _get_rest_path("/mlflow/users")
     SIGNUP = "/signup"
+    CREATE_USER = _get_rest_path("/mlflow/users/create")
+    GET_USER = _get_rest_path("/mlflow/users/get")
+    UPDATE_USER_PASSWORD = _get_rest_path("/mlflow/users/update-password")
+    UPDATE_USER_ADMIN = _get_rest_path("/mlflow/users/update-admin")
+    DELETE_USER = _get_rest_path("/mlflow/users/delete")
+    CREATE_EXPERIMENT_PERMISSION = _get_rest_path("/mlflow/experiments/permissions/create")
+    GET_EXPERIMENT_PERMISSION = _get_rest_path("/mlflow/experiments/permissions/get")
+    UPDATE_EXPERIMENT_PERMISSION = _get_rest_path("/mlflow/experiments/permissions/update")
+    DELETE_EXPERIMENT_PERMISSION = _get_rest_path("/mlflow/experiments/permissions/delete")
+    CREATE_REGISTERED_MODEL_PERMISSION = _get_rest_path(
+        "/mlflow/registered-models/permissions/create"
+    )
+    GET_REGISTERED_MODEL_PERMISSION = _get_rest_path("/mlflow/registered-models/permissions/get")
+    UPDATE_REGISTERED_MODEL_PERMISSION = _get_rest_path(
+        "/mlflow/registered-models/permissions/update"
+    )
+    DELETE_REGISTERED_MODEL_PERMISSION = _get_rest_path(
+        "/mlflow/registered-models/permissions/delete"
+    )
 
 
-UNPROTECTED_ROUTES = [ROUTES.USERS, ROUTES.SIGNUP]
+UNPROTECTED_ROUTES = [ROUTES.CREATE_USER, ROUTES.SIGNUP]
 
 
 def is_unprotected_route(path: str) -> bool:
     if path.startswith(("/static", "/favicon.ico")):
         return True
     return path in UNPROTECTED_ROUTES
 
@@ -51,14 +138,253 @@
         "You are not authenticated. Please set the environment variables "
         f"{_TRACKING_USERNAME_ENV_VAR} and {_TRACKING_PASSWORD_ENV_VAR}."
     )
     res.headers["WWW-Authenticate"] = 'Basic realm="mlflow"'
     return res
 
 
+def make_forbidden_response() -> Response:
+    res = make_response("Permission denied")
+    res.status_code = 403
+    return res
+
+
+def _get_request_param(param: str) -> Optional[str]:
+    if request.method == "GET":
+        args = request.args
+    elif request.method in ("POST", "PATCH", "DELETE"):
+        args = request.json
+    else:
+        raise MlflowException(
+            f"Unsupported HTTP method '{request.method}'",
+            BAD_REQUEST,
+        )
+
+    if param not in args:
+        raise MlflowException(
+            f"Missing value for required parameter '{param}'. "
+            "See the API docs for more information about request parameters.",
+            INVALID_PARAMETER_VALUE,
+        )
+    return args[param]
+
+
+def _get_permission_from_store_or_default(store_permission_func: Callable[[], str]) -> Permission:
+    """
+    Attempts to get permission from store,
+    and returns default permission if no record is found.
+    """
+    try:
+        perm = store_permission_func()
+    except MlflowException as e:
+        if e.error_code == ErrorCode.Name(RESOURCE_DOES_NOT_EXIST):
+            perm = auth_config.default_permission
+        else:
+            raise
+    return get_permission(perm)
+
+
+def _get_permission_from_experiment_id() -> Permission:
+    experiment_id = _get_request_param("experiment_id")
+    username = request.authorization.username
+    return _get_permission_from_store_or_default(
+        lambda: store.get_experiment_permission(experiment_id, username).permission
+    )
+
+
+def _get_permission_from_experiment_name() -> Permission:
+    experiment_name = _get_request_param("experiment_name")
+    store_exp = _get_tracking_store().get_experiment_by_name(experiment_name)
+    if store_exp is None:
+        raise MlflowException(
+            f"Could not find experiment with name {experiment_name}",
+            error_code=RESOURCE_DOES_NOT_EXIST,
+        )
+    username = request.authorization.username
+    return _get_permission_from_store_or_default(
+        lambda: store.get_experiment_permission(store_exp.experiment_id, username).permission
+    )
+
+
+def _get_permission_from_run_id() -> Permission:
+    # run permissions inherit from parent resource (experiment)
+    # so we just get the experiment permission
+    run_id = _get_request_param("run_id")
+    run = get_run(run_id)
+    experiment_id = run.info.experiment_id
+    username = request.authorization.username
+    return _get_permission_from_store_or_default(
+        lambda: store.get_experiment_permission(experiment_id, username).permission
+    )
+
+
+def _get_permission_from_registered_model_name() -> Permission:
+    name = _get_request_param("name")
+    username = request.authorization.username
+    return _get_permission_from_store_or_default(
+        lambda: store.get_registered_model_permission(name, username).permission
+    )
+
+
+def validate_can_read_experiment():
+    return _get_permission_from_experiment_id().can_read
+
+
+def validate_can_read_experiment_by_name():
+    return _get_permission_from_experiment_name().can_read
+
+
+def validate_can_update_experiment():
+    return _get_permission_from_experiment_id().can_update
+
+
+def validate_can_delete_experiment():
+    return _get_permission_from_experiment_id().can_delete
+
+
+def validate_can_manage_experiment():
+    return _get_permission_from_experiment_id().can_manage
+
+
+def validate_can_read_run():
+    return _get_permission_from_run_id().can_read
+
+
+def validate_can_update_run():
+    return _get_permission_from_run_id().can_update
+
+
+def validate_can_delete_run():
+    return _get_permission_from_run_id().can_delete
+
+
+def validate_can_manage_run():
+    return _get_permission_from_run_id().can_manage
+
+
+def validate_can_read_registered_model():
+    return _get_permission_from_registered_model_name().can_read
+
+
+def validate_can_update_registered_model():
+    return _get_permission_from_registered_model_name().can_update
+
+
+def validate_can_delete_registered_model():
+    return _get_permission_from_registered_model_name().can_delete
+
+
+def validate_can_manage_registered_model():
+    return _get_permission_from_registered_model_name().can_manage
+
+
+def sender_is_admin():
+    """Validate if the sender is admin"""
+    username = request.authorization.username
+    return store.get_user(username).is_admin
+
+
+def username_is_sender():
+    """Validate if the request username is the sender"""
+    username = _get_request_param("username")
+    sender = request.authorization.username
+    return username == sender
+
+
+def validate_can_read_user():
+    return username_is_sender()
+
+
+def validate_can_update_user_password():
+    return username_is_sender()
+
+
+def validate_can_update_user_admin():
+    # only admins can update, but admins won't reach this validator
+    return False
+
+
+def validate_can_delete_user():
+    # only admins can delete, but admins won't reach this validator
+    return False
+
+
+BEFORE_REQUEST_HANDLERS = {
+    # Routes for experiments
+    GetExperiment: validate_can_read_experiment,
+    GetExperimentByName: validate_can_read_experiment_by_name,
+    DeleteExperiment: validate_can_delete_experiment,
+    RestoreExperiment: validate_can_delete_experiment,
+    UpdateExperiment: validate_can_update_experiment,
+    SetExperimentTag: validate_can_update_experiment,
+    # Routes for runs
+    CreateRun: validate_can_update_experiment,
+    GetRun: validate_can_read_run,
+    DeleteRun: validate_can_delete_run,
+    RestoreRun: validate_can_delete_run,
+    UpdateRun: validate_can_update_run,
+    LogMetric: validate_can_update_run,
+    LogBatch: validate_can_update_run,
+    LogModel: validate_can_update_run,
+    SetTag: validate_can_update_run,
+    DeleteTag: validate_can_update_run,
+    LogParam: validate_can_update_run,
+    GetMetricHistory: validate_can_read_run,
+    ListArtifacts: validate_can_read_run,
+    # Routes for model registry
+    GetRegisteredModel: validate_can_read_registered_model,
+    DeleteRegisteredModel: validate_can_delete_registered_model,
+    UpdateRegisteredModel: validate_can_update_registered_model,
+    RenameRegisteredModel: validate_can_update_registered_model,
+    GetLatestVersions: validate_can_read_registered_model,
+    CreateModelVersion: validate_can_update_registered_model,
+    GetModelVersion: validate_can_read_registered_model,
+    DeleteModelVersion: validate_can_delete_registered_model,
+    UpdateModelVersion: validate_can_update_registered_model,
+    TransitionModelVersionStage: validate_can_update_registered_model,
+    GetModelVersionDownloadUri: validate_can_read_registered_model,
+    SetRegisteredModelTag: validate_can_update_registered_model,
+    DeleteRegisteredModelTag: validate_can_update_registered_model,
+    SetModelVersionTag: validate_can_update_registered_model,
+    DeleteModelVersionTag: validate_can_delete_registered_model,
+    SetRegisteredModelAlias: validate_can_update_registered_model,
+    DeleteRegisteredModelAlias: validate_can_delete_registered_model,
+    GetModelVersionByAlias: validate_can_read_registered_model,
+}
+
+
+def get_before_request_handler(request_class):
+    return BEFORE_REQUEST_HANDLERS.get(request_class)
+
+
+BEFORE_REQUEST_VALIDATORS = {
+    (http_path, method): handler
+    for http_path, handler, methods in get_endpoints(get_before_request_handler)
+    for method in methods
+}
+
+BEFORE_REQUEST_VALIDATORS.update(
+    {
+        (ROUTES.GET_USER, "GET"): validate_can_read_user,
+        (ROUTES.UPDATE_USER_PASSWORD, "PATCH"): validate_can_update_user_password,
+        (ROUTES.UPDATE_USER_ADMIN, "PATCH"): validate_can_update_user_admin,
+        (ROUTES.DELETE_USER, "DELETE"): validate_can_delete_user,
+        (ROUTES.GET_EXPERIMENT_PERMISSION, "GET"): validate_can_manage_experiment,
+        (ROUTES.CREATE_EXPERIMENT_PERMISSION, "POST"): validate_can_manage_experiment,
+        (ROUTES.UPDATE_EXPERIMENT_PERMISSION, "PATCH"): validate_can_manage_experiment,
+        (ROUTES.DELETE_EXPERIMENT_PERMISSION, "DELETE"): validate_can_manage_experiment,
+        (ROUTES.GET_REGISTERED_MODEL_PERMISSION, "GET"): validate_can_manage_registered_model,
+        (ROUTES.CREATE_REGISTERED_MODEL_PERMISSION, "POST"): validate_can_manage_registered_model,
+        (ROUTES.UPDATE_REGISTERED_MODEL_PERMISSION, "PATCH"): validate_can_manage_registered_model,
+        (ROUTES.DELETE_REGISTERED_MODEL_PERMISSION, "DELETE"): validate_can_manage_registered_model,
+    }
+)
+
+
+@catch_mlflow_exception
 def _before_request():
     if is_unprotected_route(request.path):
         return
 
     _user = request.authorization.username if request.authorization else None
     _logger.debug(f"before_request: {request.method} {request.path} (user: {_user})")
 
@@ -67,81 +393,306 @@
 
     username = request.authorization.username
     password = request.authorization.password
     if not store.authenticate_user(username, password):
         # let user attempt login again
         return make_basic_auth_response()
 
-    # TODO: Implement authorization
-    pass
+    # admins don't need to be authorized
+    if sender_is_admin():
+        _logger.debug(f"Admin (username={username}) authorization not required")
+        return
+
+    # authorization
+    if validator := BEFORE_REQUEST_VALIDATORS.get((request.path, request.method)):
+        _logger.debug(f"Calling validator: {validator.__name__}")
+        if not validator():
+            return make_forbidden_response()
+    else:
+        _logger.debug(f"No validator found for {(request.path, request.method)}")
+
+
+def set_can_manage_experiment_permission(resp: Response):
+    response_message = CreateExperiment.Response()
+    parse_dict(resp.json, response_message)
+    experiment_id = response_message.experiment_id
+    username = request.authorization.username
+    store.create_experiment_permission(experiment_id, username, MANAGE.name)
+
+
+def set_can_manage_registered_model_permission(resp: Response):
+    response_message = CreateRegisteredModel.Response()
+    parse_dict(resp.json, response_message)
+    name = response_message.registered_model.name
+    username = request.authorization.username
+    store.create_registered_model_permission(name, username, MANAGE.name)
+
+
+AFTER_REQUEST_PATH_HANDLERS = {
+    CreateExperiment: set_can_manage_experiment_permission,
+    CreateRegisteredModel: set_can_manage_registered_model_permission,
+}
+
+
+def get_after_request_handler(request_class):
+    return AFTER_REQUEST_PATH_HANDLERS.get(request_class)
 
 
-def _after_request(resp):
-    # TODO: Implement post-request logic
+AFTER_REQUEST_HANDLERS = {
+    (http_path, method): handler
+    for http_path, handler, methods in get_endpoints(get_after_request_handler)
+    for method in methods
+}
+
+
+@catch_mlflow_exception
+def _after_request(resp: Response):
+    _logger.debug(f"after_request: {request.method} {request.path}")
+    if 400 <= resp.status_code < 600:
+        return resp
+
+    if handler := AFTER_REQUEST_HANDLERS.get((request.path, request.method)):
+        _logger.debug(f"Calling after request handler: {handler.__name__}")
+        handler(resp)
     return resp
 
 
+def create_admin_user(username, password):
+    if not store.has_user(username):
+        store.create_user(username, password, is_admin=True)
+        _logger.info(
+            f"Created admin user '{username}'. "
+            "It is recommended that you set a new password as soon as possible "
+            f"on {ROUTES.UPDATE_USER_PASSWORD}."
+        )
+
+
+def alert(href: str):
+    return render_template_string(
+        r"""
+<script type = "text/javascript">
+{% with messages = get_flashed_messages() %}
+  {% if messages %}
+    {% for message in messages %}
+      alert("{{ message }}");
+    {% endfor %}
+  {% endif %}
+{% endwith %}
+      window.location.href = "{{ href }}";
+</script>
+""",
+        href=href,
+    )
+
+
 def signup():
-    # TODO: add css
     return render_template_string(
         r"""
+<style>
+  form {
+    background-color: #F5F5F5;
+    border: 1px solid #CCCCCC;
+    border-radius: 4px;
+    padding: 20px;
+    max-width: 400px;
+    margin: 0 auto;
+    font-family: Arial, sans-serif;
+    font-size: 14px;
+    line-height: 1.5;
+  }
+
+  input[type=text], input[type=password] {
+    width: 100%;
+    padding: 10px;
+    margin-bottom: 10px;
+    border: 1px solid #CCCCCC;
+    border-radius: 4px;
+    box-sizing: border-box;
+  }
+  input[type=submit] {
+    background-color: rgb(34, 114, 180);
+    color: #FFFFFF;
+    border: none;
+    border-radius: 4px;
+    padding: 10px 20px;
+    cursor: pointer;
+    font-size: 16px;
+    font-weight: bold;
+  }
+
+  input[type=submit]:hover {
+    background-color: rgb(14, 83, 139);
+  }
+
+  .logo-container {
+    display: flex;
+    align-items: center;
+    justify-content: center;
+    margin-bottom: 10px;
+  }
+
+  .logo {
+    max-width: 150px;
+    margin-right: 10px;
+  }
+</style>
+
 <form action="{{ users_route }}" method="post">
-  Username:
+  <div class="logo-container">
+    {% autoescape false %}
+    {{ mlflow_logo }}
+    {% endautoescape %}
+  </div>
+  <label for="username">Username:</label>
   <br>
-  <input type=text name=username>
+  <input type="text" id="username" name="username">
   <br>
-  Password:
+  <label for="password">Password:</label>
   <br>
-  <input type=password name=password>
+  <input type="password" id="password" name="password">
   <br>
   <br>
-  <input type="submit" value="Signup">
+  <input type="submit" value="Sign up">
 </form>
-<style>
-.alert.error {
-  color: red;
-}
-</style>
-{% with messages = get_flashed_messages(with_categories=true) %}
-  {% if messages %}
-    {% for category, message in messages %}
-      <p class="alert {{ category }}">{{ message }}</p>
-    {% endfor %}
-  {% endif %}
-{% endwith %}
 """,
-        users_route=ROUTES.USERS,
+        mlflow_logo=MLFLOW_LOGO,
+        users_route=ROUTES.CREATE_USER,
     )
 
 
 @catch_mlflow_exception
 def create_user():
     content_type = request.headers.get("Content-Type")
     if content_type == "application/x-www-form-urlencoded":
         username = request.form["username"]
         password = request.form["password"]
+
+        if store.has_user(username):
+            flash(f"Username has already been taken: {username}")
+            return alert(href=ROUTES.SIGNUP)
+
+        store.create_user(username, password)
+        flash(f"Successfully signed up user: {username}")
+        return alert(href=ROUTES.HOME)
     elif content_type == "application/json":
-        username = request.json["username"]
-        password = request.json["password"]
+        username = _get_request_param("username")
+        password = _get_request_param("password")
+
+        user = store.create_user(username, password)
+        return make_response({"user": user.to_json()})
     else:
         return make_response(f"Invalid content type: '{content_type}'", 400)
 
-    if store.has_user(username):
-        flash(f"Username has already been taken: '{username}'", category="error")
-        return redirect(ROUTES.SIGNUP)
-
-    store.create_user(username, password)
-    flash(f"Successfully signed up user: '{username}'")
-    return redirect(ROUTES.HOME)
 
+@catch_mlflow_exception
+def get_user():
+    username = _get_request_param("username")
+    user = store.get_user(username)
+    return make_response({"user": user.to_json()})
 
-def _get_auth_config_path():
-    return os.environ.get(
-        _AUTH_CONFIG_PATH_ENV_VAR, (Path(__file__).parent / "basic_auth.ini").resolve()
-    )
+
+@catch_mlflow_exception
+def update_user_password():
+    username = _get_request_param("username")
+    password = _get_request_param("password")
+    store.update_user(username, password=password)
+    return make_response({})
+
+
+@catch_mlflow_exception
+def update_user_admin():
+    username = _get_request_param("username")
+    is_admin_str = _get_request_param("is_admin").lower()
+    if is_admin_str == "true":
+        is_admin = True
+    elif is_admin_str == "false":
+        is_admin = False
+    else:
+        raise MlflowException(
+            f"Invalid parameter 'is_admin': '{is_admin_str}', "
+            "must be either 'true' or 'false' (case insensitive).",
+            INVALID_PARAMETER_VALUE,
+        )
+    store.update_user(username, is_admin=is_admin)
+    return make_response({})
+
+
+@catch_mlflow_exception
+def delete_user():
+    username = _get_request_param("username")
+    store.delete_user(username)
+    return make_response({})
+
+
+@catch_mlflow_exception
+def create_experiment_permission():
+    experiment_id = _get_request_param("experiment_id")
+    username = _get_request_param("username")
+    permission = _get_request_param("permission")
+    ep = store.create_experiment_permission(experiment_id, username, permission)
+    return make_response({"experiment_permission": ep.to_json()})
+
+
+@catch_mlflow_exception
+def get_experiment_permission():
+    experiment_id = _get_request_param("experiment_id")
+    username = _get_request_param("username")
+    ep = store.get_experiment_permission(experiment_id, username)
+    return make_response({"experiment_permission": ep.to_json()})
+
+
+@catch_mlflow_exception
+def update_experiment_permission():
+    experiment_id = _get_request_param("experiment_id")
+    username = _get_request_param("username")
+    permission = _get_request_param("permission")
+    store.update_experiment_permission(experiment_id, username, permission)
+    return make_response({})
+
+
+@catch_mlflow_exception
+def delete_experiment_permission():
+    experiment_id = _get_request_param("experiment_id")
+    username = _get_request_param("username")
+    store.delete_experiment_permission(experiment_id, username)
+    return make_response({})
+
+
+@catch_mlflow_exception
+def create_registered_model_permission():
+    name = _get_request_param("name")
+    username = _get_request_param("username")
+    permission = _get_request_param("permission")
+    rmp = store.create_registered_model_permission(name, username, permission)
+    return make_response({"registered_model_permission": rmp.to_json()})
+
+
+@catch_mlflow_exception
+def get_registered_model_permission():
+    name = _get_request_param("name")
+    username = _get_request_param("username")
+    rmp = store.get_registered_model_permission(name, username)
+    return make_response({"registered_model_permission": rmp.to_json()})
+
+
+@catch_mlflow_exception
+def update_registered_model_permission():
+    name = _get_request_param("name")
+    username = _get_request_param("username")
+    permission = _get_request_param("permission")
+    store.update_registered_model_permission(name, username, permission)
+    return make_response({})
+
+
+@catch_mlflow_exception
+def delete_registered_model_permission():
+    name = _get_request_param("name")
+    username = _get_request_param("username")
+    store.delete_registered_model_permission(name, username)
+    return make_response({})
 
 
 def _enable_auth(app: Flask):
     """
     Enables authentication and authorization for the MLflow server.
 
     :param app: The Flask app to enable authentication and authorization for.
@@ -149,28 +700,87 @@
     _logger.warning(
         "This feature is still experimental and may change in a future release without warning"
     )
     # secret key required for flashing
     if not app.secret_key:
         app.secret_key = str(uuid.uuid4())
 
-    auth_config_path = _get_auth_config_path()
-    auth_config = read_auth_config(auth_config_path)
     _logger.debug("Database URI: %s", auth_config.database_uri)
     store.init_db(auth_config.database_uri)
+    create_admin_user(auth_config.admin_username, auth_config.admin_password)
 
     app.add_url_rule(
         rule=ROUTES.SIGNUP,
         view_func=signup,
         methods=["GET"],
     )
     app.add_url_rule(
-        rule=ROUTES.USERS,
+        rule=ROUTES.CREATE_USER,
         view_func=create_user,
         methods=["POST"],
     )
+    app.add_url_rule(
+        rule=ROUTES.GET_USER,
+        view_func=get_user,
+        methods=["POST"],
+    )
+    app.add_url_rule(
+        rule=ROUTES.UPDATE_USER_PASSWORD,
+        view_func=update_user_password,
+        methods=["PATCH"],
+    )
+    app.add_url_rule(
+        rule=ROUTES.UPDATE_USER_ADMIN,
+        view_func=update_user_admin,
+        methods=["PATCH"],
+    )
+    app.add_url_rule(
+        rule=ROUTES.DELETE_USER,
+        view_func=delete_user,
+        methods=["DELETE"],
+    )
+    app.add_url_rule(
+        rule=ROUTES.CREATE_EXPERIMENT_PERMISSION,
+        view_func=create_experiment_permission,
+        methods=["POST"],
+    )
+    app.add_url_rule(
+        rule=ROUTES.GET_EXPERIMENT_PERMISSION,
+        view_func=get_experiment_permission,
+        methods=["GET"],
+    )
+    app.add_url_rule(
+        rule=ROUTES.UPDATE_EXPERIMENT_PERMISSION,
+        view_func=update_experiment_permission,
+        methods=["PATCH"],
+    )
+    app.add_url_rule(
+        rule=ROUTES.DELETE_EXPERIMENT_PERMISSION,
+        view_func=delete_experiment_permission,
+        methods=["DELETE"],
+    )
+    app.add_url_rule(
+        rule=ROUTES.CREATE_REGISTERED_MODEL_PERMISSION,
+        view_func=create_registered_model_permission,
+        methods=["POST"],
+    )
+    app.add_url_rule(
+        rule=ROUTES.GET_REGISTERED_MODEL_PERMISSION,
+        view_func=get_registered_model_permission,
+        methods=["GET"],
+    )
+    app.add_url_rule(
+        rule=ROUTES.UPDATE_REGISTERED_MODEL_PERMISSION,
+        view_func=update_registered_model_permission,
+        methods=["PATCH"],
+    )
+    app.add_url_rule(
+        rule=ROUTES.DELETE_REGISTERED_MODEL_PERMISSION,
+        view_func=delete_registered_model_permission,
+        methods=["DELETE"],
+    )
 
     app.before_request(_before_request)
     app.after_request(_after_request)
 
 
 _enable_auth(app)
```

## mlflow/server/auth/config.py

```diff
@@ -1,16 +1,20 @@
 import configparser
 from typing import NamedTuple
 
 
 class AuthConfig(NamedTuple):
     default_permission: str
     database_uri: str
+    admin_username: str
+    admin_password: str
 
 
 def read_auth_config(config_path: str) -> AuthConfig:
     config = configparser.ConfigParser()
     config.read(config_path)
     return AuthConfig(
         default_permission=config["mlflow"]["default_permission"],
         database_uri=config["mlflow"]["database_uri"],
+        admin_username=config["mlflow"]["admin_username"],
+        admin_password=config["mlflow"]["admin_password"],
     )
```

## mlflow/server/auth/entities.py

```diff
@@ -1,23 +1,29 @@
 class User:
     def __init__(
         self,
+        id_,
         username,
         password_hash,
         is_admin,
         experiment_permissions=None,
         registered_model_permissions=None,
     ):
+        self._id = id_
         self._username = username
         self._password_hash = password_hash
         self._is_admin = is_admin
         self._experiment_permissions = experiment_permissions
         self._registered_model_permissions = registered_model_permissions
 
     @property
+    def id(self):
+        return self._id
+
+    @property
     def username(self):
         return self._username
 
     @property
     def password_hash(self):
         return self._password_hash
 
@@ -41,14 +47,24 @@
     def registered_model_permissions(self):
         return self._registered_model_permissions
 
     @registered_model_permissions.setter
     def registered_model_permissions(self, registered_model_permissions):
         self._registered_model_permissions = registered_model_permissions
 
+    def to_json(self):
+        return {
+            "username": self.username,
+            "is_admin": self.is_admin,
+            "experiment_permissions": [p.to_json() for p in self.experiment_permissions],
+            "registered_model_permissions": [
+                p.to_json() for p in self.registered_model_permissions
+            ],
+        }
+
 
 class ExperimentPermission:
     def __init__(
         self,
         experiment_id,
         user_id,
         permission,
@@ -69,34 +85,48 @@
     def permission(self):
         return self._permission
 
     @permission.setter
     def permission(self, permission):
         self._permission = permission
 
+    def to_json(self):
+        return {
+            "experiment_id": self.experiment_id,
+            "user_id": self.user_id,
+            "permission": self.permission,
+        }
+
 
 class RegisteredModelPermission:
     def __init__(
         self,
         name,
         user_id,
         permission,
     ):
         self._name = name
         self._user_id = user_id
         self._permission = permission
 
     @property
     def name(self):
-        return self.name
+        return self._name
 
     @property
     def user_id(self):
         return self._user_id
 
     @property
     def permission(self):
         return self._permission
 
     @permission.setter
     def permission(self, permission):
         self._permission = permission
+
+    def to_json(self):
+        return {
+            "name": self.name,
+            "user_id": self.user_id,
+            "permission": self.permission,
+        }
```

## mlflow/server/auth/sqlalchemy_store.py

```diff
@@ -1,26 +1,28 @@
 from typing import List
 from sqlalchemy import (
     Column,
     String,
     ForeignKey,
     Integer,
     Boolean,
+    UniqueConstraint,
 )
 from sqlalchemy.exc import IntegrityError, NoResultFound, MultipleResultsFound
 from sqlalchemy.orm import declarative_base, relationship, sessionmaker
 from werkzeug.security import generate_password_hash, check_password_hash
 
 from mlflow.exceptions import MlflowException
 from mlflow.protos.databricks_pb2 import (
     RESOURCE_ALREADY_EXISTS,
     RESOURCE_DOES_NOT_EXIST,
     INVALID_STATE,
 )
 from mlflow.server.auth.entities import User, ExperimentPermission, RegisteredModelPermission
+from mlflow.server.auth.permissions import _validate_permission
 from mlflow.store.db.utils import create_sqlalchemy_engine_with_retry, _get_managed_session_maker
 from mlflow.utils.uri import extract_db_type_from_uri
 from mlflow.utils.validation import _validate_username
 
 Base = declarative_base()
 
 
@@ -31,45 +33,48 @@
     password_hash = Column(String(255))
     is_admin = Column(Boolean, default=False)
     experiment_permissions = relationship("SqlExperimentPermission", backref="users")
     registered_model_permissions = relationship("SqlRegisteredModelPermission", backref="users")
 
     def to_mlflow_entity(self):
         return User(
+            id_=self.id,
             username=self.username,
             password_hash=self.password_hash,
             is_admin=self.is_admin,
             experiment_permissions=[p.to_mlflow_entity() for p in self.experiment_permissions],
             registered_model_permissions=[
                 p.to_mlflow_entity() for p in self.registered_model_permissions
             ],
         )
 
 
 class SqlExperimentPermission(Base):
     __tablename__ = "experiment_permissions"
     id = Column(Integer(), primary_key=True)
-    experiment_id = Column(String(255), unique=True, nullable=False)
+    experiment_id = Column(String(255), nullable=False)
     user_id = Column(Integer, ForeignKey("users.id"), nullable=False)
     permission = Column(String(255))
+    __table_args__ = (UniqueConstraint("experiment_id", "user_id", name="unique_experiment_user"),)
 
     def to_mlflow_entity(self):
         return ExperimentPermission(
             experiment_id=self.experiment_id,
             user_id=self.user_id,
             permission=self.permission,
         )
 
 
 class SqlRegisteredModelPermission(Base):
     __tablename__ = "registered_model_permissions"
     id = Column(Integer(), primary_key=True)
-    name = Column(String(255), unique=True, nullable=False)
+    name = Column(String(255), nullable=False)
     user_id = Column(Integer, ForeignKey("users.id"), nullable=False)
     permission = Column(String(255))
+    __table_args__ = (UniqueConstraint("name", "user_id", name="unique_name_user"),)
 
     def to_mlflow_entity(self):
         return RegisteredModelPermission(
             name=self.name,
             user_id=self.user_id,
             permission=self.permission,
         )
@@ -94,31 +99,31 @@
         with self.ManagedSessionMaker() as session:
             try:
                 user = self._get_user(session, username)
                 return check_password_hash(user.password_hash, password)
             except MlflowException:
                 return False
 
-    def create_user(self, username: str, password: str, is_admin: bool = False):
+    def create_user(self, username: str, password: str, is_admin: bool = False) -> User:
         _validate_username(username)
         pwhash = generate_password_hash(password)
         with self.ManagedSessionMaker() as session:
             try:
                 user = SqlUser(username=username, password_hash=pwhash, is_admin=is_admin)
                 session.add(user)
                 session.flush()
                 return user.to_mlflow_entity()
             except IntegrityError as e:
                 raise MlflowException(
                     f"User (username={username}) already exists. Error: {e}",
                     RESOURCE_ALREADY_EXISTS,
                 )
 
-    @classmethod
-    def _get_user(cls, session, username: str) -> SqlUser:
+    @staticmethod
+    def _get_user(session, username: str) -> SqlUser:
         try:
             return session.query(SqlUser).filter(SqlUser.username == username).one()
         except NoResultFound:
             raise MlflowException(
                 f"User with username={username} not found",
                 RESOURCE_DOES_NOT_EXIST,
             )
@@ -136,7 +141,173 @@
         with self.ManagedSessionMaker() as session:
             return self._get_user(session, username).to_mlflow_entity()
 
     def list_users(self) -> List[User]:
         with self.ManagedSessionMaker() as session:
             users = session.query(SqlUser).all()
             return [u.to_mlflow_entity() for u in users]
+
+    def update_user(self, username: str, password: str = None, is_admin: bool = None) -> User:
+        with self.ManagedSessionMaker() as session:
+            user = self._get_user(session, username)
+            if password is not None:
+                pwhash = generate_password_hash(password)
+                user.password_hash = pwhash
+            if is_admin is not None:
+                user.is_admin = is_admin
+            return user.to_mlflow_entity()
+
+    def delete_user(self, username: str):
+        with self.ManagedSessionMaker() as session:
+            user = self._get_user(session, username)
+            session.delete(user)
+
+    def create_experiment_permission(
+        self, experiment_id: str, username: str, permission: str
+    ) -> ExperimentPermission:
+        _validate_permission(permission)
+        with self.ManagedSessionMaker() as session:
+            try:
+                user = self._get_user(session, username=username)
+                perm = SqlExperimentPermission(
+                    experiment_id=experiment_id, user_id=user.id, permission=permission
+                )
+                session.add(perm)
+                session.flush()
+                return perm.to_mlflow_entity()
+            except IntegrityError as e:
+                raise MlflowException(
+                    f"Experiment permission (experiment_id={experiment_id}, username={username}) "
+                    f"already exists. Error: {e}",
+                    RESOURCE_ALREADY_EXISTS,
+                )
+
+    def _get_experiment_permission(
+        self, session, experiment_id: str, username: str
+    ) -> SqlExperimentPermission:
+        try:
+            user = self._get_user(session, username=username)
+            return (
+                session.query(SqlExperimentPermission)
+                .filter(
+                    SqlExperimentPermission.experiment_id == experiment_id,
+                    SqlExperimentPermission.user_id == user.id,
+                )
+                .one()
+            )
+        except NoResultFound:
+            raise MlflowException(
+                f"Experiment permission with experiment_id={experiment_id} and "
+                f"username={username} not found",
+                RESOURCE_DOES_NOT_EXIST,
+            )
+        except MultipleResultsFound:
+            raise MlflowException(
+                f"Found multiple experiment permissions with experiment_id={experiment_id} "
+                f"and username={username}",
+                INVALID_STATE,
+            )
+
+    def get_experiment_permission(self, experiment_id: str, username: str) -> ExperimentPermission:
+        with self.ManagedSessionMaker() as session:
+            return self._get_experiment_permission(
+                session, experiment_id, username
+            ).to_mlflow_entity()
+
+    def list_experiment_permissions(self, username: str) -> List[ExperimentPermission]:
+        with self.ManagedSessionMaker() as session:
+            user = self._get_user(session, username=username)
+            perms = (
+                session.query(SqlExperimentPermission)
+                .filter(SqlExperimentPermission.user_id == user.id)
+                .all()
+            )
+            return [p.to_mlflow_entity() for p in perms]
+
+    def update_experiment_permission(
+        self, experiment_id: str, username: str, permission: str
+    ) -> ExperimentPermission:
+        _validate_permission(permission)
+        with self.ManagedSessionMaker() as session:
+            perm = self._get_experiment_permission(session, experiment_id, username)
+            perm.permission = permission
+            return perm.to_mlflow_entity()
+
+    def delete_experiment_permission(self, experiment_id: str, username: str):
+        with self.ManagedSessionMaker() as session:
+            perm = self._get_experiment_permission(session, experiment_id, username)
+            session.delete(perm)
+
+    def create_registered_model_permission(
+        self, name: str, username: str, permission: str
+    ) -> RegisteredModelPermission:
+        _validate_permission(permission)
+        with self.ManagedSessionMaker() as session:
+            try:
+                user = self._get_user(session, username=username)
+                perm = SqlRegisteredModelPermission(
+                    name=name, user_id=user.id, permission=permission
+                )
+                session.add(perm)
+                session.flush()
+                return perm.to_mlflow_entity()
+            except IntegrityError as e:
+                raise MlflowException(
+                    f"Registered model permission (name={name}, username={username}) "
+                    f"already exists. Error: {e}",
+                    RESOURCE_ALREADY_EXISTS,
+                )
+
+    def _get_registered_model_permission(
+        self, session, name: str, username: str
+    ) -> SqlRegisteredModelPermission:
+        try:
+            user = self._get_user(session, username=username)
+            return (
+                session.query(SqlRegisteredModelPermission)
+                .filter(
+                    SqlRegisteredModelPermission.name == name,
+                    SqlRegisteredModelPermission.user_id == user.id,
+                )
+                .one()
+            )
+        except NoResultFound:
+            raise MlflowException(
+                f"Registered model permission with name={name} and username={username} not found",
+                RESOURCE_DOES_NOT_EXIST,
+            )
+        except MultipleResultsFound:
+            raise MlflowException(
+                f"Found multiple registered model permissions with name={name} "
+                f"and username={username}",
+                INVALID_STATE,
+            )
+
+    def get_registered_model_permission(
+        self, name: str, username: str
+    ) -> RegisteredModelPermission:
+        with self.ManagedSessionMaker() as session:
+            return self._get_registered_model_permission(session, name, username).to_mlflow_entity()
+
+    def list_registered_model_permissions(self, username: str) -> List[RegisteredModelPermission]:
+        with self.ManagedSessionMaker() as session:
+            user = self._get_user(session, username=username)
+            perms = (
+                session.query(SqlRegisteredModelPermission)
+                .filter(SqlRegisteredModelPermission.user_id == user.id)
+                .all()
+            )
+            return [p.to_mlflow_entity() for p in perms]
+
+    def update_registered_model_permission(
+        self, name: str, username: str, permission: str
+    ) -> RegisteredModelPermission:
+        _validate_permission(permission)
+        with self.ManagedSessionMaker() as session:
+            perm = self._get_registered_model_permission(session, name, username)
+            perm.permission = permission
+            return perm.to_mlflow_entity()
+
+    def delete_registered_model_permission(self, name: str, username: str):
+        with self.ManagedSessionMaker() as session:
+            perm = self._get_registered_model_permission(session, name, username)
+            session.delete(perm)
```

## mlflow/sklearn/__init__.py

```diff
@@ -402,28 +402,32 @@
              metadata of the logged model.
 
     .. code-block:: python
         :caption: Example
 
         import mlflow
         import mlflow.sklearn
+        from mlflow.models.signature import infer_signature
         from sklearn.datasets import load_iris
         from sklearn import tree
 
-        iris = load_iris()
-        sk_model = tree.DecisionTreeClassifier()
-        sk_model = sk_model.fit(iris.data, iris.target)
-        # set the artifact_path to location where experiment artifacts will be saved
-
-        # log model params
-        mlflow.log_param("criterion", sk_model.criterion)
-        mlflow.log_param("splitter", sk_model.splitter)
+        with mlflow.start_run():
+            # load dataset and train model
+            iris = load_iris()
+            sk_model = tree.DecisionTreeClassifier()
+            sk_model = sk_model.fit(iris.data, iris.target)
+
+            # log model params
+            mlflow.log_param("criterion", sk_model.criterion)
+            mlflow.log_param("splitter", sk_model.splitter)
+            signature = infer_signature(iris.data, sk_model.predict(iris.data))
+
+            # log model
+            mlflow.sklearn.log_model(sk_model, "sk_models", signature=signature)
 
-        # log model
-        mlflow.sklearn.log_model(sk_model, "sk_models")
     """
     return Model.log(
         artifact_path=artifact_path,
         flavor=mlflow.sklearn,
         sk_model=sk_model,
         conda_env=conda_env,
         code_paths=code_paths,
```

## mlflow/store/_unity_catalog/registry/rest_store.py

```diff
@@ -52,17 +52,19 @@
     http_request,
 )
 from mlflow.store._unity_catalog.registry.utils import get_artifact_repo_from_storage_info
 from mlflow.store.model_registry.rest_store import BaseRestStore
 from mlflow.store._unity_catalog.registry.utils import (
     model_version_from_uc_proto,
     registered_model_from_uc_proto,
+    get_full_name_from_sc,
 )
 from mlflow.utils.annotations import experimental
 from mlflow.utils.databricks_utils import get_databricks_host_creds, is_databricks_uri
+from mlflow.utils._spark_utils import _get_active_spark_session
 
 
 _DATABRICKS_ORG_ID_HEADER = "x-databricks-org-id"
 _TRACKING_METHOD_TO_INFO = extract_api_info_for_service(MlflowService, _REST_API_PATH_PREFIX)
 _METHOD_TO_INFO = extract_api_info_for_service(UcModelRegistryService, _REST_API_PATH_PREFIX)
 _METHOD_TO_ALL_INFO = extract_all_api_info_for_service(
     UcModelRegistryService, _REST_API_PATH_PREFIX
@@ -108,14 +110,18 @@
                          versions from source artifacts logged to an MLflow run.
     """
 
     def __init__(self, store_uri, tracking_uri):
         super().__init__(get_host_creds=functools.partial(get_databricks_host_creds, store_uri))
         self.tracking_uri = tracking_uri
         self.get_tracking_host_creds = functools.partial(get_databricks_host_creds, tracking_uri)
+        try:
+            self.spark = _get_active_spark_session()
+        except Exception:
+            pass
 
     def _get_response_from_method(self, method):
         method_to_response = {
             CreateRegisteredModelRequest: CreateRegisteredModelResponse,
             UpdateRegisteredModelRequest: UpdateRegisteredModelResponse,
             DeleteRegisteredModelRequest: DeleteRegisteredModelResponse,
             CreateModelVersionRequest: CreateModelVersionResponse,
@@ -152,27 +158,33 @@
         :param tags: A list of :py:class:`mlflow.entities.model_registry.RegisteredModelTag`
                      instances associated with this registered model.
         :param description: Description of the model.
         :return: A single object of :py:class:`mlflow.entities.model_registry.RegisteredModel`
                  created in the backend.
         """
         _require_arg_unspecified(arg_name="tags", arg_value=tags, default_values=[[], None])
-        req_body = message_to_json(CreateRegisteredModelRequest(name=name, description=description))
+        full_name = get_full_name_from_sc(name, self.spark)
+        req_body = message_to_json(
+            CreateRegisteredModelRequest(name=full_name, description=description)
+        )
         response_proto = self._call_endpoint(CreateRegisteredModelRequest, req_body)
         return registered_model_from_uc_proto(response_proto.registered_model)
 
     def update_registered_model(self, name, description):
         """
         Update description of the registered model.
 
         :param name: Registered model name.
         :param description: New description.
         :return: A single updated :py:class:`mlflow.entities.model_registry.RegisteredModel` object.
         """
-        req_body = message_to_json(UpdateRegisteredModelRequest(name=name, description=description))
+        full_name = get_full_name_from_sc(name, self.spark)
+        req_body = message_to_json(
+            UpdateRegisteredModelRequest(name=full_name, description=description)
+        )
         response_proto = self._call_endpoint(UpdateRegisteredModelRequest, req_body)
         return registered_model_from_uc_proto(response_proto.registered_model)
 
     def rename_registered_model(self, name, new_name):
         """
         Rename the registered model.
 
@@ -189,15 +201,16 @@
         """
         Delete the registered model.
         Backend raises exception if a registered model with given name does not exist.
 
         :param name: Registered model name.
         :return: None
         """
-        req_body = message_to_json(DeleteRegisteredModelRequest(name=name))
+        full_name = get_full_name_from_sc(name, self.spark)
+        req_body = message_to_json(DeleteRegisteredModelRequest(name=full_name))
         self._call_endpoint(DeleteRegisteredModelRequest, req_body)
 
     def search_registered_models(
         self, filter_string=None, max_results=None, order_by=None, page_token=None
     ):
         """
         Search for registered models in backend that satisfy the filter criteria.
@@ -230,15 +243,16 @@
     def get_registered_model(self, name):
         """
         Get registered model instance by name.
 
         :param name: Registered model name.
         :return: A single :py:class:`mlflow.entities.model_registry.RegisteredModel` object.
         """
-        req_body = message_to_json(GetRegisteredModelRequest(name=name))
+        full_name = get_full_name_from_sc(name, self.spark)
+        req_body = message_to_json(GetRegisteredModelRequest(name=full_name))
         response_proto = self._call_endpoint(GetRegisteredModelRequest, req_body)
         return registered_model_from_uc_proto(response_proto.registered_model)
 
     def get_latest_versions(self, name, stages=None):
         """
         Latest version models for each requested stage. If no ``stages`` argument is provided,
         returns the latest version for each stage.
@@ -311,15 +325,23 @@
         if run_id is None or not is_databricks_uri(self.tracking_uri):
             return None
         host_creds = self.get_tracking_host_creds()
         endpoint, method = _TRACKING_METHOD_TO_INFO[GetRun]
         response = http_request(
             host_creds=host_creds, endpoint=endpoint, method=method, params={"run_id": run_id}
         )
-        response = verify_rest_response(response, endpoint)
+        try:
+            verify_rest_response(response, endpoint)
+        except MlflowException:
+            _logger.warning(
+                f"Unable to fetch model version's source run (with ID {run_id}) "
+                "from tracking server. The source run may be deleted or inaccessible to the "
+                "current user. No run link will be recorded for the model version."
+            )
+            return None
         if _DATABRICKS_ORG_ID_HEADER not in response.headers:
             _logger.warning(
                 "Unable to get model version source run's workspace ID from request headers. "
                 "No run link will be recorded for the model version"
             )
             return None
         return response.headers[_DATABRICKS_ORG_ID_HEADER]
@@ -373,17 +395,18 @@
         :param description: Description of the version.
         :return: A single object of :py:class:`mlflow.entities.model_registry.ModelVersion`
                  created in the backend.
         """
         _require_arg_unspecified(arg_name="run_link", arg_value=run_link)
         _require_arg_unspecified(arg_name="tags", arg_value=tags, default_values=[[], None])
         source_workspace_id = self._get_workspace_id(run_id)
+        full_name = get_full_name_from_sc(name, self.spark)
         req_body = message_to_json(
             CreateModelVersionRequest(
-                name=name,
+                name=full_name,
                 source=source,
                 run_id=run_id,
                 description=description,
                 run_tracking_server_id=source_workspace_id,
             )
         )
         with tempfile.TemporaryDirectory() as tmpdir:
@@ -398,21 +421,21 @@
                     f"the source artifact location exists and that you can download from "
                     f"it via mlflow.artifacts.download_artifacts()"
                 ) from e
             self._validate_model_signature(local_model_dir)
             model_version = self._call_endpoint(CreateModelVersionRequest, req_body).model_version
             version_number = model_version.version
             scoped_token = self._get_temporary_model_version_write_credentials(
-                name=name, version=version_number
+                name=full_name, version=version_number
             )
             store = get_artifact_repo_from_storage_info(
                 storage_location=model_version.storage_location, scoped_token=scoped_token
             )
             store.log_artifacts(local_dir=local_model_dir, artifact_path="")
-        finalized_mv = self._finalize_model_version(name=name, version=version_number)
+        finalized_mv = self._finalize_model_version(name=full_name, version=version_number)
         return model_version_from_uc_proto(finalized_mv)
 
     def transition_model_version_stage(self, name, version, stage, archive_existing_versions):
         """
         Update model version stage.
 
         :param name: Registered model name.
@@ -430,55 +453,59 @@
         Update metadata associated with a model version in backend.
 
         :param name: Registered model name.
         :param version: Registered model version.
         :param description: New model description.
         :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.
         """
+        full_name = get_full_name_from_sc(name, self.spark)
         req_body = message_to_json(
-            UpdateModelVersionRequest(name=name, version=str(version), description=description)
+            UpdateModelVersionRequest(name=full_name, version=str(version), description=description)
         )
         response_proto = self._call_endpoint(UpdateModelVersionRequest, req_body)
         return model_version_from_uc_proto(response_proto.model_version)
 
     def delete_model_version(self, name, version):
         """
         Delete model version in backend.
 
         :param name: Registered model name.
         :param version: Registered model version.
         :return: None
         """
-        req_body = message_to_json(DeleteModelVersionRequest(name=name, version=str(version)))
+        full_name = get_full_name_from_sc(name, self.spark)
+        req_body = message_to_json(DeleteModelVersionRequest(name=full_name, version=str(version)))
         self._call_endpoint(DeleteModelVersionRequest, req_body)
 
     def get_model_version(self, name, version):
         """
         Get the model version instance by name and version.
 
         :param name: Registered model name.
         :param version: Registered model version.
         :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.
         """
-        req_body = message_to_json(GetModelVersionRequest(name=name, version=str(version)))
+        full_name = get_full_name_from_sc(name, self.spark)
+        req_body = message_to_json(GetModelVersionRequest(name=full_name, version=str(version)))
         response_proto = self._call_endpoint(GetModelVersionRequest, req_body)
         return model_version_from_uc_proto(response_proto.model_version)
 
     def get_model_version_download_uri(self, name, version):
         """
         Get the download location in Model Registry for this model version.
         NOTE: For first version of Model Registry, since the models are not copied over to another
               location, download URI points to input source path.
 
         :param name: Registered model name.
         :param version: Registered model version.
         :return: A single URI location that allows reads for downloading.
         """
+        full_name = get_full_name_from_sc(name, self.spark)
         req_body = message_to_json(
-            GetModelVersionDownloadUriRequest(name=name, version=str(version))
+            GetModelVersionDownloadUriRequest(name=full_name, version=str(version))
         )
         response_proto = self._call_endpoint(GetModelVersionDownloadUriRequest, req_body)
         return response_proto.artifact_uri
 
     def search_model_versions(
         self, filter_string=None, max_results=None, order_by=None, page_token=None
     ):
@@ -493,15 +520,20 @@
                          matching search results.
         :param page_token: Token specifying the next page of results. It should be obtained from
                             a ``search_model_versions`` call.
         :return: A PagedList of :py:class:`mlflow.entities.model_registry.ModelVersion`
                  objects that satisfy the search expressions. The pagination token for the next
                  page can be obtained via the ``token`` attribute of the object.
         """
-        req_body = message_to_json(SearchModelVersionsRequest(filter=filter_string))
+        _require_arg_unspecified(arg_name="order_by", arg_value=order_by)
+        req_body = message_to_json(
+            SearchModelVersionsRequest(
+                filter=filter_string, page_token=page_token, max_results=max_results
+            )
+        )
         response_proto = self._call_endpoint(SearchModelVersionsRequest, req_body)
         model_versions = [model_version_from_uc_proto(mvd) for mvd in response_proto.model_versions]
         return PagedList(model_versions, response_proto.next_page_token)
 
     def set_model_version_tag(self, name, version, tag):
         """
         Set a tag for the model version.
@@ -527,34 +559,37 @@
         Set a registered model alias pointing to a model version.
 
         :param name: Registered model name.
         :param alias: Name of the alias.
         :param version: Registered model version number.
         :return: None
         """
+        full_name = get_full_name_from_sc(name, self.spark)
         req_body = message_to_json(
-            SetRegisteredModelAliasRequest(name=name, alias=alias, version=str(version))
+            SetRegisteredModelAliasRequest(name=full_name, alias=alias, version=str(version))
         )
         self._call_endpoint(SetRegisteredModelAliasRequest, req_body)
 
     def delete_registered_model_alias(self, name, alias):
         """
         Delete an alias associated with a registered model.
 
         :param name: Registered model name.
         :param alias: Name of the alias.
         :return: None
         """
-        req_body = message_to_json(DeleteRegisteredModelAliasRequest(name=name, alias=alias))
+        full_name = get_full_name_from_sc(name, self.spark)
+        req_body = message_to_json(DeleteRegisteredModelAliasRequest(name=full_name, alias=alias))
         self._call_endpoint(DeleteRegisteredModelAliasRequest, req_body)
 
     def get_model_version_by_alias(self, name, alias):
         """
         Get the model version instance by name and alias.
 
         :param name: Registered model name.
         :param alias: Name of the alias.
         :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.
         """
-        req_body = message_to_json(GetModelVersionByAliasRequest(name=name, alias=alias))
+        full_name = get_full_name_from_sc(name, self.spark)
+        req_body = message_to_json(GetModelVersionByAliasRequest(name=full_name, alias=alias))
         response_proto = self._call_endpoint(GetModelVersionByAliasRequest, req_body)
         return model_version_from_uc_proto(response_proto.model_version)
```

## mlflow/store/_unity_catalog/registry/utils.py

```diff
@@ -1,19 +1,21 @@
-from mlflow.entities.model_registry import ModelVersion, RegisteredModel
+from mlflow.entities.model_registry import ModelVersion, RegisteredModel, RegisteredModelAlias
 from mlflow.protos.databricks_uc_registry_messages_pb2 import (
     ModelVersion as ProtoModelVersion,
     ModelVersionStatus as ProtoModelVersionStatus,
     RegisteredModel as ProtoRegisteredModel,
     TemporaryCredentials,
 )
 from mlflow.exceptions import MlflowException
 from mlflow.store.artifact.artifact_repo import ArtifactRepository
 
 _STRING_TO_STATUS = {k: ProtoModelVersionStatus.Value(k) for k in ProtoModelVersionStatus.keys()}
 _STATUS_TO_STRING = {value: key for key, value in _STRING_TO_STATUS.items()}
+_ACTIVE_CATALOG_QUERY = "SELECT current_catalog() AS catalog"
+_ACTIVE_SCHEMA_QUERY = "SELECT current_database() AS schema"
 
 
 def uc_model_version_status_to_string(status):
     return _STATUS_TO_STRING[status]
 
 
 def model_version_from_uc_proto(uc_proto: ProtoModelVersion) -> ModelVersion:
@@ -24,23 +26,28 @@
         last_updated_timestamp=uc_proto.last_updated_timestamp,
         description=uc_proto.description,
         user_id=uc_proto.user_id,
         source=uc_proto.source,
         run_id=uc_proto.run_id,
         status=uc_model_version_status_to_string(uc_proto.status),
         status_message=uc_proto.status_message,
+        aliases=[alias.alias for alias in (uc_proto.aliases or [])],
     )
 
 
 def registered_model_from_uc_proto(uc_proto: ProtoRegisteredModel) -> RegisteredModel:
     return RegisteredModel(
         name=uc_proto.name,
         creation_timestamp=uc_proto.creation_timestamp,
         last_updated_timestamp=uc_proto.last_updated_timestamp,
         description=uc_proto.description,
+        aliases=[
+            RegisteredModelAlias(alias=alias.alias, version=alias.version)
+            for alias in (uc_proto.aliases or [])
+        ],
     )
 
 
 def get_artifact_repo_from_storage_info(
     storage_location: str, scoped_token: TemporaryCredentials
 ) -> ArtifactRepository:
     """
@@ -97,7 +104,27 @@
         credentials = Credentials(scoped_token.gcp_oauth_token.oauth_token)
         client = Client(project="mlflow", credentials=credentials)
         return GCSArtifactRepository(artifact_uri=storage_location, client=client)
     else:
         raise MlflowException(
             f"Got unexpected token type {credential_type} for Unity Catalog managed file access"
         )
+
+
+def get_full_name_from_sc(name, spark) -> str:
+    """
+    Constructs the full name of a registered model using the active catalog and schema in a spark
+    session / context.
+    :param name: the model name provided by the user
+    :param spark: the active spark session
+    """
+    num_levels = len(name.split("."))
+    if num_levels >= 3 or spark is None:
+        return name
+    catalog = spark.sql(_ACTIVE_CATALOG_QUERY).collect()[0]["catalog"]
+    # return the user provided name if the catalog is the hive metastore default
+    if catalog in {"spark_catalog", "hive_metastore"}:
+        return name
+    if num_levels == 2:
+        return f"{catalog}.{name}"
+    schema = spark.sql(_ACTIVE_SCHEMA_QUERY).collect()[0]["schema"]
+    return f"{catalog}.{schema}.{name}"
```

## mlflow/store/artifact/unity_catalog_models_artifact_repo.py

```diff
@@ -16,19 +16,23 @@
 )
 from mlflow.utils.uri import (
     get_databricks_profile_uri_from_artifact_uri,
     get_db_info_from_uri,
     is_databricks_unity_catalog_uri,
     _DATABRICKS_UNITY_CATALOG_SCHEME,
 )
+from mlflow.utils._spark_utils import _get_active_spark_session
 from mlflow.store.artifact.utils.models import (
     get_model_name_and_version,
 )
 
-from mlflow.store._unity_catalog.registry.utils import get_artifact_repo_from_storage_info
+from mlflow.store._unity_catalog.registry.utils import (
+    get_artifact_repo_from_storage_info,
+    get_full_name_from_sc,
+)
 
 _METHOD_TO_INFO = extract_api_info_for_service(UcModelRegistryService, _REST_API_PATH_PREFIX)
 
 
 class UnityCatalogModelsArtifactRepository(ArtifactRepository):
     """
     Performs storage operations on artifacts controlled by a Unity Catalog model registry
@@ -67,15 +71,20 @@
                 "Remote model registry access via model URIs of the form "
                 "'models://<scope>@<prefix>/<model_name>/<version_or_stage>' is unsupported for "
                 "models in the Unity Catalog. We recommend that you access the Unity Catalog "
                 "from the current Databricks workspace instead."
             )
         self.registry_uri = registry_uri
         self.client = MlflowClient(registry_uri=self.registry_uri)
-        self.model_name, self.model_version = get_model_name_and_version(self.client, artifact_uri)
+        try:
+            spark = _get_active_spark_session()
+        except Exception:
+            pass
+        model_name, self.model_version = get_model_name_and_version(self.client, artifact_uri)
+        self.model_name = get_full_name_from_sc(model_name, spark)
 
     def _get_blob_storage_path(self):
         return self.client.get_model_version_download_uri(self.model_name, self.model_version)
 
     def _get_scoped_token(self):
         db_creds = get_databricks_host_creds(self.registry_uri)
         endpoint, method = _METHOD_TO_INFO[GenerateTemporaryModelVersionCredentialsRequest]
```

## mlflow/tracking/client.py

```diff
@@ -2051,39 +2051,44 @@
         :return: List of :py:class:`mlflow.entities.model_registry.ModelVersion` objects.
 
         .. code-block:: python
             :caption: Example
 
             import mlflow.sklearn
             from mlflow import MlflowClient
+            from mlflow.models.signature import infer_signature
+            from sklearn.datasets import make_regression
             from sklearn.ensemble import RandomForestRegressor
 
 
             def print_models_info(mv):
                 for m in mv:
                     print("name: {}".format(m.name))
                     print("latest version: {}".format(m.version))
                     print("run_id: {}".format(m.run_id))
                     print("current_stage: {}".format(m.current_stage))
 
 
             mlflow.set_tracking_uri("sqlite:///mlruns.db")
+            X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)
 
             # Create two runs Log MLflow entities
             with mlflow.start_run() as run1:
                 params = {"n_estimators": 3, "random_state": 42}
-                rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])
+                rfr = RandomForestRegressor(**params).fit(X, y)
+                signature = infer_signature(X, rfr.predict(X))
                 mlflow.log_params(params)
-                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model")
+                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model", signature=signature)
 
             with mlflow.start_run() as run2:
                 params = {"n_estimators": 6, "random_state": 42}
-                rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])
+                rfr = RandomForestRegressor(**params).fit(X, y)
+                signature = infer_signature(X, rfr.predict(X))
                 mlflow.log_params(params)
-                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model")
+                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model", signature=signature)
 
             # Register model name in the model registry
             name = "RandomForestRegression"
             client = MlflowClient()
             client.create_registered_model(name)
 
             # Create a two versions of the rfr model under the registered model name
@@ -2238,24 +2243,29 @@
 
         .. code-block:: python
             :caption: Example
 
             import mlflow.sklearn
             from mlflow.store.artifact.runs_artifact_repo import RunsArtifactRepository
             from mlflow import MlflowClient
+            from mlflow.models.signature import infer_signature
+            from sklearn.datasets import make_regression
             from sklearn.ensemble import RandomForestRegressor
 
             mlflow.set_tracking_uri("sqlite:///mlruns.db")
             params = {"n_estimators": 3, "random_state": 42}
             name = "RandomForestRegression"
-            rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])
+            X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)
+            rfr = RandomForestRegressor(**params).fit(X, y)
+            signature = infer_signature(X, rfr.predict(X))
+
             # Log MLflow entities
             with mlflow.start_run() as run:
                 mlflow.log_params(params)
-                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model")
+                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model", signature=signature)
 
             # Register model name in the model registry
             client = MlflowClient()
             client.create_registered_model(name)
 
             # Create a new version of the rfr model under the registered model name
             desc = "A new version of the model"
@@ -2332,32 +2342,36 @@
         :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.
 
         .. code-block:: python
             :caption: Example
 
             import mlflow.sklearn
             from mlflow import MlflowClient
+            from mlflow.models.signature import infer_signature
+            from sklearn.datasets import make_regression
             from sklearn.ensemble import RandomForestRegressor
 
 
             def print_model_version_info(mv):
                 print("Name: {}".format(mv.name))
                 print("Version: {}".format(mv.version))
                 print("Description: {}".format(mv.description))
 
 
             mlflow.set_tracking_uri("sqlite:///mlruns.db")
             params = {"n_estimators": 3, "random_state": 42}
             name = "RandomForestRegression"
-            rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])
+            X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)
+            rfr = RandomForestRegressor(**params).fit(X, y)
+            signature = infer_signature(X, rfr.predict(X))
 
             # Log MLflow entities
             with mlflow.start_run() as run:
                 mlflow.log_params(params)
-                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model")
+                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model", signature=signature)
 
             # Register model name in the model registry
             client = MlflowClient()
             client.create_registered_model(name)
 
             # Create a new version of the rfr model under the registered model name
             model_uri = "runs:/{}/sklearn-model".format(run.info.run_id)
@@ -2404,34 +2418,38 @@
         :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.
 
         .. code-block:: python
             :caption: Example
 
             import mlflow.sklearn
             from mlflow import MlflowClient
+            from mlflow.models.signature import infer_signature
+            from sklearn.datasets import make_regression
             from sklearn.ensemble import RandomForestRegressor
 
 
             def print_model_version_info(mv):
                 print("Name: {}".format(mv.name))
                 print("Version: {}".format(mv.version))
                 print("Description: {}".format(mv.description))
                 print("Stage: {}".format(mv.current_stage))
 
 
             mlflow.set_tracking_uri("sqlite:///mlruns.db")
             params = {"n_estimators": 3, "random_state": 42}
             name = "RandomForestRegression"
             desc = "A new version of the model using ensemble trees"
-            rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])
+            X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)
+            rfr = RandomForestRegressor(**params).fit(X, y)
+            signature = infer_signature(X, rfr.predict(X))
 
             # Log MLflow entities
             with mlflow.start_run() as run:
                 mlflow.log_params(params)
-                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model")
+                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model", signature=signature)
 
             # Register model name in the model registry
             client = MlflowClient()
             client.create_registered_model(name)
 
             # Create a new version of the rfr model under the registered model name
             model_uri = "runs:/{}/sklearn-model".format(run.info.run_id)
@@ -2468,39 +2486,44 @@
         :param version: Version number of the model version.
 
         .. code-block:: python
             :caption: Example
 
             import mlflow.sklearn
             from mlflow import MlflowClient
+            from mlflow.models.signature import infer_signature
+            from sklearn.datasets import make_regression
             from sklearn.ensemble import RandomForestRegressor
 
 
             def print_models_info(mv):
                 for m in mv:
                     print("name: {}".format(m.name))
                     print("latest version: {}".format(m.version))
                     print("run_id: {}".format(m.run_id))
                     print("current_stage: {}".format(m.current_stage))
 
 
             mlflow.set_tracking_uri("sqlite:///mlruns.db")
+            X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)
 
             # Create two runs and log MLflow entities
             with mlflow.start_run() as run1:
                 params = {"n_estimators": 3, "random_state": 42}
-                rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])
+                rfr = RandomForestRegressor(**params).fit(X, y)
+                signature = infer_signature(X, rfr.predict(X))
                 mlflow.log_params(params)
-                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model")
+                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model", signature=signature)
 
             with mlflow.start_run() as run2:
                 params = {"n_estimators": 6, "random_state": 42}
-                rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])
+                rfr = RandomForestRegressor(**params).fit(X, y)
+                signature = infer_signature(X, rfr.predict(X))
                 mlflow.log_params(params)
-                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model")
+                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model", signature=signature)
 
             # Register model name in the model registry
             name = "RandomForestRegression"
             client = MlflowClient()
             client.create_registered_model(name)
 
             # Create a two versions of the rfr model under the registered model name
@@ -2548,28 +2571,34 @@
         :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.
 
         .. code-block:: python
             :caption: Example
 
             import mlflow.sklearn
             from mlflow import MlflowClient
+            from mlflow.models.signature import infer_signature
+            from sklearn.datasets import make_regression
             from sklearn.ensemble import RandomForestRegressor
 
+            X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)
+
             # Create two runs Log MLflow entities
             with mlflow.start_run() as run1:
                 params = {"n_estimators": 3, "random_state": 42}
-                rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])
+                rfr = RandomForestRegressor(**params).fit(X, y)
+                signature = infer_signature(X, rfr.predict(X))
                 mlflow.log_params(params)
-                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model")
+                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model", signature=signature)
 
             with mlflow.start_run() as run2:
                 params = {"n_estimators": 6, "random_state": 42}
-                rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])
+                rfr = RandomForestRegressor(**params).fit(X, y)
+                signature = infer_signature(X, rfr.predict(X))
                 mlflow.log_params(params)
-                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model")
+                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model", signature=signature)
 
             # Register model name in the model registry
             name = "RandomForestRegression"
             client = MlflowClient()
             client.create_registered_model(name)
 
             # Create a two versions of the rfr model under the registered model name
@@ -2577,15 +2606,16 @@
                 model_uri = "runs:/{}/sklearn-model".format(run_id)
                 mv = client.create_model_version(name, model_uri, run_id)
                 print("model version {} created".format(mv.version))
             print("--")
 
             # Fetch the last version; this will be version 2
             mv = client.get_model_version(name, mv.version)
-            print_model_version_info(mv)
+            print("Name: {}".format(mv.name))
+            print("Version: {}".format(mv.version))
 
         .. code-block:: text
             :caption: Output
 
             model version 1 created
             model version 2 created
             --
@@ -2603,40 +2633,44 @@
         :return: A single URI location that allows reads for downloading.
 
         .. code-block:: python
             :caption: Example
 
             import mlflow.sklearn
             from mlflow import MlflowClient
+            from mlflow.models.signature import infer_signature
+            from sklearn.datasets import make_regression
             from sklearn.ensemble import RandomForestRegressor
 
             mlflow.set_tracking_uri("sqlite:///mlruns.db")
             params = {"n_estimators": 3, "random_state": 42}
             name = "RandomForestRegression"
-            rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])
+            X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)
+            rfr = RandomForestRegressor(**params).fit(X, y)
+            signature = infer_signature(X, rfr.predict(X))
 
             # Log MLflow entities
             with mlflow.start_run() as run:
                 mlflow.log_params(params)
-                mlflow.sklearn.log_model(rfr, artifact_path="models/sklearn-model")
+                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model", signature=signature)
 
             # Register model name in the model registry
             client = MlflowClient()
             client.create_registered_model(name)
 
             # Create a new version of the rfr model under the registered model name
-            model_uri = "runs:/{}/models/sklearn-model".format(run.info.run_id)
+            model_uri = "runs:/{}/sklearn-model".format(run.info.run_id)
             mv = client.create_model_version(name, model_uri, run.info.run_id)
             artifact_uri = client.get_model_version_download_uri(name, mv.version)
             print("Download URI: {}".format(artifact_uri))
 
         .. code-block:: text
             :caption: Output
 
-            Download URI: runs:/44e04097ac364cd895f2039eaccca9ac/models/sklearn-model
+            Download URI: runs:/027d7bbe81924c5a82b3e4ce979fcab7/sklearn-model
         """
         return self._get_registry_client().get_model_version_download_uri(name, version)
 
     def search_model_versions(
         self,
         filter_string: Optional[str] = None,
         max_results: int = SEARCH_MODEL_VERSION_MAX_RESULTS_DEFAULT,
@@ -2721,25 +2755,29 @@
         :return: A list of valid stages.
 
         .. code-block:: python
             :caption: Example
 
             import mlflow.sklearn
             from mlflow import MlflowClient
+            from mlflow.models.signature import infer_signature
+            from sklearn.datasets import make_regression
             from sklearn.ensemble import RandomForestRegressor
 
             mlflow.set_tracking_uri("sqlite:///mlruns.db")
             params = {"n_estimators": 3, "random_state": 42}
             name = "RandomForestRegression"
-            rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])
+            X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)
+            rfr = RandomForestRegressor(**params).fit(X, y)
+            signature = infer_signature(X, rfr.predict(X))
 
             # Log MLflow entities
             with mlflow.start_run() as run:
                 mlflow.log_params(params)
-                mlflow.sklearn.log_model(rfr, artifact_path="models/sklearn-model")
+                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model", signature=signature)
 
             # Register model name in the model registry
             client = MlflowClient()
             client.create_registered_model(name)
 
             # Create a new version of the rfr model under the registered model name
             # fetch valid stages
@@ -2771,32 +2809,36 @@
         :return: None
 
         .. code-block:: python
             :caption: Example
 
             import mlflow.sklearn
             from mlflow import MlflowClient
+            from mlflow.models.signature import infer_signature
+            from sklearn.datasets import make_regression
             from sklearn.ensemble import RandomForestRegressor
 
 
             def print_model_version_info(mv):
                 print("Name: {}".format(mv.name))
                 print("Version: {}".format(mv.version))
                 print("Tags: {}".format(mv.tags))
 
 
             mlflow.set_tracking_uri("sqlite:///mlruns.db")
             params = {"n_estimators": 3, "random_state": 42}
             name = "RandomForestRegression"
-            rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])
+            X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)
+            rfr = RandomForestRegressor(**params).fit(X, y)
+            signature = infer_signature(X, rfr.predict(X))
 
             # Log MLflow entities
             with mlflow.start_run() as run:
                 mlflow.log_params(params)
-                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model")
+                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model", signature=signature)
 
             # Register model name in the model registry
             client = MlflowClient()
             client.create_registered_model(name)
 
             # Create a new version of the rfr model under the registered model name
             # and set a tag
@@ -2849,32 +2891,36 @@
         :return: None
 
         .. code-block:: python
             :caption: Example
 
             import mlflow.sklearn
             from mlflow import MlflowClient
+            from mlflow.models.signature import infer_signature
+            from sklearn.datasets import make_regression
             from sklearn.ensemble import RandomForestRegressor
 
 
             def print_model_version_info(mv):
                 print("Name: {}".format(mv.name))
                 print("Version: {}".format(mv.version))
                 print("Tags: {}".format(mv.tags))
 
 
             mlflow.set_tracking_uri("sqlite:///mlruns.db")
             params = {"n_estimators": 3, "random_state": 42}
             name = "RandomForestRegression"
-            rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])
+            X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)
+            rfr = RandomForestRegressor(**params).fit(X, y)
+            signature = infer_signature(X, rfr.predict(X))
 
             # Log MLflow entities
             with mlflow.start_run() as run:
                 mlflow.log_params(params)
-                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model")
+                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model", signature=signature)
 
             # Register model name in the model registry
             client = MlflowClient()
             client.create_registered_model(name)
 
             # Create a new version of the rfr model under the registered model name
             # and delete a tag
@@ -2920,14 +2966,16 @@
         :return: None
 
         .. code-block:: Python
             :caption: Example
 
             import mlflow
             from mlflow import MlflowClient
+            from mlflow.models.signature import infer_signature
+            from sklearn.datasets import make_regression
             from sklearn.ensemble import RandomForestRegressor
 
             def print_model_info(rm):
                 print("--Model--")
                 print("name: {}".format(rm.name))
                 print("aliases: {}".format(rm.aliases))
 
@@ -2936,20 +2984,22 @@
                 print("Name: {}".format(mv.name))
                 print("Version: {}".format(mv.version))
                 print("Aliases: {}".format(mv.aliases))
 
             mlflow.set_tracking_uri("sqlite:///mlruns.db")
             params = {"n_estimators": 3, "random_state": 42}
             name = "RandomForestRegression"
-            rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])
+            X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)
+            rfr = RandomForestRegressor(**params).fit(X, y)
+            signature = infer_signature(X, rfr.predict(X))
 
             # Log MLflow entities
             with mlflow.start_run() as run:
                 mlflow.log_params(params)
-                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model")
+                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model", signature=signature)
 
             # Register model name in the model registry
             client = MlflowClient()
             client.create_registered_model(name)
             model = client.get_registered_model(name)
             print_model_info(model)
 
@@ -2997,14 +3047,16 @@
         :return: None
 
         .. code-block:: Python
             :caption: Example
 
             import mlflow
             from mlflow import MlflowClient
+            from mlflow.models.signature import infer_signature
+            from sklearn.datasets import make_regression
             from sklearn.ensemble import RandomForestRegressor
 
             def print_model_info(rm):
                 print("--Model--")
                 print("name: {}".format(rm.name))
                 print("aliases: {}".format(rm.aliases))
 
@@ -3013,20 +3065,22 @@
                 print("Name: {}".format(mv.name))
                 print("Version: {}".format(mv.version))
                 print("Aliases: {}".format(mv.aliases))
 
             mlflow.set_tracking_uri("sqlite:///mlruns.db")
             params = {"n_estimators": 3, "random_state": 42}
             name = "RandomForestRegression"
-            rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])
+            X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)
+            rfr = RandomForestRegressor(**params).fit(X, y)
+            signature = infer_signature(X, rfr.predict(X))
 
             # Log MLflow entities
             with mlflow.start_run() as run:
                 mlflow.log_params(params)
-                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model")
+                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model", signature=signature)
 
             # Register model name in the model registry
             client = MlflowClient()
             client.create_registered_model(name)
             model = client.get_registered_model(name)
             print_model_info(model)
 
@@ -3087,14 +3141,16 @@
         :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.
 
         .. code-block:: Python
             :caption: Example
 
             import mlflow
             from mlflow import MlflowClient
+            from mlflow.models.signature import infer_signature
+            from sklearn.datasets import make_regression
             from sklearn.ensemble import RandomForestRegressor
 
             def print_model_info(rm):
                 print("--Model--")
                 print("name: {}".format(rm.name))
                 print("aliases: {}".format(rm.aliases))
 
@@ -3103,20 +3159,22 @@
                 print("Name: {}".format(mv.name))
                 print("Version: {}".format(mv.version))
                 print("Aliases: {}".format(mv.aliases))
 
             mlflow.set_tracking_uri("sqlite:///mlruns.db")
             params = {"n_estimators": 3, "random_state": 42}
             name = "RandomForestRegression"
-            rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])
+            X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)
+            rfr = RandomForestRegressor(**params).fit(X, y)
+            signature = infer_signature(X, rfr.predict(X))
 
             # Log MLflow entities
             with mlflow.start_run() as run:
                 mlflow.log_params(params)
-                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model")
+                mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model", signature=signature)
 
             # Register model name in the model registry
             client = MlflowClient()
             client.create_registered_model(name)
             model = client.get_registered_model(name)
             print_model_info(model)
```

## mlflow/tracking/fluent.py

```diff
@@ -1722,14 +1722,15 @@
         lightgbm,
         pyspark,
         statsmodels,
         spark,
         sklearn,
         fastai,
         pytorch,
+        transformers,
     )
 
     locals_copy = locals().items()
 
     # Mapping of library module name to specific autolog function
     # eg: mxnet.gluon is the actual library, mlflow.gluon.autolog is our autolog function for it
     LIBRARY_TO_AUTOLOG_FN = {
@@ -1741,14 +1742,16 @@
         "sklearn": sklearn.autolog,
         "fastai": fastai.autolog,
         "pyspark": spark.autolog,
         "pyspark.ml": pyspark.ml.autolog,
         # TODO: Broaden this beyond pytorch_lightning as we add autologging support for more
         # Pytorch frameworks under mlflow.pytorch.autolog
         "pytorch_lightning": pytorch.autolog,
+        "setfit": transformers.autolog,
+        "transformers": transformers.autolog,
     }
 
     def get_autologging_params(autolog_fn):
         try:
             needed_params = list(inspect.signature(autolog_fn).parameters.keys())
             return {k: v for k, v in locals_copy if k in needed_params}
         except Exception:
```

## mlflow/tracking/_model_registry/fluent.py

```diff
@@ -40,24 +40,28 @@
     :return: Single :py:class:`mlflow.entities.model_registry.ModelVersion` object created by
              backend.
 
     .. test-code-block:: python
         :caption: Example
 
         import mlflow.sklearn
+        from mlflow.models.signature import infer_signature
+        from sklearn.datasets import make_regression
         from sklearn.ensemble import RandomForestRegressor
 
         mlflow.set_tracking_uri("sqlite:////tmp/mlruns.db")
         params = {"n_estimators": 3, "random_state": 42}
+        X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)
 
         # Log MLflow entities
         with mlflow.start_run() as run:
-            rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])
+            rfr = RandomForestRegressor(**params).fit(X, y)
+            signature = infer_signature(X, rfr.predict(X))
             mlflow.log_params(params)
-            mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model")
+            mlflow.sklearn.log_model(rfr, artifact_path="sklearn-model", signature=signature)
 
         model_uri = "runs:/{}/sklearn-model".format(run.info.run_id)
         mv = mlflow.register_model(model_uri, "RandomForestRegressionModel")
         print("Name: {}".format(mv.name))
         print("Version: {}".format(mv.version))
 
     .. code-block:: text
```

## mlflow/utils/cli_args.py

```diff
@@ -161,15 +161,15 @@
 
 # We use None to disambiguate manually selecting "4"
 WORKERS = click.option(
     "--workers",
     "-w",
     envvar="MLFLOW_WORKERS",
     default=None,
-    help="Number of gunicorn worker processes to handle requests (default: 4).",
+    help="Number of gunicorn worker processes to handle requests (default: 1).",
 )
 
 ENABLE_MLSERVER = click.option(
     "--enable-mlserver",
     is_flag=True,
     default=False,
     help=(
```

## mlflow/utils/databricks_utils.py

```diff
@@ -626,14 +626,30 @@
 
     if workspace_host:
         return DatabricksWorkspaceInfo(host=workspace_host, workspace_id=workspace_id)
     else:
         return None
 
 
+def check_databricks_secret_scope_access(scope_name):
+    dbutils = _get_dbutils()
+    if dbutils:
+        try:
+            dbutils.secrets.list(scope_name)
+        except Exception as e:
+            _logger.warning(
+                f"Unable to access Databricks secret scope '{scope_name}' for OpenAI credentials "
+                "that will be used to deploy the model to Databricks Model Serving. "
+                "Please verify that the current Databricks user has 'READ' permission for "
+                "this scope. For more information, see "
+                "https://mlflow.org/docs/latest/python_api/openai/index.html#credential-management-for-openai-on-databricks. "  # pylint: disable=line-too-long
+                f"Error: {str(e)}"
+            )
+
+
 def _construct_databricks_run_url(
     host: str,
     experiment_id: str,
     run_id: str,
     workspace_id: Optional[str] = None,
     artifact_path: Optional[str] = None,
 ) -> str:
```

## mlflow/utils/environment.py

```diff
@@ -459,18 +459,15 @@
     for mlflow. The upper bound is a cap on the next major revision. The lower bound is a cap on
     the current installed minor version(i.e., 'mlflow<3,>=2.1')
     :return: string for MLflow dependency version
     """
     mlflow_version = Version(VERSION)
     current_major_version = mlflow_version.major
     current_minor_version = mlflow_version.minor
-    range_version = (
-        f"mlflow<{current_major_version + 1},>={current_major_version}.{current_minor_version}"
-    )
-    return range_version
+    return f"mlflow=={current_major_version}.{current_minor_version}"
 
 
 def _contains_mlflow_requirement(requirements):
     """
     Returns True if `requirements` contains a requirement for mlflow (e.g. 'mlflow==1.2.3').
     """
     return any(map(_is_mlflow_requirement, requirements))
```

## mlflow/utils/autologging_utils/__init__.py

```diff
@@ -1,13 +1,14 @@
 # pylint: disable=unused-wildcard-import,wildcard-import
 
+import contextlib
 import inspect
 import logging
 import time
-import contextlib
+from typing import List
 
 import mlflow
 from mlflow.entities import Metric
 from mlflow.tracking.client import MlflowClient
 from mlflow.utils.validation import MAX_METRICS_PER_BATCH
 
 # Define the module-level logger for autologging utilities before importing utilities defined in
@@ -471,14 +472,42 @@
     """
     global _AUTOLOGGING_GLOBALLY_DISABLED
     _AUTOLOGGING_GLOBALLY_DISABLED = True
     yield None
     _AUTOLOGGING_GLOBALLY_DISABLED = False
 
 
+@contextlib.contextmanager
+def disable_discrete_autologging(flavors_to_disable: List[str]) -> None:
+    """
+    Context manager for disabling specific autologging integrations temporarily while another
+    flavor's autologging is activated. This context wrapper is useful in the event that, for
+    example, a particular library calls upon another library within a training API that has a
+    current MLflow autologging integration.
+    For instance, the transformers library's Trainer class, when running metric scoring,
+    builds a sklearn model and runs evaluations as part of its accuracy scoring. Without this
+    temporary autologging disabling, a new run will be generated that contains a sklearn model
+    that holds no use for tracking purposes as it is only used during the metric evaluation phase
+    of training.
+    :param flavors_to_disable: A list of flavors that need to be temporarily disabled while
+                               executing another flavor's autologging to prevent spurious run
+                               logging of unrelated models, metrics, and parameters.
+    """
+    enabled_flavors = []
+    for flavor in flavors_to_disable:
+        if not autologging_is_disabled(flavor):
+            enabled_flavors.append(flavor)
+            autolog_func = getattr(mlflow, flavor)
+            autolog_func.autolog(disable=True)
+    yield
+    for flavor in enabled_flavors:
+        autolog_func = getattr(mlflow, flavor)
+        autolog_func.autolog(disable=False)
+
+
 def _get_new_training_session_class():
     """
     Returns a session manager class for nested autologging runs.
 
     Examples
     --------
     >>> class Parent: pass
```

## Comparing `mlflow_skinny-2.3.1.dist-info/LICENSE.txt` & `mlflow_skinny-2.3.2.dist-info/LICENSE.txt`

 * *Files identical despite different names*

## Comparing `mlflow_skinny-2.3.1.dist-info/METADATA` & `mlflow_skinny-2.3.2.dist-info/METADATA`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: mlflow-skinny
-Version: 2.3.1
+Version: 2.3.2
 Summary: MLflow: A Platform for ML Development and Productionization
 Home-page: https://mlflow.org/
 Author: Databricks
 License: Apache License 2.0
 Project-URL: Bug Tracker, https://github.com/mlflow/mlflow/issues
 Project-URL: Documentation, https://mlflow.org/docs/latest/index.html
 Project-URL: Source Code, https://github.com/mlflow/mlflow
@@ -231,7 +231,17 @@
     docker pull ghcr.io/mlflow/mlflow:v2.2.1
 
 Contributing
 ------------
 We happily welcome contributions to MLflow. We are also seeking contributions to items on the
 `MLflow Roadmap <https://github.com/mlflow/mlflow/milestone/3>`_. Please see our
 `contribution guide <CONTRIBUTING.md>`_ to learn more about contributing to MLflow.
+
+Maintainers
+-----------
+
+MLflow is currently maintained by the following members with significant contributions from hundreds of exceptionally talented community members.
+
+- `Harutaka Kawamura <https://github.com/harupy>`_
+- `Weichen Xu <https://github.com/WeichenXu123>`_
+- `Corey Zumar <https://github.com/dbczumar>`_
+- `Ben Wilson <https://github.com/BenWilson2>`_
```

## Comparing `mlflow_skinny-2.3.1.dist-info/RECORD` & `mlflow_skinny-2.3.2.dist-info/RECORD`

 * *Files 3% similar despite different names*

```diff
@@ -3,34 +3,34 @@
 mlflow/_doctor.py,sha256=8Av87JugTGSS9XBhtvy7Ml3To22jwzwYnrcEV5w7vj0,3668
 mlflow/_spark_autologging.py,sha256=f5qfIRuQQMwmstvOG_ofo6id38pnsH0WtoHdpHapYMw,9428
 mlflow/catboost.py,sha256=p9j0LvSgfjMAcNWy-HxIeAdxTHQcEmTbNLhk8j2z1AA,15140
 mlflow/cli.py,sha256=7NCvLfgizvTAfyb9C3rh0njC8JoOxYKxKt5AE6n90hI,23356
 mlflow/client.py,sha256=MDQPgZG3RWfd-L3mR4Nr6wGEbiMTeouwzwdxxVKOMi8,407
 mlflow/db.py,sha256=yuGgrAGLoWQI8tMjwt98NxAksuGG04c9CzSSSsL-oAw,881
 mlflow/diviner.py,sha256=wwfpha4AcjegbG6hRMVXLnUJsec84HA3YUX6uVVHCas,28178
-mlflow/environment_variables.py,sha256=4xmv-kN4tIUIsmma8Pwg7DT6mmluNZjH2Q8PVitQKfQ,10080
+mlflow/environment_variables.py,sha256=cwoO8U8UGCFur7K7cWvTJIaGIlx_Yc7mL_69zKpF9ew,10178
 mlflow/exceptions.py,sha256=t7Z9FPmsF3NFL6dbbKwAKg6QjHinlYa-gZLxAJNW82I,4881
 mlflow/experiments.py,sha256=XZZ8AwAOgoVY2hfJfTaVvYaq6JhdxHWvlaSX7zZqC_4,5080
 mlflow/h2o.py,sha256=8pwTh8VDnFdkfxTefcIr984jLL4JvTBkbpEVwyEsccM,14185
 mlflow/keras.py,sha256=GT9xzrZRxdKYxDfK3eH-BwDhwzO9ZfdXgYp8vwWu-nI,311
-mlflow/lightgbm.py,sha256=uUycbEHRYbyiFH96LjZxS2U92Fh4PYBaclQwYqIHBV0,35698
+mlflow/lightgbm.py,sha256=cQUHlCqTNYTpgr642wqCnB-sNfak1jlV6F2PdEif_-E,35902
 mlflow/llm.py,sha256=cN49avoWEdlR5W0PC9L3plLoROCNHCxh8xwt_397XDM,180
-mlflow/ml_package_versions.py,sha256=f8eXBsDmc8cYCbT84u9UZvRUt6deoeoKGkVuCwzn0fU,5474
+mlflow/ml_package_versions.py,sha256=EzZtOS7tpKTHWoWM9VfN_NBHJTxYDW53RlP6o8RVWl4,5575
 mlflow/mleap.py,sha256=UrPchtLPNTbSiZe1PDxkXeb4PCudBVm5HrGDss71xJM,13885
 mlflow/onnx.py,sha256=0DVbxiXJhqT9kieRAcedFWzS00EboCafn0d6zaai2q0,21826
 mlflow/pmdarima.py,sha256=4J_W-mB7xs2xlnJY2P_7jttJ4GCCoRgtk9PfBKjDqIw,17616
 mlflow/prophet.py,sha256=ky-BS3l3Wzuu9hQt_Zjj-_TKgrT-MLSNQbI48td_JrU,14024
 mlflow/pypi_package_index.json,sha256=m8hqgBvkDklIKN96nTB1L1Iv6tmXERj4tTF1rw1ATYI,7197781
 mlflow/runs.py,sha256=Cq5zpln9gsgBn28ZfqZFdDcztB5heOOwLd4vFtNaVn8,2519
 mlflow/shap.py,sha256=kUXkHNWPOXxtMFnJbmGBqOX6CZNfP_LEL72kjmr0yFE,26647
 mlflow/spacy.py,sha256=_mwaaEmsBA3vmb0j0nqn6-cpLzrtB45RMXBpMskteDU,14259
 mlflow/spark.py,sha256=vpoS66wJMh1nzHrEzsKyzoc11GRymgCFHa_GFIVFQ9M,44813
 mlflow/statsmodels.py,sha256=hY361425k4A41yhMk8LINeHeALHgJpHOKDAXPX6qt2E,24596
-mlflow/transformers.py,sha256=cTFi2CBcnTaSQRbVIU5YQclIhgXU8sQnad_dTp689nk,89127
-mlflow/version.py,sha256=paS2HJMvrkTocV_KMVjw_1V4diIfVjPz5Vh6sW9prks,147
+mlflow/transformers.py,sha256=wYxrAyryoIj_WjNZiQStPyOxu-h2CZpGMYv7jnzX-NQ,96409
+mlflow/version.py,sha256=LNvSsXCy6qGksqLF2kpKE8TkAEAQK51Dcepb-jY37RE,147
 mlflow/artifacts/__init__.py,sha256=W2xDlKsxSvEORf1PZcAD66eKXdZVpTFYelG5vAq-kc4,6485
 mlflow/azure/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mlflow/azure/client.py,sha256=SjMkSbTz7-tjBwu7hsFF7t8hlGCk3iuDVtaBUO6y1rA,11647
 mlflow/deployments/__init__.py,sha256=bgGe2fP-vIlN5JBwnE0XiEq4nAZwgOX-O1S5CcxyAcE,3797
 mlflow/deployments/base.py,sha256=HW8SzV88XJvax8U1gyCwGwNUnoXtSbxgEF-NtEQGcDs,15572
 mlflow/deployments/cli.py,sha256=NC583nod0ZHXeaNOyqK2fgRx7lfP8mjqjMW5G-smZV4,15078
 mlflow/deployments/interface.py,sha256=nqJtP5eNKW3_we-IGFMfFwE0Rv-ew0HxXz61mZ141Og,3825
@@ -67,30 +67,30 @@
 mlflow/langchain/__init__.py,sha256=v4DcE8X4fISfifZTA7-ruSbr1wI3QrcDeZYMnrIeB5s,16643
 mlflow/langchain/api_request_parallel_processor.py,sha256=9ZGfJF6jLLPj2i-LFzD_5fYbETdFEwu0JWp3cJT5QC0,4846
 mlflow/models/__init__.py,sha256=lRhJ7uI2mX2xYYiFJ6LS_4J795Vq36vC9ZDTdhluc_Y,3627
 mlflow/models/cli.py,sha256=R4-Jg5RuHYG6wdD4xUMBpWVZh0T-FwmAHu1Ng_VUvBs,9803
 mlflow/models/docker_utils.py,sha256=sE3wheLGR67zn-7Po4HeyRWXQz2bI92-fJRY2idX43g,9853
 mlflow/models/flavor_backend.py,sha256=saS7_-atraIHizYeBMesKuytwtUe_TAVpleDMKUhV_E,3420
 mlflow/models/flavor_backend_registry.py,sha256=2z5S2jxaxL0hBiIhyKaMwb0JzYogh7qemoqp1xhkeU8,2354
-mlflow/models/model.py,sha256=gzISxCps9iHo9eFVrhGYCVecevFvaTdwvb7lXqZA780,23802
+mlflow/models/model.py,sha256=1v7YsjiAshhLGfubfla03gncMj2vxlccx--LgTBubnw,24148
 mlflow/models/signature.py,sha256=iKyhOPeTSzL9zRTyOL2cg5yuzudABe5JHHHE6jid5KA,8634
-mlflow/models/utils.py,sha256=J6jxz2q4vm4C4PY2j21XlG72BS9b4-O9vUGRqNlgxPs,38033
+mlflow/models/utils.py,sha256=S5zrjFUCFOXnbOCdNoBGbaGXHnZqwoIFo9A9C56N0bo,38161
 mlflow/models/wheeled_model.py,sha256=aQT2LUntdd6hOVbKUD5ylU15_4-ofmIz2wjjCbJG8MY,11707
 mlflow/models/container/__init__.py,sha256=EqQ-YlPEpJfuutN-ggE3ATNr-CIVu-KT4-p4kHU9olE,9387
 mlflow/models/container/scoring_server/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mlflow/models/container/scoring_server/wsgi.py,sha256=lKHH1eNI2BR24UznnPlhIcUdFbUBxMSwJVoFXaBw7Lo,131
 mlflow/models/evaluation/__init__.py,sha256=cYGpHa-yh7Z7vpD48A_G5jFuvoLu2raHcezyA_GnIGk,491
 mlflow/models/evaluation/_shap_patch.py,sha256=oS3ym9uuTbb5g7s3rhCvl4vJFeB3ROK67wm1Rw_OmV4,3105
 mlflow/models/evaluation/artifacts.py,sha256=ZpQEbhLtsewUEfx5jT4Dz29UwbBGoXAGIOcLTZlOmD0,6769
-mlflow/models/evaluation/base.py,sha256=CaAi9auv-hJ7VlBzr670CO9NEFakLNbkOsRJO14SDf0,59205
+mlflow/models/evaluation/base.py,sha256=Cu5Fx-MxNClPRwYol-H4eyvgFQ84VeAV7eI5JDxWFcY,59488
 mlflow/models/evaluation/default_evaluator.py,sha256=ZiYTE3HNWuDBU2he3CERd2DNNiu17kF4cU-J8uEIqhg,50976
 mlflow/models/evaluation/evaluator_registry.py,sha256=_0BtXeHdXP0SpgEjpHbIzPqPzbydkXVpw7KMM10ldRg,2036
 mlflow/models/evaluation/lift_curve.py,sha256=8Ik5enKivwzg4IgUYW68TIEwJdrTc-lsDtPfdgtOOVM,6223
 mlflow/models/evaluation/validation.py,sha256=rS0DYVyiraGNAwgtp7lSbruIxzhhZe-RzCjNrtQj2ds,10946
-mlflow/openai/__init__.py,sha256=wr-a3uWEkv7Z8tkYt-Uf7UYw1m1EkdQHsi9iLc_ZXP4,23159
+mlflow/openai/__init__.py,sha256=I_sjCkzm33LoabvWne7Xd7eZ8V1F7z8W0QGgT43e314,23265
 mlflow/openai/api_request_parallel_processor.py,sha256=55dyFj_wgF46qt_CbNfF6Vy1oj1Pi23xpx7g1yBlU_E,12309
 mlflow/openai/retry.py,sha256=LTybicz35wnwqWI82TyEtfA42K_LIIGIAQkg_tECfOQ,2936
 mlflow/openai/utils.py,sha256=7qxqw-MMKNAKZtyZ_PLrLDMvzJ99_F2Ti7UJlt8jpyc,2040
 mlflow/paddle/__init__.py,sha256=3GDLeJPh1SE7VNbMDT5PkETvolvI5DGq4PFnuAIrO2U,23859
 mlflow/paddle/_paddle_autolog.py,sha256=320HLsBXVehs1ipElTT1M2h6AaxhmPnCp37ViWKnzN4,4792
 mlflow/projects/__init__.py,sha256=bbjwU6ZguNNdUnt64bGEqYDCrhJnhCnMKzrfIebnAzw,17396
 mlflow/projects/_project_spec.py,sha256=f1vXIPtrGkiopD9CHmJ1suziVs-n2eKf7Dv__xaqidE,11532
@@ -103,15 +103,15 @@
 mlflow/projects/backend/__init__.py,sha256=aEVrYLweP_wBxJEHJ9hJ8ZbFaFmbJot_z44wO61swck,271
 mlflow/projects/backend/abstract_backend.py,sha256=0EDJucLNKn1BZG-eUTlXhdKw5Uj9zT_VFb-ZR0-zCdk,2210
 mlflow/projects/backend/loader.py,sha256=d-2g2jFdvXkivDTSL7jYe61aPgfr1r_S2vEgVtJKGoQ,1079
 mlflow/projects/backend/local.py,sha256=4NfYiJsCjCJueM0vzsQUq58SoNEAB4Q4wjvmPS6YAnQ,17240
 mlflow/protos/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mlflow/protos/databricks_artifacts_pb2.py,sha256=VWImBxApMcc9YBCG1TNkNvLXf4PXl4kjb4UZGzKaosc,17261
 mlflow/protos/databricks_pb2.py,sha256=zIkESpGJ18X6xJTzpQ2GKCdjw88v2TtmCkBkZ9TnTxk,14095
-mlflow/protos/databricks_uc_registry_messages_pb2.py,sha256=fpkbLkDC-dyKJRI6nQF_t8c_YRGPS2x3jN7g0HU7xTk,38674
+mlflow/protos/databricks_uc_registry_messages_pb2.py,sha256=leHRsPOe67fLoDTi41OgS8x5VoHNF8YmHkxbGE8GThE,39471
 mlflow/protos/databricks_uc_registry_service_pb2.py,sha256=uc5lgb7HHaf9lbx60yLdzuRkyMqPd4Hai2l0QRcdtsY,12471
 mlflow/protos/facet_feature_statistics_pb2.py,sha256=1PV53cuL1c8Gq_jWT812Ofber3r_i0MYtcgPR_Zgggc,16146
 mlflow/protos/mlflow_artifacts_pb2.py,sha256=8zpiVKh77RSVpuRS9YG7Z4hczOEvvyCyGAGWKIibxW8,8552
 mlflow/protos/model_registry_pb2.py,sha256=1SuViyljo-k4Gftvx5mp2lkCTw9OQezkUZFVONjIaD4,54475
 mlflow/protos/service_pb2.py,sha256=AxxG8Dg8BaqO_hMaRiX55zP0XADfC4mCV0THIQsxkOI,48593
 mlflow/protos/scalapb/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mlflow/protos/scalapb/scalapb_pb2.py,sha256=G1jfOHJ01ckKPQUGz63GM6LH5fCDPOsuGaihtHeWIeo,3307
@@ -124,15 +124,15 @@
 mlflow/pyfunc/scoring_server/__init__.py,sha256=Ro7vCpIM4YDrPOPLLxti4KKf2rioBP8XYYKw6xvCO34,13910
 mlflow/pyfunc/scoring_server/client.py,sha256=nyLWhvNtbGdHX15BYLpkVdbGfwp30qU5HkCSlbpBr8s,4222
 mlflow/pyfunc/scoring_server/wsgi.py,sha256=Pz8QfjKU0UhzW9ErT5un0P8HLXgaFZR-fRMo-1TIbJk,175
 mlflow/pyspark/__init__.py,sha256=DJ9fanSajh7sVi4b-mfTFRn2lBhZj1kfz_1ymcP6qHw,50
 mlflow/pyspark/ml/__init__.py,sha256=gRgNuTqhYRyqGhokVMGNtvxMUEug6ZULknZzYiPn5Uo,53458
 mlflow/pyspark/ml/_autolog.py,sha256=9TsaNjkMRQnl9aKghilulgs8Cx1I1B6yoY9D9kqghqE,2908
 mlflow/pyspark/ml/log_model_allowlist.txt,sha256=EVLsk_IxDG--2o27a-wLnuevIUj5vY5hMVHDgiuFdzc,1886
-mlflow/pytorch/__init__.py,sha256=gvL2ShEFDDuQjZOnw5bSDItPw952vR-FoI7f6EcXFCw,45669
+mlflow/pytorch/__init__.py,sha256=r5wM617aU4jGsasB3ooKg88vw6fTly_5egHcpglX7Ls,45379
 mlflow/pytorch/_lightning_autolog.py,sha256=LDpGw4fbvH1cA8WQAbBBsZza3Bx0IiMvdv3qP4A2hfA,17629
 mlflow/pytorch/_pytorch_autolog.py,sha256=K_9sf6ZZHVkzJ61-kpE39I_ob2R2XXawwLf6OrMSntc,2654
 mlflow/pytorch/pickle_module.py,sha256=59e7_JB0Sj1EhnFI-HVfZvV4FE1rY6JpCmUWQ6AHzrg,2090
 mlflow/recipes/__init__.py,sha256=_FUcLtgAP9hiyJ7HI3VD2KsTur1laHC3y8p9SURg3Xw,1330
 mlflow/recipes/artifacts.py,sha256=lookDwTqTogrTwN9gWYpOrvz1evczyaPT0PLGpx3Y_8,6092
 mlflow/recipes/cli.py,sha256=Gfp7h6p5lfrhvbml-zOa6PaAmmsg7L3eFeN-qQeT2OM,2917
 mlflow/recipes/dag_help_strings.py,sha256=_bCnPO1U48BLyZKjJxFbkWD63ETMbfAGzYlmy8_98EU,18431
@@ -166,27 +166,29 @@
 mlflow/recipes/utils/tracking.py,sha256=RbwkaLYXxbr2qroKuRX3_WD_S8_7SNF-OIuZnWW4Dbk,12375
 mlflow/recipes/utils/wrapped_recipe_model.py,sha256=pxIzmFFrhnG8vxORiks8gCNzpOKD7cUinS56bN48uJE,1748
 mlflow/rfunc/__init__.py,sha256=KoOBWfS067bdWVE_Oik9CcydcByDqgJ8kR_3lWMvj9Q,1115
 mlflow/rfunc/backend.py,sha256=uEh6v4F_YwDprZxqMhMIhFekXXXG5LL0mWsoqq2ZdlM,3643
 mlflow/sagemaker/__init__.py,sha256=VE_6UT4pWqIWs9U8hyq7g361BKP9KB4x0S29GNj5e88,135097
 mlflow/sagemaker/cli.py,sha256=mRnNue9iZ4wdY_NX1zCxCLmgK0OR3gX2iKscfvYWZR0,12986
 mlflow/server/__init__.py,sha256=bD5aB3XiNJeqbcs69FgYBKJYNETUYk7tdSBMhN1Nq90,6460
-mlflow/server/handlers.py,sha256=9rPLAeWgjcOJLsGlPJvXpPQ7UP4C97Dipnn-cGzu5YE,68590
+mlflow/server/handlers.py,sha256=N-mIUR6iqxBiHKxKLj3zxMMiod9iuqtCYV80EKVtu50,68605
 mlflow/server/prometheus_exporter.py,sha256=iRXEy5vl4rs7LxzxTxw41BZbunqVlN5Oj1P-EEVynDA,481
-mlflow/server/auth/__init__.py,sha256=tJKsrMx24jV-gtv48BD83h4Y70AxhIMsq0L6O9CFxos,4551
-mlflow/server/auth/config.py,sha256=uArzDei2s4ezVIwsLoAQeT3GksU-KUXleXlGpfK0ldU,409
-mlflow/server/auth/entities.py,sha256=SXHghWADzS8v3QxC2iJHLOoxoJHZw-ro0TDY1H959YY,2384
-mlflow/server/auth/sqlalchemy_store.py,sha256=5HQWaNaq6dZO0G8gx5wk9T9OyJYXRB6Lc-y9f_jNQ5M,5303
-mlflow/sklearn/__init__.py,sha256=08ec0z1JL6Ll9tILsF7TAV4IpjtlYJLd5At3Tfv86Ds,82134
+mlflow/server/auth/__init__.py,sha256=QYypsxDc7ITvak48FEYfOLnGmvdszAdQPpyTQgwoUVw,24354
+mlflow/server/auth/config.py,sha256=qD07UV7U0d0xwrGMTWgyk9Z17C-Lkx-YLB958Vgw8s0,575
+mlflow/server/auth/entities.py,sha256=l1fMY2fA9Z7fywtq2HX74HOcnHY1iS0hTOe_HjuZekY,3171
+mlflow/server/auth/logo.py,sha256=CAKRXrLiQ6CZKVaXBhZ_O0jchYrgoTRXEVoWpgJpP-Y,2673
+mlflow/server/auth/permissions.py,sha256=-iiWHPDWS9HS3WCFawB2eXThtaL28Au6aLhE2oD4g_Y,1267
+mlflow/server/auth/sqlalchemy_store.py,sha256=df__rdcyR128G6pDUuYG_94Ge8eQzi54BUj_5-G0eNI,12648
+mlflow/sklearn/__init__.py,sha256=aaCvU4_Edkvr3084B7UJJSYjtoLMD8TFjKPlSkMuwJM,82319
 mlflow/sklearn/utils.py,sha256=Ia8p5A6xpun4bxwJ92uA4zaQ3daMDpeWvdctBnkjbdY,37485
 mlflow/store/__init__.py,sha256=Yr-KM9CsOUALInyZdgvizb8eCXysBU8UZdkABruVd8A,227
 mlflow/store/_unity_catalog/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mlflow/store/_unity_catalog/registry/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-mlflow/store/_unity_catalog/registry/rest_store.py,sha256=k6TX6vfj1cDRPLg8OZxUHZ9IFNly7wK6BZXF4BNP1Sk,25610
-mlflow/store/_unity_catalog/registry/utils.py,sha256=V8hciFJhGhxlRwXdA7BsBimdoHWDh3ozw0QcIE5RO6U,4276
+mlflow/store/_unity_catalog/registry/rest_store.py,sha256=-KGfG1whfUTpGoLHAZuLSvk3AqPw99sLJaQPaix9ewc,27183
+mlflow/store/_unity_catalog/registry/utils.py,sha256=0c5VOefaH5H_K_RCp7V1noPJa7DYPBOYNwA8n6vL8io,5419
 mlflow/store/artifact/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mlflow/store/artifact/artifact_repo.py,sha256=OA4iMT86dgdOyuJytQGC-Ku5aVroxnQRszk7flzFwyE,15034
 mlflow/store/artifact/artifact_repository_registry.py,sha256=PVev-PTreMx3yne9uMipBU2nkIIS_CTIKYgkW5NvJn0,5309
 mlflow/store/artifact/azure_blob_artifact_repo.py,sha256=n2csaNEtAIw0LCwR6W8oJ3nhoP9uI9CgEnOsLiYxhMk,8136
 mlflow/store/artifact/azure_data_lake_artifact_repo.py,sha256=nO7SnzF5pXtwSjK8lT1OyyADOaJZc1zMn7fQ6V9NsPw,5829
 mlflow/store/artifact/cli.py,sha256=q8FUy7m6TFDRXneh2W0aQ-PRLfkl1HzSvkFvE8Q7Rss,5378
 mlflow/store/artifact/databricks_artifact_repo.py,sha256=GiRs3aIy1mBlx9PlscY1EVLPkuLHDs3CxzgbkfSbPUE,31773
@@ -198,15 +200,15 @@
 mlflow/store/artifact/http_artifact_repo.py,sha256=Zq2ImiBkiWUoO3NN6bnzwx9GSB-s6uZnYwrAxlvSpHs,3377
 mlflow/store/artifact/local_artifact_repo.py,sha256=48nJsxzAJPNYYNoeo8gahRQ41X-LXo3IaDb0j-JjsAw,5085
 mlflow/store/artifact/mlflow_artifacts_repo.py,sha256=WsWgB_J7N4wIzB2HmvOHoernRFzDjOGpfarZ38eCrxQ,3001
 mlflow/store/artifact/models_artifact_repo.py,sha256=U0H6o7GFqEjeN6mCTXEDVKIMNlUkzA5DIPhTq7HiCGQ,6757
 mlflow/store/artifact/runs_artifact_repo.py,sha256=RChPNUB1zC0tLFEVXDi2ionsHyOqeCr6sM8UxtcoAqc,6016
 mlflow/store/artifact/s3_artifact_repo.py,sha256=tfunXtzbes9ofdV25Ue39AITBjgrnSIKj86zjsUyqN8,9442
 mlflow/store/artifact/sftp_artifact_repo.py,sha256=RVI1mdfFHdzeXPfHKBZDU-wcbvzh9_L2o5yEWGjwl9E,5455
-mlflow/store/artifact/unity_catalog_models_artifact_repo.py,sha256=gOpMwD2xSd4v51OMHxkvcsvymjIfLu2xmQ7Dt7ZRpUY,5326
+mlflow/store/artifact/unity_catalog_models_artifact_repo.py,sha256=QGEPjA4g9WZfw1X2TVX4Xzgt9vrSiC2q4MQfSFhM7BU,5592
 mlflow/store/artifact/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mlflow/store/artifact/utils/models.py,sha256=XcILBvEEULupgHmYVAekQ8xqzfeey6Xr-6fm3nV3qjo,3934
 mlflow/store/db/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mlflow/store/db/base_sql_model.py,sha256=kha9xmklzhuQAK8QEkNBn-mAHq8dUKbOM-3abaBpWmQ,71
 mlflow/store/db/db_types.py,sha256=bGoaqGlCgjrQ5PB119DE4b_t1hysxyHkObYHe5IMPss,221
 mlflow/store/db/utils.py,sha256=48zYlVF1yMjpaFpnilNWv6B3JBu4nCua3YNzu45BE-A,10592
 mlflow/store/db_migrations/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
@@ -251,22 +253,22 @@
 mlflow/store/tracking/dbmodels/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mlflow/store/tracking/dbmodels/initial_models.py,sha256=8T-NRIaHQw3Es37kIuBS7EXkJe20jTJXPU193mjeoHQ,8315
 mlflow/store/tracking/dbmodels/models.py,sha256=PPT0XC6F4foBLfQs_KcngxL8EoLIi59QXZiuse3Tbjo,15674
 mlflow/tensorflow/__init__.py,sha256=btZindFA5NV2FRlxwGmuhKgFud7xVuUK93H8SVpTgUk,57261
 mlflow/tensorflow/_autolog.py,sha256=Wss_IDfnQzbG0qEUpAr2DZZRmGay8A4X4atFbx0qU8c,8442
 mlflow/tracking/__init__.py,sha256=XFq7V_eudhTz3o_pdEyyQxb5o7jMuL_2qtEE5VygjzE,995
 mlflow/tracking/artifact_utils.py,sha256=65aU24U9qacsHnF6wM3c_r98s_XVHzEFmv2B1w0gR9Q,7155
-mlflow/tracking/client.py,sha256=uTJJr07hv60FioszbVq6oxvcMXcGn-Qrp6zdQ0VeOlg,126036
-mlflow/tracking/fluent.py,sha256=3LsyIkmMJ9i3HvJ6fd_1_ewjsB2ttk0GNgb6IBIjT_k,70974
+mlflow/tracking/client.py,sha256=gCKowVWEgP51bkiJKp5_3m3AhPw6kisXhdkYlnD77-Q,130061
+mlflow/tracking/fluent.py,sha256=GVxNlFFqNf6Mt88pIAXyxNiRwMxLe2st34vuKITFwOs,71082
 mlflow/tracking/llm_utils.py,sha256=GT3CLqNSovBKLf6t3l6jmeI3vwmw8qMwk21Y5gmkBW8,3404
 mlflow/tracking/metric_value_conversion_utils.py,sha256=qSqG_eEShP69DS5d7MkrkhYyz-kQ9ZT9y73Lc7AKz8c,2248
 mlflow/tracking/registry.py,sha256=hsZg1uVSz95lypiPgKD8t7KVKtLRW8VGi3YLICFwwHo,3515
 mlflow/tracking/_model_registry/__init__.py,sha256=_HtGwD9WY1x2-02TgEftcWrKKqBnJNjB9YdRc6sqLe4,41
 mlflow/tracking/_model_registry/client.py,sha256=GwZO4Jzuxe2eWjv9q47tR3I-E_mHpiKdRewuzvHQum0,15534
-mlflow/tracking/_model_registry/fluent.py,sha256=bG2VH5BxikL16nVVjD5S3X8px-nwkAbJ2STab0QKI4c,9364
+mlflow/tracking/_model_registry/fluent.py,sha256=2Cq8vj-boEN8_JHiEITYLB8Kq4JFgM4rYIwL7ulfX9E,9641
 mlflow/tracking/_model_registry/registry.py,sha256=qsuCwqPadP3PWvhMwBXJOubT_j4oaoNDc1aEN05MNb8,3152
 mlflow/tracking/_model_registry/utils.py,sha256=NnpDMhCpdBX4MrEMnv-MxvjO9wj7cjlpiJhFfi-0bxc,7008
 mlflow/tracking/_tracking_service/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mlflow/tracking/_tracking_service/client.py,sha256=grGPancFw9evxDcyLobmGhwepLV_GGq8JZ0lmmHtqeg,23690
 mlflow/tracking/_tracking_service/registry.py,sha256=wGtLKNTcOlnzUTHVm_o47YxWb0eA2MFhnDs1C9vCvik,2335
 mlflow/tracking/_tracking_service/utils.py,sha256=pdD1HBq_roAqk3vWNj7NTbnpZC7Tr6HI40fFIXEcY-4,9517
 mlflow/tracking/context/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
@@ -295,22 +297,22 @@
 mlflow/types/utils.py,sha256=ttRVfm7fs09fxYMR7nF62sIrudhhjBlWhAynMbLrQDo,17899
 mlflow/utils/__init__.py,sha256=wCpt9d3G_e0hyArdrzkFhrUvjtDOCcdJSgy5oWNPe6E,9389
 mlflow/utils/_capture_modules.py,sha256=d5bMqg7wSf6UQ4JRrk1Ab0y_kxhQMPR8LMTUvKZ6rcw,6270
 mlflow/utils/_spark_utils.py,sha256=AVdnCDzjOjBa8ZhLQsqYbpV1b_GGS_MCO5cVfKiumLc,6395
 mlflow/utils/annotations.py,sha256=WUt63FPWd1xeqATyMbF5wHRGp68KvkS72lqXOMnKbsg,4906
 mlflow/utils/arguments_utils.py,sha256=B8KUnf59cpg6ML3fjjxJ_FrHfIxMnWcsNZcq8KNILQk,400
 mlflow/utils/class_utils.py,sha256=1GjsGesJgRXu3omxcGzvwruh1fsCN1GvsbeEUvmtkW0,215
-mlflow/utils/cli_args.py,sha256=1WgpFFQdteAFNcEhdmYO2SqhSeNKZ7itPWaVZtD8rx0,6431
+mlflow/utils/cli_args.py,sha256=ecmOpYmR98NledPfPD8XY3tfjxRTfBixkaYZy551vIA,6431
 mlflow/utils/conda.py,sha256=cOpyLtcBJg1-7c8OqmCPB8-8Cp5VSDyKGTzOdBmGqpQ,13002
 mlflow/utils/data_utils.py,sha256=XXTjNkegciD8AhWR569p5W_BsPluxO2FOaRZOYxGnRY,432
-mlflow/utils/databricks_utils.py,sha256=rP1U3RYfbDSFvU4jAdS9IWn4jS0lJhgIOKop3WQF33U,21834
+mlflow/utils/databricks_utils.py,sha256=YusngI7nkVWUIdzAvul3K5H0nKaNGebsjP4wyJy2Zpk,22596
 mlflow/utils/docstring_utils.py,sha256=saU5MsKF5yYA12xsBg7jijnoC3yF1z88yM8LzMKzQls,9138
 mlflow/utils/env.py,sha256=YH1Rr7i6-s09PWOUyL2j-0SvR5YeZmc1hA-hKyvgEt8,192
 mlflow/utils/env_manager.py,sha256=pM-V8KW2IwZr2BDx1aZjKmliv-nM3akkEYHhLVAgaqc,474
-mlflow/utils/environment.py,sha256=RwaRzzQLZJNxl1-XIATVGeZp1XhaIk67p9KYsGcc7Go,21930
+mlflow/utils/environment.py,sha256=WWI969_9wyG71_lwkksefhlcVLr10Onyktm2O_uCLak,21851
 mlflow/utils/file_utils.py,sha256=f48QFjnqfzVXfO2_sBHiemJuawCFDcM9BeoG7Nijhvc,25967
 mlflow/utils/git_utils.py,sha256=LVLjkRJpj06-ndAVB-Pzw5YV7PaDlp2DtJhDZAqAPhs,2306
 mlflow/utils/gorilla.py,sha256=9LDEOjCoSLbq0W7kNqxyKJA3HjZZXMniIS0N4koQCTc,24166
 mlflow/utils/logging_utils.py,sha256=Ey1So5UXLREwoxHfguiAJIaylDwFnzHYzEsPMnqVlew,2597
 mlflow/utils/mime_type_utils.py,sha256=ALg_KnRUI9VPxm7OjCPX-fqzOMj-qiAmYFlJMT21fDI,1298
 mlflow/utils/mlflow_tags.py,sha256=i0jOmNT923tmpRHGjTR0SL9vnQZG5QtGhkmEK1vN9DA,3839
 mlflow/utils/model_utils.py,sha256=ezqfQURsanWBIPOwMaz-JgKGGHRJe4VlynE4ugrejTY,6208
@@ -324,15 +326,15 @@
 mlflow/utils/search_utils.py,sha256=vq3ME21AZLBrFomDEGy_yxK2kAGD3H4QXjWy3-1BIgM,56769
 mlflow/utils/server_cli_utils.py,sha256=RUy0tgl0f2NNC-b9gunt2tgALfeUJeLGjQUEwCzicuY,2368
 mlflow/utils/string_utils.py,sha256=OFq1Yqxzkr4fangUqMwCw-V_LT25EtPUZvCGMpg2K-c,3805
 mlflow/utils/time_utils.py,sha256=vsxzbrVJiCyjqhS16mgXqtCwr7XMHgKcV-C1LKqMI0A,512
 mlflow/utils/uri.py,sha256=BIilN9tjRKLJif9QqphJRHZ5qVlcUaZmTSVftNqOuGo,13915
 mlflow/utils/validation.py,sha256=7jOdkD08gU0ClF5YPBvFPstBC7KFVV6z4L1BBA_jWqY,16024
 mlflow/utils/virtualenv.py,sha256=ASdP5ZfgyLEc1rkTRZB488tmsTaKY1_qaVX-jgLv6BU,16452
-mlflow/utils/autologging_utils/__init__.py,sha256=ewsostxygslzpFOu2JqQlT57bGFRyT3a0V77NhqRug8,25551
+mlflow/utils/autologging_utils/__init__.py,sha256=0oXuYTpRaveIfK52K_55FtSz0vQr1BkeOcy3A2PFULE,27070
 mlflow/utils/autologging_utils/client.py,sha256=y6X_QdWk1oJSZITw7-jbGVwIqFQ2u5I4-jMgPvkN3o4,15731
 mlflow/utils/autologging_utils/events.py,sha256=CXnCIFMTNuvARerF_wsW5AXq7-A7fcg6djuH5jt_Ou0,10937
 mlflow/utils/autologging_utils/logging_and_warnings.py,sha256=0XG5BA4cNcX1Ezd8in7bjCjqFd3PXAD_VxjmyUu7EYQ,13381
 mlflow/utils/autologging_utils/safety.py,sha256=vaYUNEj4iCWk2RbUz3cP4rdy7NVkIzJt3bQQzWuV75Q,47266
 mlflow/utils/autologging_utils/versioning.py,sha256=7mERL6JWFEmPazbGM8bbY7Y252tIqrGuWfipYRIzMmE,3489
 mlflow/utils/import_hooks/__init__.py,sha256=YjsZtqhGnxKEBDc_GVsGdG_W2ZrJlu4FaqNSG2xduZo,13489
 mlflow/xgboost/__init__.py,sha256=mZLTOG6zNl6enEqJoo8QPcpUhSFZU1_2dyrTRJjmjR8,34313
@@ -340,13 +342,13 @@
 pylint_plugins/__init__.py,sha256=P5u2tXPOMEfyIWUfKSUd4-7lN9ZMLHIusJ403Ez70xM,521
 pylint_plugins/errors.py,sha256=vFHxRPChPKZNGQyPMip6YTwjEmooWM7hbW1sRxcTfCk,2006
 pylint_plugins/print_function.py,sha256=6MPDFzEelH_lJQTlbBIj03wBSzLtSNMvZhL0gIyacU0,856
 pylint_plugins/set_checker.py,sha256=7RklQvldMi4a_E09lzY7QMsZ7Pum9Kd-vlgq1cHYoNQ,571
 pylint_plugins/string_checker.py,sha256=Lvu8GNYn-T5t5ixy3JxoUxtaGqv2H-rOgaRzhDuewDY,878
 pylint_plugins/unittest_assert_raises.py,sha256=3Jrw4uNIXyvOWYPtDBT1PokQvvHn6zsWu6yC6IQvctM,692
 pylint_plugins/pytest_raises_checker/__init__.py,sha256=LEHPlk-aFdwgHY9dk_DAil41IU-BB1Ds9_CLq2RQISc,1546
-mlflow_skinny-2.3.1.dist-info/LICENSE.txt,sha256=Y5U1Xebzka__NZlqMPtBsYm0mRpMtUmTrONatpoL-ig,11382
-mlflow_skinny-2.3.1.dist-info/METADATA,sha256=BtTk9oA8bbEEJVbKjC_zuDJvEHeYh3gOyrD05Vwsa3E,12392
-mlflow_skinny-2.3.1.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-mlflow_skinny-2.3.1.dist-info/entry_points.txt,sha256=brdXR55SgMBSluzZ5H20Cj8-yN2n2LRFiy5Yw25JTps,92
-mlflow_skinny-2.3.1.dist-info/top_level.txt,sha256=2q15FEJ-On4TrBIP3hc6d4rDq2l4-i2mQJUq9aRdcq0,22
-mlflow_skinny-2.3.1.dist-info/RECORD,,
+mlflow_skinny-2.3.2.dist-info/LICENSE.txt,sha256=Y5U1Xebzka__NZlqMPtBsYm0mRpMtUmTrONatpoL-ig,11382
+mlflow_skinny-2.3.2.dist-info/METADATA,sha256=SzETmAQxXz2L6ZKQFlAyH332qq9xF3gO911suxZi6Yc,12761
+mlflow_skinny-2.3.2.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+mlflow_skinny-2.3.2.dist-info/entry_points.txt,sha256=brdXR55SgMBSluzZ5H20Cj8-yN2n2LRFiy5Yw25JTps,92
+mlflow_skinny-2.3.2.dist-info/top_level.txt,sha256=2q15FEJ-On4TrBIP3hc6d4rDq2l4-i2mQJUq9aRdcq0,22
+mlflow_skinny-2.3.2.dist-info/RECORD,,
```

